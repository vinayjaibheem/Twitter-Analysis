2017-09-16 14:49:36,030 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-16 14:49:36,037 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-16 14:49:36,044 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-16 14:49:36,321 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-16 14:49:36,444 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-16 14:49:36,444 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-16 14:49:36,469 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-16 14:49:36,472 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-16 14:49:36,576 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-16 14:49:36,702 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-16 14:49:36,728 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-16 14:49:36,784 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-16 14:49:36,796 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-16 14:49:36,807 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-16 14:49:36,814 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-16 14:49:36,817 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-16 14:49:36,817 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-16 14:49:36,817 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-16 14:49:36,938 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-16 14:49:36,940 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-16 14:49:36,963 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-16 14:49:36,963 INFO org.mortbay.log: jetty-6.1.26
2017-09-16 14:49:37,086 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-16 14:49:37,122 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-16 14:49:37,122 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-16 14:49:37,151 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-16 14:49:37,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-16 14:49:37,158 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-16 14:49:37,159 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-16 14:49:37,189 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-16 14:49:37,189 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-16 14:49:37,190 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-16 14:49:37,191 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 16 14:49:37
2017-09-16 14:49:37,192 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-16 14:49:37,192 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-16 14:49:37,193 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-16 14:49:37,193 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-16 14:49:37,206 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-16 14:49:37,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-16 14:49:37,209 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-16 14:49:37,209 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-16 14:49:37,209 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-16 14:49:37,209 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-16 14:49:37,209 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-16 14:49:37,209 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-16 14:49:37,216 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-16 14:49:37,216 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-16 14:49:37,216 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-16 14:49:37,216 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-16 14:49:37,217 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-16 14:49:37,271 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-16 14:49:37,271 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-16 14:49:37,271 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-16 14:49:37,271 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-16 14:49:37,272 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-16 14:49:37,272 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-16 14:49:37,272 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-16 14:49:37,280 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-16 14:49:37,280 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-16 14:49:37,280 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-16 14:49:37,280 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-16 14:49:37,282 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-16 14:49:37,282 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-16 14:49:37,282 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-16 14:49:37,287 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-16 14:49:37,287 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-16 14:49:37,287 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-16 14:49:37,291 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-16 14:49:37,291 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-16 14:49:37,293 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-16 14:49:37,293 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-16 14:49:37,293 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-16 14:49:37,293 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-16 14:49:37,344 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 57022@localhost
2017-09-16 14:49:37,364 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-16 14:49:37,365 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2017-09-16 14:49:37,366 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-09-16 14:49:37,401 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2017-09-16 14:49:37,423 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-16 14:49:37,423 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000000
2017-09-16 14:49:37,427 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-09-16 14:49:37,427 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2017-09-16 14:49:37,527 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-16 14:49:37,527 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 232 msecs
2017-09-16 14:49:37,661 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-16 14:49:37,667 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-16 14:49:37,676 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-16 14:49:37,744 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-16 14:49:37,752 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-16 14:49:37,752 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2017-09-16 14:49:37,753 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2017-09-16 14:49:37,753 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2017-09-16 14:49:37,753 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-16 14:49:37,761 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2017-09-16 14:49:37,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-16 14:49:37,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2017-09-16 14:49:37,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-16 14:49:37,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-09-16 14:49:37,762 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2017-09-16 14:49:37,794 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-16 14:49:37,795 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-16 14:49:37,797 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-16 14:49:37,801 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-16 14:49:37,801 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-16 14:49:37,805 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 4 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-16 14:49:37,809 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-16 14:49:53,330 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-16 14:49:53,330 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-16 14:49:53,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-16 14:49:53,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-16 14:49:53,435 INFO BlockStateChange: BLOCK* processReport 0xa293c4857d308ee7: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-16 14:49:53,436 INFO BlockStateChange: BLOCK* processReport 0xa293c4857d308ee7: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2017-09-16 14:51:09,640 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-16 14:51:09,640 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-16 14:51:09,640 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1, 1
2017-09-16 14:51:09,640 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=2 lastSyncedTxid=1 mostRecentTxid=2
2017-09-16 14:51:09,640 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 4 
2017-09-16 14:51:09,641 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=2 lastSyncedTxid=2 mostRecentTxid=2
2017-09-16 14:51:09,641 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 4 
2017-09-16 14:51:09,642 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000001 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000001-0000000000000000002
2017-09-16 14:51:09,645 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3
2017-09-16 14:51:10,425 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2017-09-16 14:51:10,425 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000002 size 321 bytes.
2017-09-16 14:51:10,432 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2017-09-16 14:58:18,362 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1256ms
No GCs detected
2017-09-16 15:03:33,410 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1042ms
No GCs detected
2017-09-16 15:06:17,404 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1247ms
No GCs detected
2017-09-16 15:42:41,786 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1502ms
No GCs detected
2017-09-16 15:44:19,648 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1389ms
No GCs detected
2017-09-16 15:45:07,929 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1216ms
No GCs detected
2017-09-16 15:47:55,056 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1019ms
No GCs detected
2017-09-16 15:51:12,146 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-16 15:51:12,147 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-16 15:51:12,147 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 3, 3
2017-09-16 15:51:12,150 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=4 lastSyncedTxid=3 mostRecentTxid=4
2017-09-16 15:51:12,150 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 3 
2017-09-16 15:51:12,153 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=4 lastSyncedTxid=4 mostRecentTxid=4
2017-09-16 15:51:12,153 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 5 
2017-09-16 15:51:12,154 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000003 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000003-0000000000000000004
2017-09-16 15:51:12,155 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5
2017-09-16 15:51:12,235 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2017-09-16 15:51:12,235 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000004 size 321 bytes.
2017-09-16 15:51:12,238 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2017-09-16 15:51:12,238 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-09-16 15:54:12,794 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1029ms
No GCs detected
2017-09-16 16:04:31,085 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-16 16:04:31,474 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1
************************************************************/
2017-09-16 16:17:39,865 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-16 16:17:39,873 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-16 16:17:39,883 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-16 16:17:40,130 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-16 16:17:40,254 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-16 16:17:40,254 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-16 16:17:40,270 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-16 16:17:40,273 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-16 16:17:40,365 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-16 16:17:40,483 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-16 16:17:40,506 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-16 16:17:40,558 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-16 16:17:40,569 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-16 16:17:40,575 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-16 16:17:40,579 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-16 16:17:40,581 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-16 16:17:40,581 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-16 16:17:40,581 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-16 16:17:40,688 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-16 16:17:40,690 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-16 16:17:40,706 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-16 16:17:40,706 INFO org.mortbay.log: jetty-6.1.26
2017-09-16 16:17:40,845 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-16 16:17:40,897 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-16 16:17:40,897 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-16 16:17:40,978 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-16 16:17:40,991 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-16 16:17:40,993 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-16 16:17:40,996 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-16 16:17:41,070 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-16 16:17:41,070 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-16 16:17:41,072 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-16 16:17:41,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 16 16:17:41
2017-09-16 16:17:41,077 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-16 16:17:41,077 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-16 16:17:41,081 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-16 16:17:41,081 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-16 16:17:41,115 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-16 16:17:41,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-16 16:17:41,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-16 16:17:41,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-16 16:17:41,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-16 16:17:41,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-16 16:17:41,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-16 16:17:41,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-16 16:17:41,133 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-16 16:17:41,133 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-16 16:17:41,133 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-16 16:17:41,133 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-16 16:17:41,136 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-16 16:17:41,245 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-16 16:17:41,245 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-16 16:17:41,246 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-16 16:17:41,246 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-16 16:17:41,247 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-16 16:17:41,247 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-16 16:17:41,247 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-16 16:17:41,256 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-16 16:17:41,257 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-16 16:17:41,257 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-16 16:17:41,257 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-16 16:17:41,258 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-16 16:17:41,258 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-16 16:17:41,258 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-16 16:17:41,262 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-16 16:17:41,262 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-16 16:17:41,262 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-16 16:17:41,266 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-16 16:17:41,266 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-16 16:17:41,268 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-16 16:17:41,268 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-16 16:17:41,268 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-16 16:17:41,268 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-16 16:17:41,329 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 3102@localhost
2017-09-16 16:17:41,345 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-16 16:17:41,367 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000005 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000005-0000000000000000005
2017-09-16 16:17:41,371 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000004, cpktTxId=0000000000000000004)
2017-09-16 16:17:41,399 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2017-09-16 16:17:41,416 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-16 16:17:41,416 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 4 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000004
2017-09-16 16:17:41,416 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@20f12539 expecting start txid #5
2017-09-16 16:17:41,417 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000005-0000000000000000005
2017-09-16 16:17:41,417 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000005-0000000000000000005' to transaction ID 5
2017-09-16 16:17:41,425 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000005-0000000000000000005 of size 1048576 edits # 1 loaded in 0 seconds
2017-09-16 16:17:41,425 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-09-16 16:17:41,426 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 6
2017-09-16 16:17:41,510 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-16 16:17:41,510 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 240 msecs
2017-09-16 16:17:41,680 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-16 16:17:41,685 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-16 16:17:41,693 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-16 16:17:41,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-16 16:17:41,754 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-16 16:17:41,754 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2017-09-16 16:17:41,754 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2017-09-16 16:17:41,754 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2017-09-16 16:17:41,754 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-16 16:17:41,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2017-09-16 16:17:41,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-16 16:17:41,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2017-09-16 16:17:41,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-16 16:17:41,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-09-16 16:17:41,763 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2017-09-16 16:17:41,784 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-16 16:17:41,787 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-16 16:17:41,789 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-16 16:17:41,792 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-16 16:17:41,792 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-16 16:17:41,796 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 4 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-16 16:17:41,799 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-16 16:17:50,417 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-16 16:17:50,418 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-16 16:17:50,418 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-16 16:17:50,467 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-16 16:17:50,502 INFO BlockStateChange: BLOCK* processReport 0x508ba301c7019488: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-16 16:17:50,503 INFO BlockStateChange: BLOCK* processReport 0x508ba301c7019488: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2017-09-16 16:24:32,223 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1145ms
No GCs detected
2017-09-16 16:27:10,858 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 5 Number of syncs: 2 SyncTimes(ms): 7 
2017-09-16 16:37:38,172 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 5 Number of syncs: 3 SyncTimes(ms): 10 
2017-09-16 17:05:00,842 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-16 17:05:00,842 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-16 17:05:00,842 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 6, 8
2017-09-16 17:05:00,844 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=9 lastSyncedTxid=8 mostRecentTxid=9
2017-09-16 17:05:00,844 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 5 Number of syncs: 4 SyncTimes(ms): 13 
2017-09-16 17:05:00,850 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=9 lastSyncedTxid=9 mostRecentTxid=9
2017-09-16 17:05:00,850 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 5 Number of syncs: 5 SyncTimes(ms): 18 
2017-09-16 17:05:00,856 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000006 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000006-0000000000000000009
2017-09-16 17:05:00,856 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 10
2017-09-16 17:05:01,543 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2017-09-16 17:05:01,543 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000009 size 462 bytes.
2017-09-16 17:05:01,546 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4
2017-09-16 17:05:01,546 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2017-09-16 17:24:11,969 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1011ms
No GCs detected
2017-09-16 17:25:59,799 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1406ms
No GCs detected
2017-09-16 17:26:01,845 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1545ms
No GCs detected
2017-09-16 17:26:10,937 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1082ms
No GCs detected
2017-09-16 19:43:28,851 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-16 19:43:28,852 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-16 19:43:28,852 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 10, 10
2017-09-16 19:43:28,855 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=11 lastSyncedTxid=10 mostRecentTxid=11
2017-09-16 19:43:28,855 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2017-09-16 19:43:28,864 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=11 lastSyncedTxid=11 mostRecentTxid=11
2017-09-16 19:43:28,865 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 18 
2017-09-16 19:43:28,868 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000010 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000010-0000000000000000011
2017-09-16 19:43:28,869 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 12
2017-09-16 19:43:29,028 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2017-09-16 19:43:29,029 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000011 size 462 bytes.
2017-09-16 19:43:29,037 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 9
2017-09-16 19:43:29,037 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000004, cpktTxId=0000000000000000004)
2017-09-17 21:47:28,188 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-17 21:47:28,194 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-17 21:47:28,201 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-17 21:47:28,442 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-17 21:47:28,665 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-17 21:47:28,665 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-17 21:47:28,691 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-17 21:47:28,695 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-17 21:47:28,790 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-17 21:47:29,018 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-17 21:47:29,033 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-17 21:47:29,079 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-17 21:47:29,086 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-17 21:47:29,095 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-17 21:47:29,102 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-17 21:47:29,104 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-17 21:47:29,104 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-17 21:47:29,104 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-17 21:47:29,223 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-17 21:47:29,225 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-17 21:47:29,251 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-17 21:47:29,251 INFO org.mortbay.log: jetty-6.1.26
2017-09-17 21:47:29,470 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-17 21:47:29,796 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-17 21:47:29,796 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-17 21:47:29,856 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-17 21:47:29,865 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-17 21:47:29,866 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-17 21:47:29,867 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-17 21:47:29,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-17 21:47:29,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-17 21:47:29,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-17 21:47:29,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 17 21:47:29
2017-09-17 21:47:29,910 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-17 21:47:29,910 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-17 21:47:29,912 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-17 21:47:29,912 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-17 21:47:29,932 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-17 21:47:29,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-17 21:47:29,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-17 21:47:29,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-17 21:47:29,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-17 21:47:29,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-17 21:47:29,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-17 21:47:29,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-17 21:47:29,942 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-17 21:47:29,942 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-17 21:47:29,942 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-17 21:47:29,942 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-17 21:47:29,943 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-17 21:47:30,017 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-17 21:47:30,018 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-17 21:47:30,018 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-17 21:47:30,018 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-17 21:47:30,019 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-17 21:47:30,019 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-17 21:47:30,019 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-17 21:47:30,026 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-17 21:47:30,026 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-17 21:47:30,026 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-17 21:47:30,026 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-17 21:47:30,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-17 21:47:30,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-17 21:47:30,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-17 21:47:30,033 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-17 21:47:30,033 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-17 21:47:30,033 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-17 21:47:30,037 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-17 21:47:30,038 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-17 21:47:30,040 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-17 21:47:30,040 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-17 21:47:30,040 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-17 21:47:30,040 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-17 21:47:30,440 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 4671@localhost
2017-09-17 21:47:30,462 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-17 21:47:30,493 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000012 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000012-0000000000000000012
2017-09-17 21:47:30,498 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000011, cpktTxId=0000000000000000011)
2017-09-17 21:47:30,535 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 3 INodes.
2017-09-17 21:47:30,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-17 21:47:30,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 11 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000011
2017-09-17 21:47:30,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@20f12539 expecting start txid #12
2017-09-17 21:47:30,555 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000012-0000000000000000012
2017-09-17 21:47:30,556 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000012-0000000000000000012' to transaction ID 12
2017-09-17 21:47:30,563 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000012-0000000000000000012 of size 1048576 edits # 1 loaded in 0 seconds
2017-09-17 21:47:30,563 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2017-09-17 21:47:30,563 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2017-09-17 21:47:30,568 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/raji/hadoop_store/hdfs/namenode/current/fsimage.ckpt_0000000000000000012 using no compression
2017-09-17 21:47:30,603 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/raji/hadoop_store/hdfs/namenode/current/fsimage.ckpt_0000000000000000012 of size 462 bytes saved in 0 seconds.
2017-09-17 21:47:30,612 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 11
2017-09-17 21:47:30,612 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000009, cpktTxId=0000000000000000009)
2017-09-17 21:47:30,621 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 13
2017-09-17 21:47:30,703 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-17 21:47:30,703 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 660 msecs
2017-09-17 21:47:30,878 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-17 21:47:30,884 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-17 21:47:30,904 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-17 21:47:30,976 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-17 21:47:31,010 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-17 21:47:31,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2017-09-17 21:47:31,011 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2017-09-17 21:47:31,011 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2017-09-17 21:47:31,011 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-17 21:47:31,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2017-09-17 21:47:31,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-17 21:47:31,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2017-09-17 21:47:31,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-17 21:47:31,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-09-17 21:47:31,022 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 11 msec
2017-09-17 21:47:31,074 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-17 21:47:31,076 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-17 21:47:31,263 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-17 21:47:31,267 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-17 21:47:31,268 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-17 21:47:31,273 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 4 milliseconds
name space=3
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-17 21:47:31,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-17 21:47:40,623 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-17 21:47:40,624 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-17 21:47:40,624 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-17 21:47:40,692 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-17 21:47:40,750 INFO BlockStateChange: BLOCK* processReport 0x36eab1b1d48d4249: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-17 21:47:40,752 INFO BlockStateChange: BLOCK* processReport 0x36eab1b1d48d4249: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2017-09-17 21:52:59,150 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1027ms
No GCs detected
2017-09-17 21:53:09,137 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1011ms
No GCs detected
2017-09-17 21:54:11,516 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 27 Number of transactions batched in Syncs: 12 Number of syncs: 2 SyncTimes(ms): 6 
2017-09-17 21:54:11,657 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:50010 for /hbase/.tmp/hbase.version
2017-09-17 21:54:12,111 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/.tmp/hbase.version
2017-09-17 21:54:12,111 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2017-09-17 21:54:12,523 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/hbase.version is closed by DFSClient_NONMAPREDUCE_-210773990_1
2017-09-17 21:54:12,547 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:50010 for /hbase/.tmp/hbase.id
2017-09-17 21:54:12,560 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741826_1002 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/.tmp/hbase.id
2017-09-17 21:54:12,560 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2017-09-17 21:54:12,965 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/hbase.id is closed by DFSClient_NONMAPREDUCE_-210773990_1
2017-09-17 21:54:13,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:50010 for /hbase/data/hbase/meta/1588230740/.regioninfo
2017-09-17 21:54:13,203 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/.regioninfo is closed by DFSClient_NONMAPREDUCE_-210773990_1
2017-09-17 21:54:13,376 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_-210773990_1
2017-09-17 21:54:13,394 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:50010 for /hbase/data/hbase/meta/.tmp/.tableinfo.0000000001
2017-09-17 21:54:13,415 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741828_1004 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/data/hbase/meta/.tmp/.tableinfo.0000000001
2017-09-17 21:54:13,821 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_-210773990_1
2017-09-17 21:54:14,384 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:50010 for /hbase/WALs/localhost,42006,1505703251297/localhost%2C42006%2C1505703251297.default.1505703254367
2017-09-17 21:54:14,404 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/localhost,42006,1505703251297/localhost%2C42006%2C1505703251297.default.1505703254367 for DFSClient_NONMAPREDUCE_-210773990_1
2017-09-17 21:54:19,727 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:50010 for /hbase/WALs/localhost,42006,1505703251297/localhost%2C42006%2C1505703251297..meta.1505703259718.meta
2017-09-17 21:54:19,767 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/localhost,42006,1505703251297/localhost%2C42006%2C1505703251297..meta.1505703259718.meta for DFSClient_NONMAPREDUCE_-210773990_1
2017-09-17 21:54:19,851 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/recovered.edits/3.seqid is closed by DFSClient_NONMAPREDUCE_-210773990_1
2017-09-17 21:54:20,169 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:50010 for /hbase/MasterProcWALs/state-00000000000000000001.log
2017-09-17 21:54:20,209 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/MasterProcWALs/state-00000000000000000001.log for DFSClient_NONMAPREDUCE_-210773990_1
2017-09-17 21:54:20,437 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:50010 for /hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001
2017-09-17 21:54:20,478 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741832_1008 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001
2017-09-17 21:54:20,883 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_-210773990_1
2017-09-17 21:54:20,935 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:50010 for /hbase/.tmp/data/hbase/namespace/79989b40c9402aa9d6ca36b956c52c9a/.regioninfo
2017-09-17 21:54:20,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741833_1009 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/.tmp/data/hbase/namespace/79989b40c9402aa9d6ca36b956c52c9a/.regioninfo
2017-09-17 21:54:21,387 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/data/hbase/namespace/79989b40c9402aa9d6ca36b956c52c9a/.regioninfo is closed by DFSClient_NONMAPREDUCE_-210773990_1
2017-09-17 21:54:21,913 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/namespace/79989b40c9402aa9d6ca36b956c52c9a/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_-210773990_1
2017-09-17 21:54:44,335 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/MasterProcWALs/state-00000000000000000001.log is closed by DFSClient_NONMAPREDUCE_-210773990_1
2017-09-17 22:06:05,935 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-17 22:06:05,944 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-17 22:06:05,951 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-17 22:06:06,217 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-17 22:06:06,337 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-17 22:06:06,337 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-17 22:06:06,355 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-17 22:06:06,357 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-17 22:06:06,446 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-17 22:06:06,592 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-17 22:06:06,611 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-17 22:06:06,662 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-17 22:06:06,669 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-17 22:06:06,673 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-17 22:06:06,678 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-17 22:06:06,680 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-17 22:06:06,680 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-17 22:06:06,680 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-17 22:06:06,788 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-17 22:06:06,791 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-17 22:06:06,809 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-17 22:06:06,809 INFO org.mortbay.log: jetty-6.1.26
2017-09-17 22:06:07,030 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-17 22:06:07,095 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-17 22:06:07,095 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-17 22:06:07,135 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-17 22:06:07,141 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-17 22:06:07,142 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-17 22:06:07,143 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-17 22:06:07,174 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-17 22:06:07,174 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-17 22:06:07,175 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-17 22:06:07,175 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 17 22:06:07
2017-09-17 22:06:07,176 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-17 22:06:07,176 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-17 22:06:07,177 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-17 22:06:07,178 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-17 22:06:07,193 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-17 22:06:07,195 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-17 22:06:07,195 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-17 22:06:07,195 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-17 22:06:07,195 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-17 22:06:07,195 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-17 22:06:07,195 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-17 22:06:07,195 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-17 22:06:07,200 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-17 22:06:07,200 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-17 22:06:07,200 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-17 22:06:07,200 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-17 22:06:07,201 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-17 22:06:07,260 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-17 22:06:07,260 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-17 22:06:07,260 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-17 22:06:07,260 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-17 22:06:07,261 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-17 22:06:07,261 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-17 22:06:07,262 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-17 22:06:07,271 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-17 22:06:07,272 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-17 22:06:07,272 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-17 22:06:07,272 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-17 22:06:07,273 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-17 22:06:07,273 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-17 22:06:07,273 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-17 22:06:07,277 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-17 22:06:07,277 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-17 22:06:07,277 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-17 22:06:07,282 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-17 22:06:07,282 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-17 22:06:07,284 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-17 22:06:07,284 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-17 22:06:07,284 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-17 22:06:07,284 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-17 22:06:07,453 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 2971@localhost
2017-09-17 22:06:07,471 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-17 22:06:07,495 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000013 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000013-0000000000000000098
2017-09-17 22:06:07,499 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000012, cpktTxId=0000000000000000012)
2017-09-17 22:06:07,530 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 3 INodes.
2017-09-17 22:06:07,548 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-17 22:06:07,548 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 12 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000012
2017-09-17 22:06:07,548 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@20f12539 expecting start txid #13
2017-09-17 22:06:07,548 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000013-0000000000000000098
2017-09-17 22:06:07,549 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000013-0000000000000000098' to transaction ID 13
2017-09-17 22:06:07,608 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000013-0000000000000000098 of size 1048576 edits # 86 loaded in 0 seconds
2017-09-17 22:06:07,608 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-09-17 22:06:07,609 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 99
2017-09-17 22:06:07,697 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-17 22:06:07,697 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 410 msecs
2017-09-17 22:06:07,825 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-17 22:06:07,829 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-17 22:06:07,837 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-17 22:06:07,901 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-17 22:06:07,909 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 2
2017-09-17 22:06:07,910 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 5 blocks to reach the threshold 0.9990 of total blocks 6.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-17 22:06:07,939 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-17 22:06:07,941 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-17 22:06:07,945 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-17 22:06:07,948 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-17 22:06:07,948 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-17 22:06:07,954 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 6 milliseconds
name space=37
storage space=268436289
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-17 22:06:07,958 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-17 22:06:16,667 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-17 22:06:16,667 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-17 22:06:16,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-17 22:06:16,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-17 22:06:16,834 INFO BlockStateChange: BLOCK* processReport 0x8e9b4956303fa4ed: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-17 22:06:16,839 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 5 has reached the threshold 0.9990 of total blocks 6. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2017-09-17 22:06:16,839 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2017-09-17 22:06:16,841 INFO BlockStateChange: BLOCK* processReport 0x8e9b4956303fa4ed: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 8, hasStaleStorage: false, processing time: 20 msecs, invalidatedBlocks: 0
2017-09-17 22:06:16,842 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 8
2017-09-17 22:06:16,842 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-17 22:06:16,842 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2017-09-17 22:06:16,842 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-17 22:06:16,842 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 2
2017-09-17 22:06:16,843 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 3 msec
2017-09-17 22:06:36,852 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 6 has reached the threshold 0.9990 of total blocks 6. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2017-09-17 22:06:46,857 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 39 secs
2017-09-17 22:06:46,857 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2017-09-17 22:06:46,858 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2017-09-17 22:06:46,858 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-17 22:10:05,696 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-17 22:10:05,698 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1
************************************************************/
2017-09-17 22:10:45,820 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-17 22:10:45,827 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-17 22:10:45,835 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-17 22:10:46,066 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-17 22:10:46,135 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-17 22:10:46,135 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-17 22:10:46,149 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-17 22:10:46,152 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-17 22:10:46,235 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-17 22:10:46,351 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-17 22:10:46,365 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-17 22:10:46,408 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-17 22:10:46,417 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-17 22:10:46,422 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-17 22:10:46,427 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-17 22:10:46,429 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-17 22:10:46,429 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-17 22:10:46,429 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-17 22:10:46,525 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-17 22:10:46,527 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-17 22:10:46,539 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-17 22:10:46,539 INFO org.mortbay.log: jetty-6.1.26
2017-09-17 22:10:46,657 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-17 22:10:46,675 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-17 22:10:46,676 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-17 22:10:46,702 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-17 22:10:46,707 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-17 22:10:46,707 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-17 22:10:46,709 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-17 22:10:46,735 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-17 22:10:46,735 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-17 22:10:46,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-17 22:10:46,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 17 22:10:46
2017-09-17 22:10:46,737 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-17 22:10:46,737 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-17 22:10:46,738 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-17 22:10:46,738 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-17 22:10:46,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-17 22:10:46,752 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-17 22:10:46,752 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-17 22:10:46,752 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-17 22:10:46,752 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-17 22:10:46,752 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-17 22:10:46,752 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-17 22:10:46,752 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-17 22:10:46,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-17 22:10:46,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-17 22:10:46,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-17 22:10:46,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-17 22:10:46,758 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-17 22:10:46,806 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-17 22:10:46,806 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-17 22:10:46,806 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-17 22:10:46,806 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-17 22:10:46,807 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-17 22:10:46,807 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-17 22:10:46,807 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-17 22:10:46,816 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-17 22:10:46,816 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-17 22:10:46,816 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-17 22:10:46,817 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-17 22:10:46,818 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-17 22:10:46,818 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-17 22:10:46,818 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-17 22:10:46,823 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-17 22:10:46,823 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-17 22:10:46,823 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-17 22:10:46,827 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-17 22:10:46,827 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-17 22:10:46,829 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-17 22:10:46,830 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-17 22:10:46,830 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-17 22:10:46,830 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-17 22:10:46,902 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 4080@localhost
2017-09-17 22:10:46,918 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-17 22:10:46,941 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000099 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000099-0000000000000000099
2017-09-17 22:10:46,946 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000012, cpktTxId=0000000000000000012)
2017-09-17 22:10:46,973 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 3 INodes.
2017-09-17 22:10:46,991 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-17 22:10:46,991 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 12 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000012
2017-09-17 22:10:46,991 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@77a98a6a expecting start txid #13
2017-09-17 22:10:46,991 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000013-0000000000000000098
2017-09-17 22:10:46,992 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000013-0000000000000000098' to transaction ID 13
2017-09-17 22:10:47,046 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000013-0000000000000000098 of size 1048576 edits # 86 loaded in 0 seconds
2017-09-17 22:10:47,046 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@78fbff54 expecting start txid #99
2017-09-17 22:10:47,046 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000099-0000000000000000099
2017-09-17 22:10:47,046 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000099-0000000000000000099' to transaction ID 13
2017-09-17 22:10:47,047 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000099-0000000000000000099 of size 1048576 edits # 1 loaded in 0 seconds
2017-09-17 22:10:47,047 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-09-17 22:10:47,047 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 100
2017-09-17 22:10:47,126 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-17 22:10:47,126 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 293 msecs
2017-09-17 22:10:47,241 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-17 22:10:47,246 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-17 22:10:47,255 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-17 22:10:47,298 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-17 22:10:47,304 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 2
2017-09-17 22:10:47,304 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 5 blocks to reach the threshold 0.9990 of total blocks 6.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-17 22:10:47,329 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-17 22:10:47,329 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-17 22:10:47,331 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-17 22:10:47,333 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-17 22:10:47,334 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-17 22:10:47,338 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 4 milliseconds
name space=37
storage space=268436289
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-17 22:10:47,343 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-17 22:10:51,931 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-17 22:10:51,931 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-17 22:10:51,932 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-17 22:10:51,975 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-17 22:10:52,025 INFO BlockStateChange: BLOCK* processReport 0x528d06e947be4496: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-17 22:10:52,035 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 5 has reached the threshold 0.9990 of total blocks 6. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2017-09-17 22:10:52,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2017-09-17 22:10:52,036 INFO BlockStateChange: BLOCK* processReport 0x528d06e947be4496: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 8, hasStaleStorage: false, processing time: 11 msecs, invalidatedBlocks: 0
2017-09-17 22:10:52,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 8
2017-09-17 22:10:52,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-17 22:10:52,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2017-09-17 22:10:52,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-17 22:10:52,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 2
2017-09-17 22:10:52,038 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 3 msec
2017-09-17 22:11:12,048 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 6 has reached the threshold 0.9990 of total blocks 6. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2017-09-17 22:11:22,068 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 35 secs
2017-09-17 22:11:22,068 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2017-09-17 22:11:22,069 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2017-09-17 22:11:22,069 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-17 22:13:41,413 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 18693ms
No GCs detected
2017-09-17 22:13:58,687 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 99 Number of syncs: 2 SyncTimes(ms): 7 
2017-09-17 22:13:58,925 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: recoverLease: [Lease.  Holder: DFSClient_NONMAPREDUCE_-210773990_1, pending creates: 3], src=/hbase/MasterProcWALs/state-00000000000000000002.log from client DFSClient_NONMAPREDUCE_-210773990_1
2017-09-17 22:13:58,925 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_-210773990_1, pending creates: 3], src=/hbase/MasterProcWALs/state-00000000000000000002.log
2017-09-17 22:13:58,927 WARN org.apache.hadoop.hdfs.StateChange: BLOCK* internalReleaseLease: All existing blocks are COMPLETE, lease removed, file /hbase/MasterProcWALs/state-00000000000000000002.log closed.
2017-09-17 22:14:01,571 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:50010 for /hbase/WALs/localhost,33338,1505704430927/localhost%2C33338%2C1505704430927.default.1505704441538
2017-09-17 22:14:01,736 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/localhost,33338,1505704430927/localhost%2C33338%2C1505704430927.default.1505704441538 for DFSClient_NONMAPREDUCE_-137504307_1
2017-09-17 22:14:03,640 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: recoverLease: [Lease.  Holder: DFSClient_NONMAPREDUCE_-210773990_1, pending creates: 2], src=/hbase/WALs/localhost,42006,1505703251297-splitting/localhost%2C42006%2C1505703251297..meta.1505703259718.meta from client DFSClient_NONMAPREDUCE_-210773990_1
2017-09-17 22:14:03,640 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_-210773990_1, pending creates: 2], src=/hbase/WALs/localhost,42006,1505703251297-splitting/localhost%2C42006%2C1505703251297..meta.1505703259718.meta
2017-09-17 22:14:03,641 WARN org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.internalReleaseLease: File /hbase/WALs/localhost,42006,1505703251297-splitting/localhost%2C42006%2C1505703251297..meta.1505703259718.meta has not been closed. Lease recovery is in progress. RecoveryId = 1011 for block blk_1073741830_1006
2017-09-17 22:14:05,997 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-896759491-127.0.0.1-1505591284841:blk_1073741830_1006, newgenerationstamp=1011, newlength=956, newtargets=[127.0.0.1:50010], closeFile=true, deleteBlock=false)
2017-09-17 22:14:06,001 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-896759491-127.0.0.1-1505591284841:blk_1073741830_1006, file=/hbase/WALs/localhost,42006,1505703251297-splitting/localhost%2C42006%2C1505703251297..meta.1505703259718.meta, newgenerationstamp=1011, newlength=956, newtargets=[127.0.0.1:50010]) successful
2017-09-17 22:14:07,879 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1012, replicas=127.0.0.1:50010 for /hbase/data/hbase/meta/1588230740/recovered.edits/0000000000000000005.temp
2017-09-17 22:14:07,909 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/recovered.edits/0000000000000000005.temp is closed by DFSClient_NONMAPREDUCE_-137504307_1
2017-09-17 22:14:07,972 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9000, call Call#77 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 127.0.0.1:50556
org.apache.hadoop.fs.PathIsNotEmptyDirectoryException: `/hbase/WALs/localhost,42006,1505703251297-splitting is non empty': Directory is not empty
	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:115)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2783)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1047)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:626)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:845)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:788)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2455)
2017-09-17 22:14:08,000 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9000, call Call#84 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 127.0.0.1:50556
org.apache.hadoop.fs.PathIsNotEmptyDirectoryException: `/hbase/WALs/localhost,42006,1505703251297-splitting is non empty': Directory is not empty
	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:115)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2783)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1047)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:626)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:845)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:788)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2455)
2017-09-17 22:14:08,057 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1013, replicas=127.0.0.1:50010 for /hbase/WALs/localhost,33338,1505704430927/localhost%2C33338%2C1505704430927..meta.1505704448050.meta
2017-09-17 22:14:08,086 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/localhost,33338,1505704430927/localhost%2C33338%2C1505704430927..meta.1505704448050.meta for DFSClient_NONMAPREDUCE_-137504307_1
2017-09-17 22:14:08,477 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1014, replicas=127.0.0.1:50010 for /hbase/data/hbase/meta/1588230740/.tmp/5187d793f9244ecd9072af58cb36f372
2017-09-17 22:14:08,519 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741837_1014 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/data/hbase/meta/1588230740/.tmp/5187d793f9244ecd9072af58cb36f372
2017-09-17 22:14:08,924 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/.tmp/5187d793f9244ecd9072af58cb36f372 is closed by DFSClient_NONMAPREDUCE_-137504307_1
2017-09-17 22:14:09,083 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/recovered.edits/7.seqid is closed by DFSClient_NONMAPREDUCE_-137504307_1
2017-09-17 22:14:09,381 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1015, replicas=127.0.0.1:50010 for /hbase/MasterProcWALs/state-00000000000000000003.log
2017-09-17 22:14:09,445 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/MasterProcWALs/state-00000000000000000003.log for DFSClient_NONMAPREDUCE_-137504307_1
2017-09-17 22:14:09,838 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: recoverLease: [Lease.  Holder: DFSClient_NONMAPREDUCE_-210773990_1, pending creates: 1], src=/hbase/WALs/localhost,42006,1505703251297-splitting/localhost%2C42006%2C1505703251297.default.1505703254367 from client DFSClient_NONMAPREDUCE_-210773990_1
2017-09-17 22:14:09,838 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_-210773990_1, pending creates: 1], src=/hbase/WALs/localhost,42006,1505703251297-splitting/localhost%2C42006%2C1505703251297.default.1505703254367
2017-09-17 22:14:09,838 WARN org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.internalReleaseLease: File /hbase/WALs/localhost,42006,1505703251297-splitting/localhost%2C42006%2C1505703251297.default.1505703254367 has not been closed. Lease recovery is in progress. RecoveryId = 1016 for block blk_1073741829_1005
2017-09-17 22:14:11,993 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-896759491-127.0.0.1-1505591284841:blk_1073741829_1005, newgenerationstamp=1016, newlength=571, newtargets=[127.0.0.1:50010], closeFile=true, deleteBlock=false)
2017-09-17 22:14:11,995 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-896759491-127.0.0.1-1505591284841:blk_1073741829_1005, file=/hbase/WALs/localhost,42006,1505703251297-splitting/localhost%2C42006%2C1505703251297.default.1505703254367, newgenerationstamp=1016, newlength=571, newtargets=[127.0.0.1:50010]) successful
2017-09-17 22:14:13,921 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1017, replicas=127.0.0.1:50010 for /hbase/data/hbase/namespace/79989b40c9402aa9d6ca36b956c52c9a/recovered.edits/0000000000000000004.temp
2017-09-17 22:14:13,939 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741839_1017 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/data/hbase/namespace/79989b40c9402aa9d6ca36b956c52c9a/recovered.edits/0000000000000000004.temp
2017-09-17 22:14:14,344 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/namespace/79989b40c9402aa9d6ca36b956c52c9a/recovered.edits/0000000000000000004.temp is closed by DFSClient_NONMAPREDUCE_-137504307_1
2017-09-17 22:14:14,657 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1018, replicas=127.0.0.1:50010 for /hbase/data/hbase/namespace/79989b40c9402aa9d6ca36b956c52c9a/.tmp/e0be397ef80240d796568f58fd05a7be
2017-09-17 22:14:14,672 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/namespace/79989b40c9402aa9d6ca36b956c52c9a/.tmp/e0be397ef80240d796568f58fd05a7be is closed by DFSClient_NONMAPREDUCE_-137504307_1
2017-09-17 22:14:14,731 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/namespace/79989b40c9402aa9d6ca36b956c52c9a/recovered.edits/6.seqid is closed by DFSClient_NONMAPREDUCE_-137504307_1
2017-09-17 22:14:29,119 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741838_1015 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/MasterProcWALs/state-00000000000000000003.log
2017-09-17 22:14:29,523 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/MasterProcWALs/state-00000000000000000003.log is closed by DFSClient_NONMAPREDUCE_-137504307_1
2017-09-17 22:15:04,955 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1019, replicas=127.0.0.1:50010 for /hbase/MasterProcWALs/state-00000000000000000004.log
2017-09-17 22:15:04,956 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 76 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 115 Number of syncs: 58 SyncTimes(ms): 56 
2017-09-17 22:15:04,975 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741841_1019 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/MasterProcWALs/state-00000000000000000004.log
2017-09-17 22:15:05,153 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/namespace/79989b40c9402aa9d6ca36b956c52c9a/recovered.edits/8.seqid is closed by DFSClient_NONMAPREDUCE_-137504307_1
2017-09-17 22:15:05,379 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/MasterProcWALs/state-00000000000000000004.log is closed by DFSClient_NONMAPREDUCE_-137504307_1
2017-09-17 22:15:11,279 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1020, replicas=127.0.0.1:50010 for /hbase/data/hbase/meta/1588230740/.tmp/34a06669265345f2b16d2a19662ff46d
2017-09-17 22:15:11,290 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741842_1020 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/data/hbase/meta/1588230740/.tmp/34a06669265345f2b16d2a19662ff46d
2017-09-17 22:15:11,692 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/.tmp/34a06669265345f2b16d2a19662ff46d is closed by DFSClient_NONMAPREDUCE_-137504307_1
2017-09-17 22:15:11,753 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/recovered.edits/14.seqid is closed by DFSClient_NONMAPREDUCE_-137504307_1
2017-09-17 22:15:11,866 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741836_1013 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/WALs/localhost,33338,1505704430927/localhost%2C33338%2C1505704430927..meta.1505704448050.meta
2017-09-17 22:15:12,271 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/WALs/localhost,33338,1505704430927/localhost%2C33338%2C1505704430927..meta.1505704448050.meta is closed by DFSClient_NONMAPREDUCE_-137504307_1
2017-09-17 22:15:12,301 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741834_1010 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/WALs/localhost,33338,1505704430927/localhost%2C33338%2C1505704430927.default.1505704441538
2017-09-17 22:15:12,707 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/WALs/localhost,33338,1505704430927/localhost%2C33338%2C1505704430927.default.1505704441538 is closed by DFSClient_NONMAPREDUCE_-137504307_1
2017-09-17 22:15:44,291 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-17 22:15:44,292 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1
************************************************************/
2017-09-23 22:08:24,960 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-23 22:08:24,969 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-23 22:08:24,978 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-23 22:08:25,377 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-23 22:08:25,995 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-23 22:08:25,995 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-23 22:08:26,031 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-23 22:08:26,036 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-23 22:08:26,157 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-23 22:08:26,366 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-23 22:08:26,389 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-23 22:08:26,438 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-23 22:08:26,445 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-23 22:08:26,450 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-23 22:08:26,455 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-23 22:08:26,457 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-23 22:08:26,457 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-23 22:08:26,457 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-23 22:08:26,586 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-23 22:08:26,594 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-23 22:08:26,621 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-23 22:08:26,622 INFO org.mortbay.log: jetty-6.1.26
2017-09-23 22:08:27,354 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-23 22:08:27,913 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-23 22:08:27,913 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-23 22:08:28,098 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-23 22:08:28,112 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-23 22:08:28,113 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-23 22:08:28,116 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-23 22:08:28,152 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-23 22:08:28,152 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-23 22:08:28,154 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-23 22:08:28,154 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 23 22:08:28
2017-09-23 22:08:28,156 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-23 22:08:28,156 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-23 22:08:28,157 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-23 22:08:28,157 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-23 22:08:28,175 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-23 22:08:28,177 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-23 22:08:28,177 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-23 22:08:28,177 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-23 22:08:28,177 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-23 22:08:28,177 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-23 22:08:28,177 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-23 22:08:28,178 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-23 22:08:28,183 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-23 22:08:28,183 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-23 22:08:28,183 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-23 22:08:28,183 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-23 22:08:28,184 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-23 22:08:28,248 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-23 22:08:28,248 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-23 22:08:28,248 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-23 22:08:28,249 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-23 22:08:28,249 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-23 22:08:28,249 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-23 22:08:28,250 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-23 22:08:28,258 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-23 22:08:28,259 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-23 22:08:28,259 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-23 22:08:28,259 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-23 22:08:28,261 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-23 22:08:28,261 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-23 22:08:28,261 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-23 22:08:28,269 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-23 22:08:28,270 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-23 22:08:28,270 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-23 22:08:28,275 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-23 22:08:28,276 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-23 22:08:28,279 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-23 22:08:28,279 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-23 22:08:28,279 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-23 22:08:28,279 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-23 22:08:28,967 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 3314@localhost
2017-09-23 22:08:28,992 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-23 22:08:29,025 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000100 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000100-0000000000000000195
2017-09-23 22:08:29,033 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000012, cpktTxId=0000000000000000012)
2017-09-23 22:08:29,077 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 3 INodes.
2017-09-23 22:08:29,107 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-23 22:08:29,108 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 12 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000012
2017-09-23 22:08:29,108 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@77a98a6a expecting start txid #13
2017-09-23 22:08:29,108 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000013-0000000000000000098
2017-09-23 22:08:29,110 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000013-0000000000000000098' to transaction ID 13
2017-09-23 22:08:29,219 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000013-0000000000000000098 of size 1048576 edits # 86 loaded in 0 seconds
2017-09-23 22:08:29,219 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@78fbff54 expecting start txid #99
2017-09-23 22:08:29,219 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000099-0000000000000000099
2017-09-23 22:08:29,219 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000099-0000000000000000099' to transaction ID 13
2017-09-23 22:08:29,243 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000099-0000000000000000099 of size 1048576 edits # 1 loaded in 0 seconds
2017-09-23 22:08:29,243 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3e10dc6 expecting start txid #100
2017-09-23 22:08:29,243 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000100-0000000000000000195
2017-09-23 22:08:29,243 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000100-0000000000000000195' to transaction ID 13
2017-09-23 22:08:29,260 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000100-0000000000000000195 of size 1048576 edits # 96 loaded in 0 seconds
2017-09-23 22:08:29,260 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2017-09-23 22:08:29,260 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2017-09-23 22:08:29,266 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/raji/hadoop_store/hdfs/namenode/current/fsimage.ckpt_0000000000000000195 using no compression
2017-09-23 22:08:29,317 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/raji/hadoop_store/hdfs/namenode/current/fsimage.ckpt_0000000000000000195 of size 3362 bytes saved in 0 seconds.
2017-09-23 22:08:29,330 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 12
2017-09-23 22:08:29,330 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000011, cpktTxId=0000000000000000011)
2017-09-23 22:08:29,342 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 196
2017-09-23 22:08:29,464 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem write lock held for 1181 ms via
java.lang.Thread.getStackTrace(Thread.java:1559)
org.apache.hadoop.util.StringUtils.getStackTrace(StringUtils.java:1032)
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:233)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.writeUnlock(FSNamesystem.java:1537)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1041)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:691)
org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:634)
org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:695)
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:898)
org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:877)
org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1603)
org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1671)
	Number of suppressed write-lock reports: 0
	Longest write-lock held interval: 1181
2017-09-23 22:08:29,464 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-23 22:08:29,465 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1182 msecs
2017-09-23 22:08:29,716 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-23 22:08:29,727 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-23 22:08:29,748 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-23 22:08:29,871 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-23 22:08:29,885 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-23 22:08:29,886 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 13 blocks to reach the threshold 0.9990 of total blocks 14.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-23 22:08:29,927 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-23 22:08:29,930 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-23 22:08:30,030 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-23 22:08:30,035 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-23 22:08:30,036 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-23 22:08:30,066 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 30 milliseconds
name space=42
storage space=19986
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-23 22:08:30,100 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-23 22:08:34,045 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-23 22:08:34,046 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-23 22:08:34,046 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-23 22:08:34,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-23 22:08:34,458 INFO BlockStateChange: BLOCK* processReport 0xd57eba3e1bb1052c: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-23 22:08:34,463 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 13 has reached the threshold 0.9990 of total blocks 14. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2017-09-23 22:08:34,463 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2017-09-23 22:08:34,526 INFO BlockStateChange: BLOCK* processReport 0xd57eba3e1bb1052c: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 14, hasStaleStorage: false, processing time: 68 msecs, invalidatedBlocks: 0
2017-09-23 22:08:34,527 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 14
2017-09-23 22:08:34,528 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-23 22:08:34,528 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2017-09-23 22:08:34,528 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-23 22:08:34,528 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-09-23 22:08:34,528 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 4 msec
2017-09-23 22:08:54,541 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 14 has reached the threshold 0.9990 of total blocks 14. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2017-09-23 22:09:04,569 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 36 secs
2017-09-23 22:09:04,569 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2017-09-23 22:09:04,570 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2017-09-23 22:09:04,570 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-23 22:09:43,696 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1013ms
No GCs detected
2017-09-23 22:10:52,760 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 195 Number of syncs: 2 SyncTimes(ms): 14 
2017-09-23 22:10:53,450 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1021, replicas=127.0.0.1:50010 for /hbase/WALs/localhost,38399,1506222651827/localhost%2C38399%2C1506222651827.default.1506222653386
2017-09-23 22:10:53,635 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/localhost,38399,1506222651827/localhost%2C38399%2C1506222651827.default.1506222653386 for DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:10:57,971 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1022, replicas=127.0.0.1:50010 for /hbase/WALs/localhost,38399,1506222651827/localhost%2C38399%2C1506222651827..meta.1506222657957.meta
2017-09-23 22:10:57,984 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/localhost,38399,1506222651827/localhost%2C38399%2C1506222651827..meta.1506222657957.meta for DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:10:58,395 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/recovered.edits/15.seqid is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:10:58,831 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/namespace/79989b40c9402aa9d6ca36b956c52c9a/recovered.edits/9.seqid is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:11:53,313 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 33 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 205 Number of syncs: 23 SyncTimes(ms): 32 
2017-09-23 22:13:23,280 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1023, replicas=127.0.0.1:50010 for /hbase/MasterProcWALs/state-00000000000000000005.log
2017-09-23 22:13:23,281 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 39 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 205 Number of syncs: 27 SyncTimes(ms): 39 
2017-09-23 22:13:23,323 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/MasterProcWALs/state-00000000000000000005.log for DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:13:23,662 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1024, replicas=127.0.0.1:50010 for /hbase/.tmp/data/default/webtable/.tmp/.tableinfo.0000000001
2017-09-23 22:13:23,705 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/data/default/webtable/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:13:23,722 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1025, replicas=127.0.0.1:50010 for /hbase/.tmp/data/default/webtable/fd8572ca7dc2c3def9da44a199cb9ad0/.regioninfo
2017-09-23 22:13:23,746 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741847_1025 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/.tmp/data/default/webtable/fd8572ca7dc2c3def9da44a199cb9ad0/.regioninfo
2017-09-23 22:13:24,150 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/data/default/webtable/fd8572ca7dc2c3def9da44a199cb9ad0/.regioninfo is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:13:24,691 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/default/webtable/fd8572ca7dc2c3def9da44a199cb9ad0/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:18:20,296 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 65 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 216 Number of syncs: 44 SyncTimes(ms): 67 
2017-09-23 22:18:20,338 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1026, replicas=127.0.0.1:50010 for /hbase/data/hbase/meta/1588230740/.tmp/827f21e39bd340cebd4ef6eb510fcac5
2017-09-23 22:18:20,352 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/.tmp/827f21e39bd340cebd4ef6eb510fcac5 is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:18:20,588 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1027, replicas=127.0.0.1:50010 for /hbase/data/hbase/meta/1588230740/.tmp/92add5b34cd4421abf88b967facf713c
2017-09-23 22:18:20,612 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741849_1027 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/data/hbase/meta/1588230740/.tmp/92add5b34cd4421abf88b967facf713c
2017-09-23 22:18:21,018 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/.tmp/92add5b34cd4421abf88b967facf713c is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:18:53,340 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741845_1023 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/MasterProcWALs/state-00000000000000000005.log
2017-09-23 22:18:53,744 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/MasterProcWALs/state-00000000000000000005.log is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:22:33,720 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1028, replicas=127.0.0.1:50010 for /hbase/MasterProcWALs/state-00000000000000000006.log
2017-09-23 22:22:33,721 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 95 Total time for transactions(ms): 14 Number of transactions batched in Syncs: 225 Number of syncs: 63 SyncTimes(ms): 91 
2017-09-23 22:22:33,764 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/MasterProcWALs/state-00000000000000000006.log for DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:22:33,970 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1029, replicas=127.0.0.1:50010 for /hbase/.tmp/data/default/people/.tmp/.tableinfo.0000000001
2017-09-23 22:22:34,006 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741851_1029 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/.tmp/data/default/people/.tmp/.tableinfo.0000000001
2017-09-23 22:22:34,417 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/data/default/people/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:22:34,478 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1030, replicas=127.0.0.1:50010 for /hbase/.tmp/data/default/people/63bda68d7e5c60de8c37e4e6b35b0423/.regioninfo
2017-09-23 22:22:34,515 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741852_1030 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/.tmp/data/default/people/63bda68d7e5c60de8c37e4e6b35b0423/.regioninfo
2017-09-23 22:22:34,922 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/data/default/people/63bda68d7e5c60de8c37e4e6b35b0423/.regioninfo is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:22:35,374 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/default/people/63bda68d7e5c60de8c37e4e6b35b0423/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:23:53,291 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 119 Total time for transactions(ms): 20 Number of transactions batched in Syncs: 234 Number of syncs: 80 SyncTimes(ms): 126 
2017-09-23 22:27:48,122 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 127 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 234 Number of syncs: 88 SyncTimes(ms): 142 
2017-09-23 22:27:48,144 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1031, replicas=127.0.0.1:50010 for /hbase/data/hbase/meta/1588230740/.tmp/1a4541c8998148bfbf27ef564ab1774c
2017-09-23 22:27:48,176 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741853_1031 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/data/hbase/meta/1588230740/.tmp/1a4541c8998148bfbf27ef564ab1774c
2017-09-23 22:27:48,581 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/.tmp/1a4541c8998148bfbf27ef564ab1774c is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:27:53,919 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/MasterProcWALs/state-00000000000000000006.log is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:31:49,727 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1032, replicas=127.0.0.1:50010 for /hbase/MasterProcWALs/state-00000000000000000007.log
2017-09-23 22:31:49,728 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 138 Total time for transactions(ms): 23 Number of transactions batched in Syncs: 236 Number of syncs: 95 SyncTimes(ms): 158 
2017-09-23 22:31:49,763 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/MasterProcWALs/state-00000000000000000007.log for DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:31:50,362 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1033, replicas=127.0.0.1:50010 for /hbase/data/default/webtable/fd8572ca7dc2c3def9da44a199cb9ad0/.tmp/5b1f588dacec42fb9035e40e70cef075
2017-09-23 22:31:50,385 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/default/webtable/fd8572ca7dc2c3def9da44a199cb9ad0/.tmp/5b1f588dacec42fb9035e40e70cef075 is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:31:50,502 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/default/webtable/fd8572ca7dc2c3def9da44a199cb9ad0/recovered.edits/10.seqid is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:37:53,300 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 163 Total time for transactions(ms): 27 Number of transactions batched in Syncs: 243 Number of syncs: 115 SyncTimes(ms): 184 
2017-09-23 22:37:54,193 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/MasterProcWALs/state-00000000000000000007.log is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:40:49,163 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 174 Total time for transactions(ms): 30 Number of transactions batched in Syncs: 243 Number of syncs: 126 SyncTimes(ms): 202 
2017-09-23 22:40:49,209 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1034, replicas=127.0.0.1:50010 for /hbase/data/hbase/meta/1588230740/.tmp/22bb1af81e4f47a7a981f7d67dda0153
2017-09-23 22:40:49,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741856_1034 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/data/hbase/meta/1588230740/.tmp/22bb1af81e4f47a7a981f7d67dda0153
2017-09-23 22:40:49,635 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/.tmp/22bb1af81e4f47a7a981f7d67dda0153 is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:40:49,829 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741857_1035, replicas=127.0.0.1:50010 for /hbase/data/hbase/meta/1588230740/.tmp/b1512979028e4276a1f50c1d3e413377
2017-09-23 22:40:49,843 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741857_1035 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /hbase/data/hbase/meta/1588230740/.tmp/b1512979028e4276a1f50c1d3e413377
2017-09-23 22:40:50,250 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/.tmp/b1512979028e4276a1f50c1d3e413377 is closed by DFSClient_NONMAPREDUCE_-212409849_1
2017-09-23 22:45:53,275 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 197 Total time for transactions(ms): 34 Number of transactions batched in Syncs: 251 Number of syncs: 141 SyncTimes(ms): 226 
2017-09-23 22:48:40,635 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-23 22:48:40,635 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-23 22:48:40,635 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 196, 399
2017-09-23 22:48:40,635 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=400 lastSyncedTxid=399 mostRecentTxid=400
2017-09-23 22:48:40,635 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 205 Total time for transactions(ms): 36 Number of transactions batched in Syncs: 251 Number of syncs: 149 SyncTimes(ms): 234 
2017-09-23 22:48:40,640 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=400 lastSyncedTxid=400 mostRecentTxid=400
2017-09-23 22:48:40,640 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 205 Total time for transactions(ms): 36 Number of transactions batched in Syncs: 251 Number of syncs: 150 SyncTimes(ms): 238 
2017-09-23 22:48:40,646 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000196 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000196-0000000000000000400
2017-09-23 22:48:40,647 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 401
2017-09-23 22:48:42,136 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2000.00 KB/s
2017-09-23 22:48:42,137 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000400 size 4373 bytes.
2017-09-23 22:48:42,140 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 195
2017-09-23 22:48:42,140 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000012, cpktTxId=0000000000000000012)
2017-09-28 17:59:33,186 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-28 17:59:33,198 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-28 17:59:33,206 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-28 17:59:33,488 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-28 17:59:33,613 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-28 17:59:33,613 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-28 17:59:33,631 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-28 17:59:33,634 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-28 17:59:33,728 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-28 17:59:33,872 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-28 17:59:33,895 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-28 17:59:33,943 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-28 17:59:33,953 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-28 17:59:33,960 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-28 17:59:33,967 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-28 17:59:33,968 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-28 17:59:33,968 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-28 17:59:33,969 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-28 17:59:34,086 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-28 17:59:34,088 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-28 17:59:34,105 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-28 17:59:34,106 INFO org.mortbay.log: jetty-6.1.26
2017-09-28 17:59:34,327 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-28 17:59:34,398 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-28 17:59:34,398 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-28 17:59:34,437 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-28 17:59:34,443 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-28 17:59:34,444 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-28 17:59:34,445 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-28 17:59:34,478 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-28 17:59:34,478 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-28 17:59:34,479 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-28 17:59:34,479 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 28 17:59:34
2017-09-28 17:59:34,480 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-28 17:59:34,480 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-28 17:59:34,482 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-28 17:59:34,482 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-28 17:59:34,499 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-28 17:59:34,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-28 17:59:34,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-28 17:59:34,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-28 17:59:34,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-28 17:59:34,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-28 17:59:34,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-28 17:59:34,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-28 17:59:34,504 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-28 17:59:34,504 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-28 17:59:34,504 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-28 17:59:34,504 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-28 17:59:34,505 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-28 17:59:34,561 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-28 17:59:34,561 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-28 17:59:34,561 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-28 17:59:34,561 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-28 17:59:34,561 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-28 17:59:34,562 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-28 17:59:34,562 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-28 17:59:34,568 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-28 17:59:34,568 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-28 17:59:34,568 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-28 17:59:34,568 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-28 17:59:34,570 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-28 17:59:34,570 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-28 17:59:34,570 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-28 17:59:34,574 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-28 17:59:34,574 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-28 17:59:34,574 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-28 17:59:34,578 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-28 17:59:34,579 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-28 17:59:34,581 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-28 17:59:34,581 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-28 17:59:34,581 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-28 17:59:34,581 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-28 17:59:34,728 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 3092@localhost
2017-09-28 17:59:34,746 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-28 17:59:34,778 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000401 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000401-0000000000000000401
2017-09-28 17:59:34,784 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000400, cpktTxId=0000000000000000400)
2017-09-28 17:59:34,818 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 53 INodes.
2017-09-28 17:59:34,854 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-28 17:59:34,854 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 400 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000400
2017-09-28 17:59:34,855 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@20f12539 expecting start txid #401
2017-09-28 17:59:34,855 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000401-0000000000000000401
2017-09-28 17:59:34,856 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000401-0000000000000000401' to transaction ID 401
2017-09-28 17:59:34,864 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000401-0000000000000000401 of size 1048576 edits # 1 loaded in 0 seconds
2017-09-28 17:59:34,865 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2017-09-28 17:59:34,865 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2017-09-28 17:59:34,868 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/raji/hadoop_store/hdfs/namenode/current/fsimage.ckpt_0000000000000000401 using no compression
2017-09-28 17:59:34,899 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/raji/hadoop_store/hdfs/namenode/current/fsimage.ckpt_0000000000000000401 of size 4373 bytes saved in 0 seconds.
2017-09-28 17:59:34,908 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 400
2017-09-28 17:59:34,908 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000195, cpktTxId=0000000000000000195)
2017-09-28 17:59:34,917 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 402
2017-09-28 17:59:34,999 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-28 17:59:34,999 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 415 msecs
2017-09-28 17:59:35,141 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-28 17:59:35,145 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-28 17:59:35,156 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-28 17:59:35,213 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-28 17:59:35,219 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 2
2017-09-28 17:59:35,219 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 9 blocks to reach the threshold 0.9990 of total blocks 10.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-28 17:59:35,246 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-28 17:59:35,247 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-28 17:59:35,251 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-28 17:59:35,255 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-28 17:59:35,255 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-28 17:59:35,267 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 12 milliseconds
name space=53
storage space=268448980
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-28 17:59:35,283 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-28 17:59:40,213 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-28 17:59:40,213 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-28 17:59:40,214 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-28 17:59:40,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-28 17:59:40,359 INFO BlockStateChange: BLOCK* processReport 0xf92c1e55fb3c812: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-28 17:59:40,365 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 9 has reached the threshold 0.9990 of total blocks 10. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2017-09-28 17:59:40,365 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2017-09-28 17:59:40,367 INFO BlockStateChange: BLOCK* processReport 0xf92c1e55fb3c812: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 12, hasStaleStorage: false, processing time: 18 msecs, invalidatedBlocks: 0
2017-09-28 17:59:40,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 12
2017-09-28 17:59:40,379 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-28 17:59:40,379 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2017-09-28 17:59:40,379 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-28 17:59:40,379 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 2
2017-09-28 17:59:40,379 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 11 msec
2017-09-28 18:00:00,391 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 10 has reached the threshold 0.9990 of total blocks 10. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2017-09-28 18:00:10,396 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 35 secs
2017-09-28 18:00:10,396 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2017-09-28 18:00:10,396 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2017-09-28 18:00:10,397 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-28 18:34:50,494 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 401 Number of syncs: 2 SyncTimes(ms): 6 
2017-09-28 18:38:53,653 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 401 Number of syncs: 3 SyncTimes(ms): 9 
2017-09-28 18:51:32,575 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-28 18:51:32,620 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1
************************************************************/
2017-09-28 22:12:32,657 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-28 22:12:32,667 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-28 22:12:32,676 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-28 22:12:32,977 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-28 22:12:33,101 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-28 22:12:33,101 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-28 22:12:33,118 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-28 22:12:33,121 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-28 22:12:33,214 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-28 22:12:33,373 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-28 22:12:33,401 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-28 22:12:33,447 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-28 22:12:33,456 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-28 22:12:33,464 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-28 22:12:33,469 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-28 22:12:33,471 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-28 22:12:33,471 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-28 22:12:33,471 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-28 22:12:33,576 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-28 22:12:33,579 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-28 22:12:33,607 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-28 22:12:33,608 INFO org.mortbay.log: jetty-6.1.26
2017-09-28 22:12:33,894 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-28 22:12:33,932 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-28 22:12:33,932 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-28 22:12:33,976 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-28 22:12:33,984 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-28 22:12:33,985 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-28 22:12:33,987 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-28 22:12:34,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-28 22:12:34,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-28 22:12:34,025 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-28 22:12:34,025 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 28 22:12:34
2017-09-28 22:12:34,027 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-28 22:12:34,027 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-28 22:12:34,028 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-28 22:12:34,029 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-28 22:12:34,048 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-28 22:12:34,050 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-28 22:12:34,050 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-28 22:12:34,050 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-28 22:12:34,050 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-28 22:12:34,050 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-28 22:12:34,050 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-28 22:12:34,050 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-28 22:12:34,055 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-28 22:12:34,055 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-28 22:12:34,055 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-28 22:12:34,055 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-28 22:12:34,056 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-28 22:12:34,120 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-28 22:12:34,120 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-28 22:12:34,120 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-28 22:12:34,120 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-28 22:12:34,121 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-28 22:12:34,121 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-28 22:12:34,121 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-28 22:12:34,128 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-28 22:12:34,128 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-28 22:12:34,128 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-28 22:12:34,128 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-28 22:12:34,129 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-28 22:12:34,129 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-28 22:12:34,129 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-28 22:12:34,133 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-28 22:12:34,133 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-28 22:12:34,133 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-28 22:12:34,138 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-28 22:12:34,138 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-28 22:12:34,141 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-28 22:12:34,141 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-28 22:12:34,141 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-28 22:12:34,141 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-28 22:12:34,289 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 3034@localhost
2017-09-28 22:12:34,305 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-28 22:12:34,329 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000402 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000402-0000000000000000406
2017-09-28 22:12:34,333 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000401, cpktTxId=0000000000000000401)
2017-09-28 22:12:34,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 53 INodes.
2017-09-28 22:12:34,398 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-28 22:12:34,398 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 401 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000401
2017-09-28 22:12:34,398 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@20f12539 expecting start txid #402
2017-09-28 22:12:34,398 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000402-0000000000000000406
2017-09-28 22:12:34,400 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000402-0000000000000000406' to transaction ID 402
2017-09-28 22:12:34,421 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000402-0000000000000000406 of size 1048576 edits # 5 loaded in 0 seconds
2017-09-28 22:12:34,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2017-09-28 22:12:34,421 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2017-09-28 22:12:34,426 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/raji/hadoop_store/hdfs/namenode/current/fsimage.ckpt_0000000000000000406 using no compression
2017-09-28 22:12:34,462 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/raji/hadoop_store/hdfs/namenode/current/fsimage.ckpt_0000000000000000406 of size 4614 bytes saved in 0 seconds.
2017-09-28 22:12:34,474 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 401
2017-09-28 22:12:34,474 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000400, cpktTxId=0000000000000000400)
2017-09-28 22:12:34,487 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 407
2017-09-28 22:12:34,577 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-28 22:12:34,578 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 433 msecs
2017-09-28 22:12:34,698 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-28 22:12:34,703 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-28 22:12:34,711 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-28 22:12:34,769 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-28 22:12:34,777 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 2
2017-09-28 22:12:34,777 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 9 blocks to reach the threshold 0.9990 of total blocks 10.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-28 22:12:34,811 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-28 22:12:34,811 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-28 22:12:34,816 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-28 22:12:34,820 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-28 22:12:34,820 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-28 22:12:34,826 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 6 milliseconds
name space=57
storage space=268448980
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-28 22:12:34,844 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-28 22:12:39,842 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-28 22:12:39,843 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-28 22:12:39,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-28 22:12:39,918 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-28 22:12:39,974 INFO BlockStateChange: BLOCK* processReport 0xa24920840a6f3984: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-28 22:12:39,979 INFO BlockStateChange: BLOCK* processReport 0xa24920840a6f3984: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 10, hasStaleStorage: false, processing time: 5 msecs, invalidatedBlocks: 0
2017-09-28 22:15:50,977 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1184ms
No GCs detected
2017-09-28 22:17:46,256 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename from 127.0.0.1:38652: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot rename /usr. Name node is in safe mode.
The reported blocks 8 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 10.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-28 22:18:18,520 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9000, call Call#2 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 127.0.0.1:38656: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/hive/warehouse. Name node is in safe mode.
The reported blocks 8 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 10.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-28 22:19:19,735 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call Call#2 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:38660: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /user. Name node is in safe mode.
The reported blocks 8 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 10.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-28 22:23:16,608 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000, call Call#2 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:38672: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /user. Name node is in safe mode.
The reported blocks 8 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 10.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-28 22:25:09,211 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-28 22:25:09,215 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1
************************************************************/
2017-09-28 22:25:53,793 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-28 22:25:53,801 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-28 22:25:53,809 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-28 22:25:54,051 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-28 22:25:54,125 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-28 22:25:54,125 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-28 22:25:54,139 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-28 22:25:54,142 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-28 22:25:54,230 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-28 22:25:54,344 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-28 22:25:54,361 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-28 22:25:54,408 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-28 22:25:54,416 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-28 22:25:54,421 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-28 22:25:54,426 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-28 22:25:54,428 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-28 22:25:54,428 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-28 22:25:54,428 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-28 22:25:54,534 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-28 22:25:54,535 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-28 22:25:54,548 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-28 22:25:54,548 INFO org.mortbay.log: jetty-6.1.26
2017-09-28 22:25:54,663 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-28 22:25:54,685 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-28 22:25:54,685 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-28 22:25:54,713 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-28 22:25:54,718 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-28 22:25:54,719 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-28 22:25:54,720 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-28 22:25:54,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-28 22:25:54,747 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-28 22:25:54,748 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-28 22:25:54,748 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 28 22:25:54
2017-09-28 22:25:54,749 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-28 22:25:54,749 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-28 22:25:54,750 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-28 22:25:54,750 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-28 22:25:54,761 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-28 22:25:54,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-28 22:25:54,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-28 22:25:54,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-28 22:25:54,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-28 22:25:54,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-28 22:25:54,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-28 22:25:54,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-28 22:25:54,768 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-28 22:25:54,768 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-28 22:25:54,768 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-28 22:25:54,768 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-28 22:25:54,769 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-28 22:25:54,823 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-28 22:25:54,823 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-28 22:25:54,823 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-28 22:25:54,823 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-28 22:25:54,824 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-28 22:25:54,824 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-28 22:25:54,824 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-28 22:25:54,830 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-28 22:25:54,830 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-28 22:25:54,831 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-28 22:25:54,831 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-28 22:25:54,832 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-28 22:25:54,832 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-28 22:25:54,832 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-28 22:25:54,836 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-28 22:25:54,836 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-28 22:25:54,836 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-28 22:25:54,840 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-28 22:25:54,841 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-28 22:25:54,843 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-28 22:25:54,843 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-28 22:25:54,844 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-28 22:25:54,844 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-28 22:25:54,906 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 6162@localhost
2017-09-28 22:25:54,922 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-28 22:25:54,942 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000407 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000407-0000000000000000407
2017-09-28 22:25:54,946 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000406, cpktTxId=0000000000000000406)
2017-09-28 22:25:54,972 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 57 INodes.
2017-09-28 22:25:55,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-28 22:25:55,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 406 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000406
2017-09-28 22:25:55,006 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@20f12539 expecting start txid #407
2017-09-28 22:25:55,006 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000407-0000000000000000407
2017-09-28 22:25:55,007 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000407-0000000000000000407' to transaction ID 407
2017-09-28 22:25:55,015 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000407-0000000000000000407 of size 1048576 edits # 1 loaded in 0 seconds
2017-09-28 22:25:55,015 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-09-28 22:25:55,015 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 408
2017-09-28 22:25:55,096 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-28 22:25:55,096 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 248 msecs
2017-09-28 22:25:55,242 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-28 22:25:55,246 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-28 22:25:55,254 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-28 22:25:55,294 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-28 22:25:55,301 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 2
2017-09-28 22:25:55,302 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 9 blocks to reach the threshold 0.9990 of total blocks 10.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-28 22:25:55,332 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-28 22:25:55,332 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-28 22:25:55,338 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-28 22:25:55,339 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-28 22:25:55,339 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-28 22:25:55,344 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 4 milliseconds
name space=57
storage space=268448980
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-28 22:25:55,347 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-28 22:26:00,092 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-28 22:26:00,093 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-28 22:26:00,093 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-28 22:26:00,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-28 22:26:00,172 INFO BlockStateChange: BLOCK* processReport 0xfc9fae8834fc9626: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-28 22:26:00,176 INFO BlockStateChange: BLOCK* processReport 0xfc9fae8834fc9626: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 10, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2017-09-28 22:27:10,826 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename from 127.0.0.1:38722: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot rename /usr. Name node is in safe mode.
The reported blocks 8 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 10.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-28 22:27:28,846 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000, call Call#2 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:38724: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /user. Name node is in safe mode.
The reported blocks 8 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 10.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-28 22:28:20,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2017-09-28 22:28:20,108 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 145 secs
2017-09-28 22:28:20,108 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2017-09-28 22:28:20,108 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2017-09-28 22:28:20,108 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-28 22:28:20,111 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 12
2017-09-28 22:28:20,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-28 22:28:20,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 2
2017-09-28 22:28:20,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-28 22:28:20,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 2
2017-09-28 22:28:20,112 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 3 msec
2017-09-28 22:28:46,406 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is already OFF
2017-09-28 22:28:55,667 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 407 Number of syncs: 2 SyncTimes(ms): 7 
2017-09-28 22:32:00,072 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 407 Number of syncs: 3 SyncTimes(ms): 10 
2017-09-28 22:44:07,033 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1035ms
No GCs detected
2017-09-28 22:44:55,735 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1107ms
No GCs detected
2017-09-28 23:00:06,087 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-28 23:00:06,088 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-28 23:00:06,088 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 408, 411
2017-09-28 23:00:06,090 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=412 lastSyncedTxid=411 mostRecentTxid=412
2017-09-28 23:00:06,090 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 407 Number of syncs: 5 SyncTimes(ms): 14 
2017-09-28 23:00:06,098 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=412 lastSyncedTxid=412 mostRecentTxid=412
2017-09-28 23:00:06,098 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 407 Number of syncs: 6 SyncTimes(ms): 20 
2017-09-28 23:00:06,106 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000408 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000408-0000000000000000412
2017-09-28 23:00:06,106 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 413
2017-09-28 23:00:06,950 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2000.00 KB/s
2017-09-28 23:00:06,950 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000412 size 4615 bytes.
2017-09-28 23:00:06,952 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 406
2017-09-28 23:00:06,953 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000401, cpktTxId=0000000000000000401)
2017-09-28 23:20:23,248 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 13 
2017-09-28 23:25:55,167 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: [Lease.  Holder: DFSClient_NONMAPREDUCE_-212409849_1, pending creates: 3] has expired hard limit
2017-09-28 23:25:55,168 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_-212409849_1, pending creates: 3], src=/hbase/WALs/localhost,38399,1506222651827/localhost%2C38399%2C1506222651827..meta.1506222657957.meta
2017-09-28 23:25:55,175 WARN org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.internalReleaseLease: File /hbase/WALs/localhost,38399,1506222651827/localhost%2C38399%2C1506222651827..meta.1506222657957.meta has not been closed. Lease recovery is in progress. RecoveryId = 1036 for block blk_1073741844_1022
2017-09-28 23:25:55,176 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_-212409849_1, pending creates: 2], src=/hbase/WALs/localhost,38399,1506222651827/localhost%2C38399%2C1506222651827.default.1506222653386
2017-09-28 23:25:55,176 WARN org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.internalReleaseLease: File /hbase/WALs/localhost,38399,1506222651827/localhost%2C38399%2C1506222651827.default.1506222653386 has not been closed. Lease recovery is in progress. RecoveryId = 1037 for block blk_1073741843_1021
2017-09-28 23:25:55,177 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_-212409849_1, pending creates: 1], src=/hbase/MasterProcWALs/state-00000000000000000008.log
2017-09-28 23:25:55,185 WARN org.apache.hadoop.hdfs.StateChange: BLOCK* internalReleaseLease: All existing blocks are COMPLETE, lease removed, file /hbase/MasterProcWALs/state-00000000000000000008.log closed.
2017-09-28 23:25:55,187 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 8 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 17 
2017-09-28 23:25:58,008 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-896759491-127.0.0.1-1505591284841:blk_1073741844_1022, newgenerationstamp=1036, newlength=3782, newtargets=[127.0.0.1:50010], closeFile=true, deleteBlock=false)
2017-09-28 23:25:58,025 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-896759491-127.0.0.1-1505591284841:blk_1073741844_1022, file=/hbase/WALs/localhost,38399,1506222651827/localhost%2C38399%2C1506222651827..meta.1506222657957.meta, newgenerationstamp=1036, newlength=3782, newtargets=[127.0.0.1:50010]) successful
2017-09-28 23:25:58,035 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-896759491-127.0.0.1-1505591284841:blk_1073741843_1021, newgenerationstamp=1037, newlength=2550, newtargets=[127.0.0.1:50010], closeFile=true, deleteBlock=false)
2017-09-28 23:25:58,040 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-896759491-127.0.0.1-1505591284841:blk_1073741843_1021, file=/hbase/WALs/localhost,38399,1506222651827/localhost%2C38399%2C1506222651827.default.1506222653386, newgenerationstamp=1037, newlength=2550, newtargets=[127.0.0.1:50010]) successful
2017-09-28 23:30:49,364 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1025ms
No GCs detected
2017-09-29 00:00:09,366 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-29 00:00:09,367 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-29 00:00:09,368 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 413, 422
2017-09-29 00:00:09,368 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=423 lastSyncedTxid=422 mostRecentTxid=423
2017-09-29 00:00:09,368 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 11 Total time for transactions(ms): 17 Number of transactions batched in Syncs: 4 Number of syncs: 7 SyncTimes(ms): 28 
2017-09-29 00:00:09,373 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=423 lastSyncedTxid=423 mostRecentTxid=423
2017-09-29 00:00:09,373 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 11 Total time for transactions(ms): 17 Number of transactions batched in Syncs: 4 Number of syncs: 8 SyncTimes(ms): 32 
2017-09-29 00:00:09,377 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000413 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000413-0000000000000000423
2017-09-29 00:00:09,377 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 424
2017-09-29 00:00:09,505 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2000.00 KB/s
2017-09-29 00:00:09,505 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000423 size 4320 bytes.
2017-09-29 00:00:09,508 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 412
2017-09-29 00:00:09,508 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000406, cpktTxId=0000000000000000406)
2017-09-29 00:03:59,101 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1077ms
No GCs detected
2017-09-29 00:13:42,188 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-29 00:13:42,190 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1
************************************************************/
2017-09-29 00:26:37,720 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-29 00:26:37,728 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-29 00:26:37,734 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-29 00:26:37,986 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-29 00:26:38,066 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-29 00:26:38,067 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-29 00:26:38,083 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-29 00:26:38,085 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-29 00:26:38,179 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-29 00:26:38,296 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-29 00:26:38,314 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-29 00:26:38,363 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-29 00:26:38,372 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-29 00:26:38,377 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-29 00:26:38,381 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-29 00:26:38,383 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-29 00:26:38,383 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-29 00:26:38,383 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-29 00:26:38,512 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-29 00:26:38,514 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-29 00:26:38,534 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-29 00:26:38,534 INFO org.mortbay.log: jetty-6.1.26
2017-09-29 00:26:38,642 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-29 00:26:38,673 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-29 00:26:38,673 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-29 00:26:38,700 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-29 00:26:38,705 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-29 00:26:38,706 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-29 00:26:38,707 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-29 00:26:38,735 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-29 00:26:38,735 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-29 00:26:38,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-29 00:26:38,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 29 00:26:38
2017-09-29 00:26:38,738 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-29 00:26:38,738 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 00:26:38,739 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-29 00:26:38,739 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-29 00:26:38,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-29 00:26:38,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-29 00:26:38,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-29 00:26:38,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-29 00:26:38,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-29 00:26:38,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-29 00:26:38,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-29 00:26:38,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-29 00:26:38,762 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-29 00:26:38,762 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-29 00:26:38,762 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-29 00:26:38,762 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-29 00:26:38,763 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-29 00:26:38,817 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-29 00:26:38,817 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 00:26:38,818 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-29 00:26:38,818 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-29 00:26:38,818 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-29 00:26:38,819 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-29 00:26:38,819 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-29 00:26:38,825 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-29 00:26:38,826 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 00:26:38,826 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-29 00:26:38,826 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-29 00:26:38,828 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-29 00:26:38,828 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-29 00:26:38,828 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-29 00:26:38,833 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-29 00:26:38,833 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-29 00:26:38,833 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-29 00:26:38,839 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-29 00:26:38,839 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-29 00:26:38,841 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-29 00:26:38,841 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 00:26:38,841 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-29 00:26:38,842 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-29 00:26:38,907 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 13958@localhost
2017-09-29 00:26:38,924 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-29 00:26:38,947 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000424 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000424-0000000000000000424
2017-09-29 00:26:38,952 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000423, cpktTxId=0000000000000000423)
2017-09-29 00:26:38,982 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 59 INodes.
2017-09-29 00:26:39,012 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-29 00:26:39,012 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 423 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000423
2017-09-29 00:26:39,012 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@20f12539 expecting start txid #424
2017-09-29 00:26:39,012 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000424-0000000000000000424
2017-09-29 00:26:39,013 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000424-0000000000000000424' to transaction ID 424
2017-09-29 00:26:39,020 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000424-0000000000000000424 of size 1048576 edits # 1 loaded in 0 seconds
2017-09-29 00:26:39,021 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-09-29 00:26:39,021 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 425
2017-09-29 00:26:39,102 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-29 00:26:39,102 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 257 msecs
2017-09-29 00:26:39,237 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-29 00:26:39,241 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-29 00:26:39,250 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-29 00:26:39,291 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-29 00:26:39,299 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-29 00:26:39,299 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 11 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 00:26:39,329 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-29 00:26:39,329 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-29 00:26:39,333 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-29 00:26:39,336 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-29 00:26:39,336 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-29 00:26:39,348 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 12 milliseconds
name space=59
storage space=19856
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-29 00:26:39,353 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-29 00:26:43,943 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-29 00:26:43,944 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-29 00:26:43,944 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-29 00:26:43,994 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-29 00:26:44,024 INFO BlockStateChange: BLOCK* processReport 0x241409e5821f49f6: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-29 00:26:44,026 INFO BlockStateChange: BLOCK* processReport 0x241409e5821f49f6: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 10, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2017-09-29 00:27:49,093 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000, call Call#1 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39010: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 00:28:49,126 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000, call Call#3 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39012: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 00:29:49,155 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000, call Call#5 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39014: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 00:30:49,211 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000, call Call#7 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39016: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 00:31:49,262 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000, call Call#9 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39018: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 00:32:49,394 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000, call Call#11 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39020: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 00:33:49,430 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000, call Call#13 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39022: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 00:34:49,457 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000, call Call#15 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39024: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 00:35:30,831 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000, call Call#4 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:39026: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /tmp/hive/root/5c3c5a50-8f3d-4ceb-a2e4-a8cb7bff21e8. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 00:35:49,500 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call Call#17 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39028: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 00:36:49,524 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call Call#19 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39030: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 00:37:49,542 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call Call#21 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39032: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 00:37:49,920 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2017-09-29 00:37:49,921 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 671 secs
2017-09-29 00:37:49,921 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2017-09-29 00:37:49,921 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2017-09-29 00:37:49,921 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-29 00:37:49,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 12
2017-09-29 00:37:49,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-29 00:37:49,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 2
2017-09-29 00:37:49,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-29 00:37:49,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-09-29 00:37:49,931 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 10 msec
2017-09-29 00:38:37,846 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is already OFF
2017-09-29 00:38:49,556 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-29 00:38:49,556 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-29 00:38:49,556 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 425, 425
2017-09-29 00:38:49,556 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=426 lastSyncedTxid=425 mostRecentTxid=426
2017-09-29 00:38:49,557 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 424 Number of syncs: 2 SyncTimes(ms): 7 
2017-09-29 00:38:49,560 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=426 lastSyncedTxid=426 mostRecentTxid=426
2017-09-29 00:38:49,560 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 424 Number of syncs: 3 SyncTimes(ms): 11 
2017-09-29 00:38:49,563 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000425 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000425-0000000000000000426
2017-09-29 00:38:49,564 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 427
2017-09-29 00:38:50,250 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 444.44 KB/s
2017-09-29 00:38:50,250 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000426 size 4320 bytes.
2017-09-29 00:38:50,253 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 423
2017-09-29 00:38:50,253 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000412, cpktTxId=0000000000000000412)
2017-09-29 00:47:07,368 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 10 
2017-09-29 00:54:40,418 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 13 
2017-09-29 00:54:40,513 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741858_1038, replicas=127.0.0.1:50010 for /user/hive/warehouse/Downloads/apache-hive-2.2.0-bin.tar.gz._COPYING_
2017-09-29 00:54:43,039 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741859_1039, replicas=127.0.0.1:50010 for /user/hive/warehouse/Downloads/apache-hive-2.2.0-bin.tar.gz._COPYING_
2017-09-29 00:54:45,763 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/Downloads/apache-hive-2.2.0-bin.tar.gz._COPYING_ is closed by DFSClient_NONMAPREDUCE_320132238_1
2017-09-29 00:54:45,839 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741860_1040, replicas=127.0.0.1:50010 for /user/hive/warehouse/Downloads/hadoop-2.8.1.tar.gz._COPYING_
2017-09-29 00:54:51,505 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741861_1041, replicas=127.0.0.1:50010 for /user/hive/warehouse/Downloads/hadoop-2.8.1.tar.gz._COPYING_
2017-09-29 00:54:57,304 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741862_1042, replicas=127.0.0.1:50010 for /user/hive/warehouse/Downloads/hadoop-2.8.1.tar.gz._COPYING_
2017-09-29 00:55:02,118 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741863_1043, replicas=127.0.0.1:50010 for /user/hive/warehouse/Downloads/hadoop-2.8.1.tar.gz._COPYING_
2017-09-29 00:55:02,602 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/Downloads/hadoop-2.8.1.tar.gz._COPYING_ is closed by DFSClient_NONMAPREDUCE_320132238_1
2017-09-29 00:55:02,650 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741864_1044, replicas=127.0.0.1:50010 for /user/hive/warehouse/Downloads/jdk-8u144-linux-x64.tar.gz._COPYING_
2017-09-29 00:55:08,076 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741865_1045, replicas=127.0.0.1:50010 for /user/hive/warehouse/Downloads/jdk-8u144-linux-x64.tar.gz._COPYING_
2017-09-29 00:55:09,282 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741865_1045 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/hive/warehouse/Downloads/jdk-8u144-linux-x64.tar.gz._COPYING_
2017-09-29 00:55:09,282 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2017-09-29 00:55:09,688 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/Downloads/jdk-8u144-linux-x64.tar.gz._COPYING_ is closed by DFSClient_NONMAPREDUCE_320132238_1
2017-09-29 00:55:09,726 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741866_1046, replicas=127.0.0.1:50010 for /user/hive/warehouse/Downloads/twitter2.json._COPYING_
2017-09-29 00:55:10,206 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741866_1046 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/hive/warehouse/Downloads/twitter2.json._COPYING_
2017-09-29 00:55:10,614 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/Downloads/twitter2.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_320132238_1
2017-09-29 00:56:20,134 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 45 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 17 Number of syncs: 28 SyncTimes(ms): 34 
2017-09-29 01:16:20,376 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 50 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 17 Number of syncs: 33 SyncTimes(ms): 42 
2017-09-29 01:18:51,816 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 52 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 17 Number of syncs: 35 SyncTimes(ms): 48 
2017-09-29 01:20:53,880 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 53 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 17 Number of syncs: 36 SyncTimes(ms): 49 
2017-09-29 01:20:53,904 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741867_1047, replicas=127.0.0.1:50010 for /user/hive/warehouse/test.json._COPYING_
2017-09-29 01:20:53,958 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/test.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_-486845306_1
2017-09-29 01:22:18,185 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 59 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 19 Number of syncs: 40 SyncTimes(ms): 53 
2017-09-29 01:23:23,151 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 60 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 19 Number of syncs: 41 SyncTimes(ms): 56 
2017-09-29 01:28:03,862 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 61 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 19 Number of syncs: 42 SyncTimes(ms): 59 
2017-09-29 01:33:40,615 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-29 01:33:40,616 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1
************************************************************/
2017-09-29 01:34:40,161 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-29 01:34:40,171 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-29 01:34:40,177 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-29 01:34:40,421 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-29 01:34:40,502 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-29 01:34:40,502 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-29 01:34:40,518 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-29 01:34:40,521 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-29 01:34:40,603 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-29 01:34:40,713 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-29 01:34:40,731 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-29 01:34:40,785 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-29 01:34:40,800 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-29 01:34:40,808 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-29 01:34:40,813 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-29 01:34:40,815 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-29 01:34:40,816 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-29 01:34:40,816 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-29 01:34:40,918 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-29 01:34:40,919 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-29 01:34:40,933 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-29 01:34:40,933 INFO org.mortbay.log: jetty-6.1.26
2017-09-29 01:34:41,047 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-29 01:34:41,080 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-29 01:34:41,080 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-29 01:34:41,106 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-29 01:34:41,112 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-29 01:34:41,113 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-29 01:34:41,114 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-29 01:34:41,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-29 01:34:41,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-29 01:34:41,143 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-29 01:34:41,143 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 29 01:34:41
2017-09-29 01:34:41,145 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-29 01:34:41,145 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 01:34:41,146 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-29 01:34:41,146 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-29 01:34:41,160 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-29 01:34:41,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-29 01:34:41,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-29 01:34:41,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-29 01:34:41,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-29 01:34:41,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-29 01:34:41,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-29 01:34:41,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-29 01:34:41,167 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-29 01:34:41,167 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-29 01:34:41,167 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-29 01:34:41,167 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-29 01:34:41,169 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-29 01:34:41,222 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-29 01:34:41,222 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 01:34:41,222 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-29 01:34:41,222 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-29 01:34:41,223 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-29 01:34:41,223 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-29 01:34:41,224 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-29 01:34:41,231 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-29 01:34:41,231 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 01:34:41,232 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-29 01:34:41,232 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-29 01:34:41,233 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-29 01:34:41,233 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-29 01:34:41,233 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-29 01:34:41,238 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-29 01:34:41,238 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-29 01:34:41,238 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-29 01:34:41,242 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-29 01:34:41,242 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-29 01:34:41,244 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-29 01:34:41,245 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 01:34:41,245 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-29 01:34:41,245 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-29 01:34:41,309 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 20626@localhost
2017-09-29 01:34:41,326 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-29 01:34:41,352 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000427 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000427-0000000000000000488
2017-09-29 01:34:41,357 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000426, cpktTxId=0000000000000000426)
2017-09-29 01:34:41,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 59 INodes.
2017-09-29 01:34:41,422 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-29 01:34:41,422 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 426 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000426
2017-09-29 01:34:41,423 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@20f12539 expecting start txid #427
2017-09-29 01:34:41,423 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000427-0000000000000000488
2017-09-29 01:34:41,424 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000427-0000000000000000488' to transaction ID 427
2017-09-29 01:34:41,469 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000427-0000000000000000488 of size 1048576 edits # 62 loaded in 0 seconds
2017-09-29 01:34:41,469 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-09-29 01:34:41,469 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 489
2017-09-29 01:34:41,547 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-29 01:34:41,547 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 299 msecs
2017-09-29 01:34:41,666 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-29 01:34:41,670 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-29 01:34:41,678 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-29 01:34:41,723 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-29 01:34:41,730 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-29 01:34:41,730 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 11 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:34:41,760 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-29 01:34:41,763 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-29 01:34:41,767 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-29 01:34:41,770 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-29 01:34:41,771 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-29 01:34:41,775 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 4 milliseconds
name space=60
storage space=19856
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-29 01:34:41,779 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-29 01:34:46,619 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-29 01:34:46,620 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-29 01:34:46,621 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-29 01:34:46,671 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-29 01:34:46,704 INFO BlockStateChange: BLOCK* processReport 0x83c48e07609dc5d: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-29 01:34:46,707 INFO BlockStateChange: BLOCK* processReport 0x83c48e07609dc5d: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 10, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2017-09-29 01:35:51,808 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9000, call Call#1 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39462: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:36:51,848 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000, call Call#3 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39466: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:37:51,893 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000, call Call#5 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39468: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:38:51,935 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000, call Call#7 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39470: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:39:51,991 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000, call Call#9 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39472: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:40:52,094 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000, call Call#11 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39474: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:41:52,139 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9000, call Call#13 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39476: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:42:52,197 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call Call#15 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39478: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:43:52,223 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9000, call Call#17 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39486: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:44:52,260 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000, call Call#19 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39490: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:45:52,332 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call Call#21 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39492: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:46:52,373 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000, call Call#23 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39498: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:47:52,403 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9000, call Call#25 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39510: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:48:52,437 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9000, call Call#27 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39514: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:49:34,577 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000, call Call#2 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:39516: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /user/hive/warehouse1. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:49:52,476 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000, call Call#29 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:39520: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:50:07,768 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000, call Call#2 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:39524: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /user/hive/warehouse1. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 01:50:33,632 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2017-09-29 01:50:33,633 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 952 secs
2017-09-29 01:50:33,633 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2017-09-29 01:50:33,633 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2017-09-29 01:50:33,634 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-29 01:50:33,641 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 12
2017-09-29 01:50:33,641 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-29 01:50:33,641 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 2
2017-09-29 01:50:33,641 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-29 01:50:33,641 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-09-29 01:50:33,642 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2017-09-29 01:50:47,380 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is already OFF
2017-09-29 01:50:52,541 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-29 01:50:52,541 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-29 01:50:52,542 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 489, 489
2017-09-29 01:50:52,542 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=490 lastSyncedTxid=489 mostRecentTxid=490
2017-09-29 01:50:52,543 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 488 Number of syncs: 2 SyncTimes(ms): 6 
2017-09-29 01:50:52,545 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=490 lastSyncedTxid=490 mostRecentTxid=490
2017-09-29 01:50:52,546 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 488 Number of syncs: 3 SyncTimes(ms): 9 
2017-09-29 01:50:52,549 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000489 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000489-0000000000000000490
2017-09-29 01:50:52,549 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 491
2017-09-29 01:50:53,380 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2000.00 KB/s
2017-09-29 01:50:53,381 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000490 size 4390 bytes.
2017-09-29 01:50:53,385 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 426
2017-09-29 01:50:53,385 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000423, cpktTxId=0000000000000000423)
2017-09-29 01:51:03,100 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1060ms
No GCs detected
2017-09-29 01:53:12,589 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 18 
2017-09-29 01:54:22,393 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 8 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 8 SyncTimes(ms): 25 
2017-09-29 01:55:31,127 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-29 01:55:31,129 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1
************************************************************/
2017-09-29 11:59:50,045 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-29 11:59:50,053 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-29 11:59:50,061 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-29 11:59:50,340 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-29 11:59:50,451 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-29 11:59:50,452 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-29 11:59:50,467 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-29 11:59:50,470 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-29 11:59:50,558 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-29 11:59:50,702 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-29 11:59:50,729 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-29 11:59:50,785 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-29 11:59:50,793 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-29 11:59:50,797 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-29 11:59:50,801 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-29 11:59:50,803 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-29 11:59:50,803 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-29 11:59:50,803 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-29 11:59:50,916 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-29 11:59:50,918 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-29 11:59:50,936 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-29 11:59:50,937 INFO org.mortbay.log: jetty-6.1.26
2017-09-29 11:59:51,174 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-29 11:59:51,250 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-29 11:59:51,250 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-29 11:59:51,281 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-29 11:59:51,287 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-29 11:59:51,288 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-29 11:59:51,289 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-29 11:59:51,322 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-29 11:59:51,322 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-29 11:59:51,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-29 11:59:51,325 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 29 11:59:51
2017-09-29 11:59:51,327 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-29 11:59:51,327 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 11:59:51,329 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-29 11:59:51,329 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-29 11:59:51,352 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-29 11:59:51,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-29 11:59:51,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-29 11:59:51,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-29 11:59:51,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-29 11:59:51,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-29 11:59:51,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-29 11:59:51,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-29 11:59:51,364 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-29 11:59:51,364 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-29 11:59:51,364 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-29 11:59:51,365 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-29 11:59:51,367 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-29 11:59:51,455 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-29 11:59:51,455 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 11:59:51,455 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-29 11:59:51,455 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-29 11:59:51,456 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-29 11:59:51,456 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-29 11:59:51,456 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-29 11:59:51,466 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-29 11:59:51,466 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 11:59:51,466 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-29 11:59:51,466 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-29 11:59:51,468 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-29 11:59:51,468 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-29 11:59:51,468 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-29 11:59:51,473 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-29 11:59:51,473 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-29 11:59:51,473 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-29 11:59:51,477 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-29 11:59:51,477 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-29 11:59:51,479 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-29 11:59:51,479 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 11:59:51,479 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-29 11:59:51,480 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-29 11:59:51,646 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 2841@localhost
2017-09-29 11:59:51,665 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-29 11:59:51,691 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000491 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000491-0000000000000000500
2017-09-29 11:59:51,696 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000490, cpktTxId=0000000000000000490)
2017-09-29 11:59:51,730 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 60 INodes.
2017-09-29 11:59:51,764 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-29 11:59:51,764 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 490 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000490
2017-09-29 11:59:51,764 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@20f12539 expecting start txid #491
2017-09-29 11:59:51,764 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000491-0000000000000000500
2017-09-29 11:59:51,765 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000491-0000000000000000500' to transaction ID 491
2017-09-29 11:59:51,798 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000491-0000000000000000500 of size 1048576 edits # 10 loaded in 0 seconds
2017-09-29 11:59:51,798 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2017-09-29 11:59:51,798 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2017-09-29 11:59:51,802 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/raji/hadoop_store/hdfs/namenode/current/fsimage.ckpt_0000000000000000500 using no compression
2017-09-29 11:59:51,836 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/raji/hadoop_store/hdfs/namenode/current/fsimage.ckpt_0000000000000000500 of size 4572 bytes saved in 0 seconds.
2017-09-29 11:59:51,847 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 490
2017-09-29 11:59:51,847 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000426, cpktTxId=0000000000000000426)
2017-09-29 11:59:51,859 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 501
2017-09-29 11:59:51,953 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-29 11:59:51,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 471 msecs
2017-09-29 11:59:52,086 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-29 11:59:52,093 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-29 11:59:52,103 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-29 11:59:52,160 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-29 11:59:52,168 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-29 11:59:52,168 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 11 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 11:59:52,198 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-29 11:59:52,199 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-29 11:59:52,204 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-29 11:59:52,208 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-29 11:59:52,208 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-29 11:59:52,222 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 14 milliseconds
name space=63
storage space=19856
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-29 11:59:52,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-29 11:59:57,198 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-29 11:59:57,199 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-29 11:59:57,199 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-29 11:59:57,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-29 11:59:57,331 INFO BlockStateChange: BLOCK* processReport 0x46e3372d51082cc4: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-29 11:59:57,334 INFO BlockStateChange: BLOCK* processReport 0x46e3372d51082cc4: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 10, hasStaleStorage: false, processing time: 10 msecs, invalidatedBlocks: 0
2017-09-29 12:00:57,503 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000, call Call#2 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:43290: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /data. Name node is in safe mode.
The reported blocks 10 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 12.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 12:08:28,155 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2017-09-29 12:08:28,155 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 516 secs
2017-09-29 12:08:28,155 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2017-09-29 12:08:28,155 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2017-09-29 12:08:28,155 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-29 12:08:28,157 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 12
2017-09-29 12:08:28,163 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-29 12:08:28,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 2
2017-09-29 12:08:28,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-29 12:08:28,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-09-29 12:08:28,164 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2017-09-29 12:08:45,165 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is already OFF
2017-09-29 12:08:51,784 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 500 Number of syncs: 2 SyncTimes(ms): 7 
2017-09-29 12:12:14,886 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1076ms
No GCs detected
2017-09-29 12:12:32,064 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 500 Number of syncs: 3 SyncTimes(ms): 10 
2017-09-29 12:12:32,103 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741868_1048, replicas=127.0.0.1:50010 for /data/twitter2.json._COPYING_
2017-09-29 12:12:32,513 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741868_1048 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /data/twitter2.json._COPYING_
2017-09-29 12:12:32,935 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /data/twitter2.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_1952297023_1
2017-09-29 12:12:46,626 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741869_1049, replicas=127.0.0.1:50010 for /data/test.json._COPYING_
2017-09-29 12:12:46,673 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /data/test.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_-646950020_1
2017-09-29 12:14:38,961 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 15 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 504 Number of syncs: 11 SyncTimes(ms): 24 
2017-09-29 12:16:49,448 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 19 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 504 Number of syncs: 15 SyncTimes(ms): 31 
2017-09-29 12:18:53,241 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 22 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 504 Number of syncs: 18 SyncTimes(ms): 35 
2017-09-29 12:29:50,007 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 23 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 504 Number of syncs: 19 SyncTimes(ms): 36 
2017-09-29 12:31:27,555 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 25 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 504 Number of syncs: 21 SyncTimes(ms): 39 
2017-09-29 12:36:22,949 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 26 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 504 Number of syncs: 22 SyncTimes(ms): 39 
2017-09-29 12:39:20,091 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 28 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 504 Number of syncs: 24 SyncTimes(ms): 44 
2017-09-29 12:41:54,210 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 29 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 504 Number of syncs: 25 SyncTimes(ms): 45 
2017-09-29 12:50:17,442 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 31 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 504 Number of syncs: 27 SyncTimes(ms): 48 
2017-09-29 12:52:50,994 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 32 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 504 Number of syncs: 28 SyncTimes(ms): 51 
2017-09-29 12:58:02,715 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-29 12:58:02,715 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-29 12:58:02,715 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 501, 533
2017-09-29 12:58:02,716 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=534 lastSyncedTxid=533 mostRecentTxid=534
2017-09-29 12:58:02,716 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 34 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 504 Number of syncs: 30 SyncTimes(ms): 55 
2017-09-29 12:58:02,721 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=534 lastSyncedTxid=534 mostRecentTxid=534
2017-09-29 12:58:02,721 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 34 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 504 Number of syncs: 31 SyncTimes(ms): 60 
2017-09-29 12:58:02,727 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000501 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000501-0000000000000000534
2017-09-29 12:58:02,727 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 535
2017-09-29 12:58:03,476 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 4000.00 KB/s
2017-09-29 12:58:03,476 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000534 size 5004 bytes.
2017-09-29 12:58:03,478 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 500
2017-09-29 12:58:03,478 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000490, cpktTxId=0000000000000000490)
2017-09-29 13:13:42,301 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 10 
2017-09-29 13:21:05,819 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 11 
2017-09-29 13:22:48,719 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 14 
2017-09-29 13:24:13,596 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 6 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 15 
2017-09-29 13:50:15,399 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 8 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 8 SyncTimes(ms): 18 
2017-09-29 13:51:31,564 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 10 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 10 SyncTimes(ms): 24 
2017-09-29 13:58:04,676 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-29 13:58:04,677 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-29 13:58:04,677 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 535, 553
2017-09-29 13:58:04,677 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=554 lastSyncedTxid=553 mostRecentTxid=554
2017-09-29 13:58:04,678 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 20 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 1 Number of syncs: 19 SyncTimes(ms): 36 
2017-09-29 13:58:04,681 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=554 lastSyncedTxid=554 mostRecentTxid=554
2017-09-29 13:58:04,682 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 20 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 1 Number of syncs: 20 SyncTimes(ms): 40 
2017-09-29 13:58:04,684 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000535 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000535-0000000000000000554
2017-09-29 13:58:04,684 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 555
2017-09-29 13:58:04,745 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1333.33 KB/s
2017-09-29 13:58:04,746 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000554 size 5064 bytes.
2017-09-29 13:58:04,748 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 534
2017-09-29 13:58:04,749 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000500, cpktTxId=0000000000000000500)
2017-09-29 14:19:35,520 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2017-09-29 14:23:56,853 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 10 
2017-09-29 14:36:45,493 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 13 
2017-09-29 14:38:11,175 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 16 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 3 Number of syncs: 13 SyncTimes(ms): 19 
2017-09-29 14:44:17,334 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 23 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 4 Number of syncs: 19 SyncTimes(ms): 24 
2017-09-29 14:45:42,606 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 24 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 4 Number of syncs: 20 SyncTimes(ms): 27 
2017-09-29 14:45:42,631 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741870_1050, replicas=127.0.0.1:50010 for /data/test.json._COPYING_
2017-09-29 14:45:42,679 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /data/test.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_-950125509_1
2017-09-29 14:54:59,921 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 32 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 6 Number of syncs: 26 SyncTimes(ms): 35 
2017-09-29 14:56:10,841 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 39 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 7 Number of syncs: 32 SyncTimes(ms): 39 
2017-09-29 14:58:06,162 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-29 14:58:06,162 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-29 14:58:06,162 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 555, 593
2017-09-29 14:58:06,163 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=594 lastSyncedTxid=593 mostRecentTxid=594
2017-09-29 14:58:06,163 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 40 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 7 Number of syncs: 33 SyncTimes(ms): 42 
2017-09-29 14:58:06,169 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=594 lastSyncedTxid=594 mostRecentTxid=594
2017-09-29 14:58:06,169 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 40 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 7 Number of syncs: 34 SyncTimes(ms): 48 
2017-09-29 14:58:06,172 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000555 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000555-0000000000000000594
2017-09-29 14:58:06,172 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 595
2017-09-29 14:58:06,246 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2000.00 KB/s
2017-09-29 14:58:06,246 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000594 size 4822 bytes.
2017-09-29 14:58:06,249 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 554
2017-09-29 14:58:06,249 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000534, cpktTxId=0000000000000000534)
2017-09-29 15:20:13,346 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2017-09-29 15:21:32,856 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 15 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 1 Number of syncs: 14 SyncTimes(ms): 33 
2017-09-29 15:24:04,518 INFO BlockStateChange: BLOCK* processReport 0x46e3372d51082cc5: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 11, hasStaleStorage: false, processing time: 6 msecs, invalidatedBlocks: 0
2017-09-29 15:27:08,399 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 19 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 1 Number of syncs: 18 SyncTimes(ms): 40 
2017-09-29 15:28:14,808 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 21 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 1 Number of syncs: 20 SyncTimes(ms): 44 
2017-09-29 15:58:07,990 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-29 15:58:07,990 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-29 15:58:07,990 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 595, 616
2017-09-29 15:58:07,990 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=617 lastSyncedTxid=616 mostRecentTxid=617
2017-09-29 15:58:07,990 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 23 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 1 Number of syncs: 22 SyncTimes(ms): 48 
2017-09-29 15:58:07,992 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=617 lastSyncedTxid=617 mostRecentTxid=617
2017-09-29 15:58:07,992 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 23 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 1 Number of syncs: 23 SyncTimes(ms): 49 
2017-09-29 15:58:07,993 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000595 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000595-0000000000000000617
2017-09-29 15:58:07,993 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 618
2017-09-29 15:58:08,041 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 4000.00 KB/s
2017-09-29 15:58:08,041 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000617 size 4989 bytes.
2017-09-29 15:58:08,043 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 594
2017-09-29 15:58:08,043 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000554, cpktTxId=0000000000000000554)
2017-09-29 16:00:40,433 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 5 
2017-09-29 16:09:47,511 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 11 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 2 Number of syncs: 9 SyncTimes(ms): 20 
2017-09-29 16:19:05,330 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 13 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 2 Number of syncs: 11 SyncTimes(ms): 24 
2017-09-29 16:21:32,498 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 14 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 2 Number of syncs: 12 SyncTimes(ms): 28 
2017-09-29 16:22:40,264 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 16 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 2 Number of syncs: 14 SyncTimes(ms): 33 
2017-09-29 16:31:11,334 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 23 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 3 Number of syncs: 20 SyncTimes(ms): 39 
2017-09-29 16:31:54,430 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741871_1051, replicas=127.0.0.1:50010 for /data/twitter2.json._COPYING_
2017-09-29 16:31:54,628 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /data/twitter2.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2122893231_1
2017-09-29 16:37:19,381 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 31 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 5 Number of syncs: 26 SyncTimes(ms): 53 
2017-09-29 16:58:09,423 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-29 16:58:09,423 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-29 16:58:09,424 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 618, 656
2017-09-29 16:58:09,425 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=657 lastSyncedTxid=656 mostRecentTxid=657
2017-09-29 16:58:09,425 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 40 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 6 Number of syncs: 34 SyncTimes(ms): 64 
2017-09-29 16:58:09,431 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=657 lastSyncedTxid=657 mostRecentTxid=657
2017-09-29 16:58:09,431 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 40 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 6 Number of syncs: 35 SyncTimes(ms): 70 
2017-09-29 16:58:09,433 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000618 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000618-0000000000000000657
2017-09-29 16:58:09,433 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 658
2017-09-29 16:58:09,509 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1333.33 KB/s
2017-09-29 16:58:09,509 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000657 size 4996 bytes.
2017-09-29 16:58:09,512 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 617
2017-09-29 16:58:09,512 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000594, cpktTxId=0000000000000000594)
2017-09-29 16:59:13,322 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2017-09-29 17:02:26,759 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 16 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 2 Number of syncs: 14 SyncTimes(ms): 18 
2017-09-29 17:11:15,401 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 23 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 3 Number of syncs: 20 SyncTimes(ms): 28 
2017-09-29 17:29:13,783 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 27 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 3 Number of syncs: 21 SyncTimes(ms): 31 
2017-09-29 17:29:13,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741872_1052, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job.jar
2017-09-29 17:29:13,989 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job.jar is closed by DFSClient_NONMAPREDUCE_585764752_1
2017-09-29 17:29:13,996 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job.jar
2017-09-29 17:29:14,028 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job.split
2017-09-29 17:29:14,035 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741873_1053, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job.split
2017-09-29 17:29:14,043 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741873_1053 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job.split
2017-09-29 17:29:14,447 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job.split is closed by DFSClient_NONMAPREDUCE_585764752_1
2017-09-29 17:29:14,475 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741874_1054, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job.splitmetainfo
2017-09-29 17:29:14,499 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_585764752_1
2017-09-29 17:29:14,609 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741875_1055, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job.xml
2017-09-29 17:29:14,629 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741875_1055 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job.xml
2017-09-29 17:29:15,034 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job.xml is closed by DFSClient_NONMAPREDUCE_585764752_1
2017-09-29 17:29:22,039 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741876_1056, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job_1506704426452_0001_1_conf.xml
2017-09-29 17:29:22,084 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741876_1056 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job_1506704426452_0001_1_conf.xml
2017-09-29 17:29:22,494 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job_1506704426452_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1466328242_1
2017-09-29 17:29:28,590 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741877_1057, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job_1506704426452_0001_1.jhist
2017-09-29 17:29:28,617 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job_1506704426452_0001_1.jhist for DFSClient_NONMAPREDUCE_-1466328242_1
2017-09-29 17:29:33,216 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741878_1058, replicas=127.0.0.1:50010 for /data/out/_temporary/1/_temporary/attempt_1506704426452_0001_r_000000_0/part-r-00000
2017-09-29 17:29:33,557 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741878_1058 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /data/out/_temporary/1/_temporary/attempt_1506704426452_0001_r_000000_0/part-r-00000
2017-09-29 17:29:33,964 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /data/out/_temporary/1/_temporary/attempt_1506704426452_0001_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1506704426452_0001_r_000000_0_-1408978763_1
2017-09-29 17:29:34,094 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1466328242_1
2017-09-29 17:29:34,134 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /data/out/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1466328242_1
2017-09-29 17:29:34,144 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1466328242_1
2017-09-29 17:29:34,165 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741877_1057 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job_1506704426452_0001_1.jhist
2017-09-29 17:29:34,570 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job_1506704426452_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_-1466328242_1
2017-09-29 17:29:34,614 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741879_1059, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506704426452_0001.summary_tmp
2017-09-29 17:29:34,635 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506704426452_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1466328242_1
2017-09-29 17:29:34,665 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741880_1060, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506704426452_0001-1506724155293-root-word+count-1506724174146-1-1-SUCCEEDED-default-1506724161743.jhist_tmp
2017-09-29 17:29:34,674 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741880_1060 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506704426452_0001-1506724155293-root-word+count-1506724174146-1-1-SUCCEEDED-default-1506724161743.jhist_tmp
2017-09-29 17:29:35,077 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506704426452_0001-1506724155293-root-word+count-1506724174146-1-1-SUCCEEDED-default-1506724161743.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1466328242_1
2017-09-29 17:29:35,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741881_1061, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506704426452_0001_conf.xml_tmp
2017-09-29 17:29:35,139 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506704426452_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1466328242_1
2017-09-29 17:32:59,884 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-29 17:32:59,886 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1
************************************************************/
2017-09-29 21:56:58,176 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-29 21:56:58,183 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-29 21:56:58,191 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-29 21:56:58,469 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-29 21:56:58,640 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-29 21:56:58,640 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-29 21:56:58,680 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-29 21:56:58,687 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-29 21:56:58,818 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-29 21:56:58,955 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-29 21:56:58,976 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-29 21:56:59,028 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-29 21:56:59,041 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-29 21:56:59,046 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-29 21:56:59,051 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-29 21:56:59,053 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-29 21:56:59,053 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-29 21:56:59,053 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-29 21:56:59,170 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-29 21:56:59,172 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-29 21:56:59,192 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-29 21:56:59,193 INFO org.mortbay.log: jetty-6.1.26
2017-09-29 21:56:59,417 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-29 21:56:59,481 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-29 21:56:59,481 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-29 21:56:59,516 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-29 21:56:59,524 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-29 21:56:59,525 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-29 21:56:59,527 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-29 21:56:59,560 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-29 21:56:59,560 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-29 21:56:59,561 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-29 21:56:59,561 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 29 21:56:59
2017-09-29 21:56:59,562 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-29 21:56:59,562 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 21:56:59,563 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-29 21:56:59,564 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-29 21:56:59,581 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-29 21:56:59,583 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-29 21:56:59,584 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-29 21:56:59,584 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-29 21:56:59,584 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-29 21:56:59,584 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-29 21:56:59,584 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-29 21:56:59,584 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-29 21:56:59,589 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-29 21:56:59,589 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-29 21:56:59,589 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-29 21:56:59,589 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-29 21:56:59,590 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-29 21:56:59,655 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-29 21:56:59,655 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 21:56:59,656 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-29 21:56:59,656 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-29 21:56:59,657 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-29 21:56:59,657 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-29 21:56:59,657 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-29 21:56:59,664 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-29 21:56:59,664 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 21:56:59,664 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-29 21:56:59,664 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-29 21:56:59,665 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-29 21:56:59,665 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-29 21:56:59,665 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-29 21:56:59,670 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-29 21:56:59,670 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-29 21:56:59,670 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-29 21:56:59,675 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-29 21:56:59,675 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-29 21:56:59,678 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-29 21:56:59,678 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 21:56:59,678 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-29 21:56:59,678 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-29 21:56:59,831 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 2945@localhost
2017-09-29 21:56:59,848 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-29 21:56:59,873 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000658 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000658-0000000000000000769
2017-09-29 21:56:59,878 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000657, cpktTxId=0000000000000000657)
2017-09-29 21:56:59,908 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 69 INodes.
2017-09-29 21:56:59,939 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-29 21:56:59,939 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 657 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000657
2017-09-29 21:56:59,940 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@20f12539 expecting start txid #658
2017-09-29 21:56:59,940 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000658-0000000000000000769
2017-09-29 21:56:59,941 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000658-0000000000000000769' to transaction ID 658
2017-09-29 21:56:59,980 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job.jar
2017-09-29 21:56:59,980 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506704426452_0001/job.split
2017-09-29 21:56:59,996 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000658-0000000000000000769 of size 1048576 edits # 112 loaded in 0 seconds
2017-09-29 21:56:59,996 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2017-09-29 21:56:59,996 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2017-09-29 21:57:00,003 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/raji/hadoop_store/hdfs/namenode/current/fsimage.ckpt_0000000000000000769 using no compression
2017-09-29 21:57:00,054 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/raji/hadoop_store/hdfs/namenode/current/fsimage.ckpt_0000000000000000769 of size 5835 bytes saved in 0 seconds.
2017-09-29 21:57:00,064 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 657
2017-09-29 21:57:00,064 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000617, cpktTxId=0000000000000000617)
2017-09-29 21:57:00,079 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 770
2017-09-29 21:57:00,164 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-29 21:57:00,164 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 483 msecs
2017-09-29 21:57:00,454 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-29 21:57:00,463 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-29 21:57:00,474 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-29 21:57:00,537 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-29 21:57:00,544 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-29 21:57:00,544 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 16 blocks to reach the threshold 0.9990 of total blocks 17.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 21:57:00,574 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-29 21:57:00,574 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-29 21:57:00,585 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-29 21:57:00,598 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-29 21:57:00,598 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-29 21:57:00,603 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 5 milliseconds
name space=80
storage space=39282273
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-29 21:57:00,620 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-29 21:57:04,883 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-29 21:57:04,884 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-29 21:57:04,884 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-29 21:57:04,954 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-29 21:57:05,008 INFO BlockStateChange: BLOCK* processReport 0xdc8ecb08619ba26b: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-29 21:57:05,010 INFO BlockStateChange: BLOCK* processReport 0xdc8ecb08619ba26b: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 15, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2017-09-29 22:04:03,305 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1074ms
No GCs detected
2017-09-29 22:06:39,455 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-29 22:06:39,457 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1
************************************************************/
2017-09-29 22:08:04,785 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-29 22:08:04,794 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-29 22:08:04,799 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-29 22:08:05,046 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-29 22:08:05,122 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-29 22:08:05,122 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-29 22:08:05,137 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-29 22:08:05,139 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-29 22:08:05,223 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-29 22:08:05,336 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-29 22:08:05,354 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-29 22:08:05,398 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-29 22:08:05,406 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-29 22:08:05,412 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-29 22:08:05,418 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-29 22:08:05,421 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-29 22:08:05,421 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-29 22:08:05,421 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-29 22:08:05,514 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-29 22:08:05,515 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-29 22:08:05,534 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-29 22:08:05,534 INFO org.mortbay.log: jetty-6.1.26
2017-09-29 22:08:05,638 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-29 22:08:05,669 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-29 22:08:05,669 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-29 22:08:05,697 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-29 22:08:05,702 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-29 22:08:05,703 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-29 22:08:05,704 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-29 22:08:05,730 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-29 22:08:05,730 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-29 22:08:05,730 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-29 22:08:05,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 29 22:08:05
2017-09-29 22:08:05,732 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-29 22:08:05,732 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 22:08:05,733 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-29 22:08:05,733 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-29 22:08:05,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-29 22:08:05,748 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-29 22:08:05,748 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-29 22:08:05,748 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-29 22:08:05,748 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-29 22:08:05,748 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-29 22:08:05,748 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-29 22:08:05,748 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-29 22:08:05,753 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-29 22:08:05,753 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-29 22:08:05,753 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-29 22:08:05,753 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-29 22:08:05,754 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-29 22:08:05,806 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-29 22:08:05,806 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 22:08:05,807 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-29 22:08:05,807 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-29 22:08:05,808 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-29 22:08:05,808 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-29 22:08:05,808 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-29 22:08:05,815 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-29 22:08:05,815 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 22:08:05,815 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-29 22:08:05,815 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-29 22:08:05,817 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-29 22:08:05,817 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-29 22:08:05,817 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-29 22:08:05,821 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-29 22:08:05,821 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-29 22:08:05,821 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-29 22:08:05,825 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-29 22:08:05,826 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-29 22:08:05,828 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-29 22:08:05,828 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 22:08:05,829 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-29 22:08:05,829 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-29 22:08:05,892 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 6125@localhost
2017-09-29 22:08:05,908 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-29 22:08:05,932 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000770 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000770-0000000000000000770
2017-09-29 22:08:05,939 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000769, cpktTxId=0000000000000000769)
2017-09-29 22:08:05,973 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 80 INodes.
2017-09-29 22:08:06,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-29 22:08:06,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 769 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000769
2017-09-29 22:08:06,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@20f12539 expecting start txid #770
2017-09-29 22:08:06,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000770-0000000000000000770
2017-09-29 22:08:06,006 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000770-0000000000000000770' to transaction ID 770
2017-09-29 22:08:06,014 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000770-0000000000000000770 of size 1048576 edits # 1 loaded in 0 seconds
2017-09-29 22:08:06,015 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-09-29 22:08:06,015 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 771
2017-09-29 22:08:06,093 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-29 22:08:06,093 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 261 msecs
2017-09-29 22:08:06,209 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-29 22:08:06,213 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-29 22:08:06,221 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-29 22:08:06,261 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-29 22:08:06,267 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-29 22:08:06,268 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 16 blocks to reach the threshold 0.9990 of total blocks 17.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 22:08:06,296 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-29 22:08:06,296 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-29 22:08:06,301 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-29 22:08:06,303 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-29 22:08:06,303 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-29 22:08:06,316 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 12 milliseconds
name space=80
storage space=39282273
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-29 22:08:06,320 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-29 22:08:11,114 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-29 22:08:11,115 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-29 22:08:11,115 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-29 22:08:11,174 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-29 22:08:11,205 INFO BlockStateChange: BLOCK* processReport 0x69c5c55cb8cae726: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-29 22:08:11,207 INFO BlockStateChange: BLOCK* processReport 0x69c5c55cb8cae726: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 15, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2017-09-29 22:20:24,344 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1202ms
No GCs detected
2017-09-29 22:23:51,893 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000, call Call#4 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:57956: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /tmp/hive/root/db6f84b5-fa8d-4229-b4f1-ba98112e965c. Name node is in safe mode.
The reported blocks 15 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 17.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 22:25:57,302 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-29 22:25:57,305 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1
************************************************************/
2017-09-29 22:28:26,226 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-29 22:28:26,234 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-29 22:28:26,241 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-29 22:28:26,535 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-29 22:28:26,654 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-29 22:28:26,654 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-29 22:28:26,671 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-29 22:28:26,674 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-29 22:28:26,759 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-29 22:28:26,904 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-29 22:28:26,925 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-29 22:28:26,979 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-29 22:28:26,988 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-29 22:28:26,995 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-29 22:28:27,003 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-29 22:28:27,005 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-29 22:28:27,006 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-29 22:28:27,006 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-29 22:28:27,128 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-29 22:28:27,131 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-29 22:28:27,152 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-29 22:28:27,152 INFO org.mortbay.log: jetty-6.1.26
2017-09-29 22:28:27,404 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-29 22:28:27,434 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-29 22:28:27,435 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-29 22:28:27,475 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-29 22:28:27,481 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-29 22:28:27,482 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-29 22:28:27,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-29 22:28:27,514 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-29 22:28:27,514 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-29 22:28:27,515 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-29 22:28:27,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 29 22:28:27
2017-09-29 22:28:27,517 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-29 22:28:27,517 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 22:28:27,518 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-29 22:28:27,518 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-29 22:28:27,535 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-29 22:28:27,537 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-29 22:28:27,537 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-29 22:28:27,537 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-29 22:28:27,537 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-29 22:28:27,537 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-29 22:28:27,537 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-29 22:28:27,537 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-29 22:28:27,542 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-29 22:28:27,542 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-29 22:28:27,542 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-29 22:28:27,542 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-29 22:28:27,543 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-29 22:28:27,606 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-29 22:28:27,606 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 22:28:27,606 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-29 22:28:27,606 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-29 22:28:27,607 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-29 22:28:27,607 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-29 22:28:27,607 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-29 22:28:27,614 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-29 22:28:27,615 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 22:28:27,615 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-29 22:28:27,615 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-29 22:28:27,616 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-29 22:28:27,616 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-29 22:28:27,616 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-29 22:28:27,620 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-29 22:28:27,620 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-29 22:28:27,620 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-29 22:28:27,626 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-29 22:28:27,626 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-29 22:28:27,628 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-29 22:28:27,628 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 22:28:27,628 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-29 22:28:27,628 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-29 22:28:27,780 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 2854@localhost
2017-09-29 22:28:27,798 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-29 22:28:27,830 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000771 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000771-0000000000000000771
2017-09-29 22:28:27,838 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000769, cpktTxId=0000000000000000769)
2017-09-29 22:28:27,871 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 80 INodes.
2017-09-29 22:28:27,908 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-29 22:28:27,909 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 769 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000769
2017-09-29 22:28:27,909 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@77a98a6a expecting start txid #770
2017-09-29 22:28:27,909 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000770-0000000000000000770
2017-09-29 22:28:27,910 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000770-0000000000000000770' to transaction ID 770
2017-09-29 22:28:27,920 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000770-0000000000000000770 of size 1048576 edits # 1 loaded in 0 seconds
2017-09-29 22:28:27,920 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@78fbff54 expecting start txid #771
2017-09-29 22:28:27,920 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000771-0000000000000000771
2017-09-29 22:28:27,920 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000771-0000000000000000771' to transaction ID 770
2017-09-29 22:28:27,921 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000771-0000000000000000771 of size 1048576 edits # 1 loaded in 0 seconds
2017-09-29 22:28:27,921 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-09-29 22:28:27,921 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 772
2017-09-29 22:28:27,997 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-29 22:28:27,997 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 366 msecs
2017-09-29 22:28:28,198 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-29 22:28:28,206 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-29 22:28:28,215 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-29 22:28:28,274 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-29 22:28:28,281 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-29 22:28:28,281 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 16 blocks to reach the threshold 0.9990 of total blocks 17.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 22:28:28,312 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-29 22:28:28,312 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-29 22:28:28,317 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-29 22:28:28,321 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-29 22:28:28,322 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-29 22:28:28,328 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 5 milliseconds
name space=80
storage space=39282273
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-29 22:28:28,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-29 22:28:32,977 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-29 22:28:32,977 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-29 22:28:32,977 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-29 22:28:33,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-29 22:28:33,103 INFO BlockStateChange: BLOCK* processReport 0x7837c91dd293b02d: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-29 22:28:33,105 INFO BlockStateChange: BLOCK* processReport 0x7837c91dd293b02d: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 15, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2017-09-29 22:35:18,111 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1133ms
No GCs detected
2017-09-29 22:35:37,455 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1037ms
No GCs detected
2017-09-29 22:38:42,112 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1091ms
No GCs detected
2017-09-29 22:39:21,231 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1252ms
No GCs detected
2017-09-29 22:49:43,629 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1120ms
No GCs detected
2017-09-29 22:53:55,224 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1083ms
No GCs detected
2017-09-29 23:00:14,656 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1061ms
No GCs detected
2017-09-29 23:10:46,771 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000, call Call#4 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:59558: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /tmp/hive/root/6548b426-54e0-4b31-9751-570b470407f4. Name node is in safe mode.
The reported blocks 15 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 17.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 23:12:01,599 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2017-09-29 23:12:01,599 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 2614 secs
2017-09-29 23:12:01,599 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2017-09-29 23:12:01,600 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2017-09-29 23:12:01,600 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-29 23:12:01,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 17
2017-09-29 23:12:01,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-29 23:12:01,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 2
2017-09-29 23:12:01,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-29 23:12:01,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-09-29 23:12:01,609 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 10 msec
2017-09-29 23:12:14,864 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 52 Number of transactions batched in Syncs: 771 Number of syncs: 2 SyncTimes(ms): 4 
2017-09-29 23:13:18,197 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1044ms
No GCs detected
2017-09-29 23:13:32,393 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 8 Total time for transactions(ms): 54 Number of transactions batched in Syncs: 771 Number of syncs: 8 SyncTimes(ms): 16 
2017-09-29 23:14:55,546 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1201ms
No GCs detected
2017-09-29 23:17:43,729 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1139ms
No GCs detected
2017-09-29 23:20:46,876 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1051ms
No GCs detected
2017-09-29 23:25:03,521 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 11 Total time for transactions(ms): 54 Number of transactions batched in Syncs: 771 Number of syncs: 11 SyncTimes(ms): 23 
2017-09-29 23:27:05,356 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 17 Total time for transactions(ms): 54 Number of transactions batched in Syncs: 771 Number of syncs: 17 SyncTimes(ms): 34 
2017-09-29 23:27:39,102 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-29 23:27:39,102 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-29 23:27:39,103 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 772, 796
2017-09-29 23:27:39,103 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=797 lastSyncedTxid=796 mostRecentTxid=797
2017-09-29 23:27:39,108 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=797 lastSyncedTxid=797 mostRecentTxid=797
2017-09-29 23:27:39,108 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 26 Total time for transactions(ms): 55 Number of transactions batched in Syncs: 772 Number of syncs: 26 SyncTimes(ms): 53 
2017-09-29 23:27:39,114 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000772 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000772-0000000000000000797
2017-09-29 23:27:39,115 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 798
2017-09-29 23:27:40,478 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2500.00 KB/s
2017-09-29 23:27:40,478 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000797 size 6002 bytes.
2017-09-29 23:27:40,482 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 769
2017-09-29 23:27:40,482 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000657, cpktTxId=0000000000000000657)
2017-09-29 23:30:28,802 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 17 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 2 Number of syncs: 15 SyncTimes(ms): 26 
2017-09-29 23:31:52,197 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 24 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 2 Number of syncs: 22 SyncTimes(ms): 43 
2017-09-29 23:34:09,497 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 28 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 2 Number of syncs: 26 SyncTimes(ms): 54 
2017-09-29 23:35:22,572 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 32 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 2 Number of syncs: 30 SyncTimes(ms): 64 
2017-09-29 23:39:29,406 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 42 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 4 Number of syncs: 38 SyncTimes(ms): 78 
2017-09-29 23:40:54,076 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 56 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 6 Number of syncs: 50 SyncTimes(ms): 97 
2017-09-29 23:42:43,947 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 58 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 6 Number of syncs: 52 SyncTimes(ms): 103 
2017-09-29 23:45:25,691 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 60 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 6 Number of syncs: 54 SyncTimes(ms): 107 
2017-09-29 23:47:08,003 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1080ms
No GCs detected
2017-09-29 23:47:31,280 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1249ms
No GCs detected
2017-09-29 23:48:13,540 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1205ms
No GCs detected
2017-09-29 23:49:15,436 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1129ms
No GCs detected
2017-09-29 23:51:33,526 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-29 23:51:33,531 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1
************************************************************/
2017-09-29 23:52:49,741 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-29 23:52:49,749 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-29 23:52:49,756 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-29 23:52:49,987 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-29 23:52:50,057 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-29 23:52:50,057 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-29 23:52:50,071 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-29 23:52:50,074 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-29 23:52:50,165 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-29 23:52:50,274 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-29 23:52:50,292 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-29 23:52:50,338 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-29 23:52:50,348 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-29 23:52:50,355 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-29 23:52:50,361 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-29 23:52:50,362 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-29 23:52:50,363 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-29 23:52:50,363 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-29 23:52:50,453 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-29 23:52:50,455 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-29 23:52:50,474 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-29 23:52:50,474 INFO org.mortbay.log: jetty-6.1.26
2017-09-29 23:52:50,580 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-29 23:52:50,612 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-29 23:52:50,613 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-29 23:52:50,647 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-29 23:52:50,653 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-29 23:52:50,653 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-29 23:52:50,655 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-29 23:52:50,680 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-29 23:52:50,680 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-29 23:52:50,681 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-29 23:52:50,681 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 29 23:52:50
2017-09-29 23:52:50,683 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-29 23:52:50,683 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 23:52:50,684 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-29 23:52:50,684 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-29 23:52:50,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-29 23:52:50,702 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-29 23:52:50,702 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-29 23:52:50,702 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-29 23:52:50,702 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-29 23:52:50,702 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-29 23:52:50,702 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-29 23:52:50,702 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-29 23:52:50,709 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-29 23:52:50,709 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-29 23:52:50,709 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-29 23:52:50,709 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-29 23:52:50,710 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-29 23:52:50,763 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-29 23:52:50,763 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 23:52:50,763 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-29 23:52:50,763 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-29 23:52:50,764 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-29 23:52:50,764 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-29 23:52:50,764 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-29 23:52:50,771 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-29 23:52:50,771 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 23:52:50,771 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-29 23:52:50,771 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-29 23:52:50,772 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-29 23:52:50,773 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-29 23:52:50,773 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-29 23:52:50,777 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-29 23:52:50,777 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-29 23:52:50,777 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-29 23:52:50,781 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-29 23:52:50,781 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-29 23:52:50,783 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-29 23:52:50,783 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-29 23:52:50,783 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-29 23:52:50,783 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-29 23:52:50,841 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 11693@localhost
2017-09-29 23:52:50,858 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-29 23:52:50,881 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000798 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000798-0000000000000000857
2017-09-29 23:52:50,886 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000797, cpktTxId=0000000000000000797)
2017-09-29 23:52:50,918 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 82 INodes.
2017-09-29 23:52:50,956 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-29 23:52:50,956 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 797 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000797
2017-09-29 23:52:50,956 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@20f12539 expecting start txid #798
2017-09-29 23:52:50,956 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000798-0000000000000000857
2017-09-29 23:52:50,957 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000798-0000000000000000857' to transaction ID 798
2017-09-29 23:52:50,994 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000798-0000000000000000857 of size 1048576 edits # 60 loaded in 0 seconds
2017-09-29 23:52:50,995 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-09-29 23:52:50,995 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 858
2017-09-29 23:52:51,074 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-29 23:52:51,074 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 289 msecs
2017-09-29 23:52:51,191 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-29 23:52:51,195 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-29 23:52:51,204 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-29 23:52:51,262 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-29 23:52:51,271 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-29 23:52:51,271 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 23:52:51,304 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-29 23:52:51,304 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-29 23:52:51,311 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-29 23:52:51,323 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-29 23:52:51,323 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-29 23:52:51,327 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 4 milliseconds
name space=79
storage space=22062622
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-29 23:52:51,330 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-29 23:52:56,177 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-29 23:52:56,178 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-29 23:52:56,179 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-29 23:52:56,238 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-29 23:52:56,271 INFO BlockStateChange: BLOCK* processReport 0xfa82fbdf60e56c13: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-29 23:52:56,273 INFO BlockStateChange: BLOCK* processReport 0xfa82fbdf60e56c13: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 14, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2017-09-29 23:54:01,149 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call Call#1 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59766: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 23:55:01,197 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000, call Call#3 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59768: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 23:56:01,230 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call Call#5 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59774: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 23:57:01,266 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call Call#7 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59776: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 23:58:01,281 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call Call#9 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59778: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-29 23:59:01,394 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000, call Call#11 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59780: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 00:00:01,441 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000, call Call#13 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59782: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 00:01:01,458 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000, call Call#15 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59784: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 00:02:01,482 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000, call Call#17 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59786: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 00:03:01,519 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000, call Call#19 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59788: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 00:03:17,984 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1225ms
No GCs detected
2017-09-30 00:04:01,581 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000, call Call#21 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59790: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 00:05:01,612 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000, call Call#23 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59792: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 00:06:01,645 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000, call Call#25 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59794: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 00:07:01,691 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000, call Call#27 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59796: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 00:08:01,714 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000, call Call#29 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59798: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 00:09:01,801 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000, call Call#31 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59800: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 00:10:01,840 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000, call Call#33 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59802: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 00:11:01,882 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000, call Call#35 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59804: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 00:12:01,913 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000, call Call#37 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59806: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 00:13:01,944 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000, call Call#39 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59808: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 00:13:57,540 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000, call Call#4 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:59810: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /tmp/hive/root/95f21442-6afb-46f1-8861-3c7f2b36403f. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 00:14:02,002 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000, call Call#41 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 127.0.0.1:59812: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 14 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 16.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 00:14:30,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2017-09-30 00:14:30,086 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1299 secs
2017-09-30 00:14:30,086 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2017-09-30 00:14:30,086 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2017-09-30 00:14:30,086 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-30 00:14:30,094 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 16
2017-09-30 00:14:30,094 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-30 00:14:30,094 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 2
2017-09-30 00:14:30,095 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-30 00:14:30,095 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-09-30 00:14:30,095 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2017-09-30 00:14:43,571 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 857 Number of syncs: 2 SyncTimes(ms): 7 
2017-09-30 00:15:02,039 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-30 00:15:02,039 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-30 00:15:02,039 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 858, 860
2017-09-30 00:15:02,040 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=861 lastSyncedTxid=860 mostRecentTxid=861
2017-09-30 00:15:02,044 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=861 lastSyncedTxid=861 mostRecentTxid=861
2017-09-30 00:15:02,044 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 857 Number of syncs: 5 SyncTimes(ms): 15 
2017-09-30 00:15:02,050 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000858 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000858-0000000000000000861
2017-09-30 00:15:02,050 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 862
2017-09-30 00:15:03,134 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2500.00 KB/s
2017-09-30 00:15:03,134 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000861 size 5927 bytes.
2017-09-30 00:15:03,137 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 797
2017-09-30 00:15:03,137 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000769, cpktTxId=0000000000000000769)
2017-09-30 00:16:03,310 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 32 
2017-09-30 00:18:52,217 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 11 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 1 Number of syncs: 10 SyncTimes(ms): 36 
2017-09-30 00:18:52,459 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741882_1062, replicas=127.0.0.1:50010 for /tmp/hive/root/b88ff3b8-198f-4150-bf70-f90219fe5f45/hive_2017-09-30_00-18-52_152_2684687446596334703-1/-mr-10003/1bcc6ebe-0995-4edc-a79c-a76828da2c56/map.xml
2017-09-30 00:18:52,499 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741882_1062 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/b88ff3b8-198f-4150-bf70-f90219fe5f45/hive_2017-09-30_00-18-52_152_2684687446596334703-1/-mr-10003/1bcc6ebe-0995-4edc-a79c-a76828da2c56/map.xml
2017-09-30 00:18:52,499 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2017-09-30 00:18:52,909 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/b88ff3b8-198f-4150-bf70-f90219fe5f45/hive_2017-09-30_00-18-52_152_2684687446596334703-1/-mr-10003/1bcc6ebe-0995-4edc-a79c-a76828da2c56/map.xml is closed by DFSClient_NONMAPREDUCE_-9224089_1
2017-09-30 00:18:52,949 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/b88ff3b8-198f-4150-bf70-f90219fe5f45/hive_2017-09-30_00-18-52_152_2684687446596334703-1/-mr-10003/1bcc6ebe-0995-4edc-a79c-a76828da2c56/map.xml
2017-09-30 00:18:53,561 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000, call Call#78 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:59836: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/b88ff3b8-198f-4150-bf70-f90219fe5f45/hive_2017-09-30_00-18-52_152_2684687446596334703-1/-mr-10003/1bcc6ebe-0995-4edc-a79c-a76828da2c56/reduce.xml
2017-09-30 00:18:53,670 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741883_1063, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/libjars/hive-json-serde-0.3.jar
2017-09-30 00:18:53,754 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741883_1063 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/libjars/hive-json-serde-0.3.jar
2017-09-30 00:18:54,158 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/libjars/hive-json-serde-0.3.jar is closed by DFSClient_NONMAPREDUCE_-9224089_1
2017-09-30 00:18:54,166 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/libjars/hive-json-serde-0.3.jar
2017-09-30 00:18:54,194 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741884_1064, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job.jar
2017-09-30 00:18:54,552 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741884_1064 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job.jar
2017-09-30 00:18:54,957 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job.jar is closed by DFSClient_NONMAPREDUCE_-9224089_1
2017-09-30 00:18:54,964 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job.jar
2017-09-30 00:18:55,132 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job.split
2017-09-30 00:18:55,138 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741885_1065, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job.split
2017-09-30 00:18:55,196 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741885_1065 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job.split
2017-09-30 00:18:55,599 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job.split is closed by DFSClient_NONMAPREDUCE_-9224089_1
2017-09-30 00:18:55,611 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741886_1066, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job.splitmetainfo
2017-09-30 00:18:55,624 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741886_1066 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job.splitmetainfo
2017-09-30 00:18:56,029 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-9224089_1
2017-09-30 00:18:56,148 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741887_1067, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job.xml
2017-09-30 00:18:56,186 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job.xml is closed by DFSClient_NONMAPREDUCE_-9224089_1
2017-09-30 00:19:06,568 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741888_1068, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job_1506747333911_0001_1_conf.xml
2017-09-30 00:19:06,688 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job_1506747333911_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_288913750_1
2017-09-30 00:19:13,738 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741889_1069, replicas=127.0.0.1:50010 for /tmp/hive/root/b88ff3b8-198f-4150-bf70-f90219fe5f45/hive_2017-09-30_00-18-52_152_2684687446596334703-1/_task_tmp.-mr-10000/_tmp.000000_0
2017-09-30 00:19:16,464 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/b88ff3b8-198f-4150-bf70-f90219fe5f45/hive_2017-09-30_00-18-52_152_2684687446596334703-1/_task_tmp.-mr-10000/_tmp.000000_0 is closed by DFSClient_attempt_1506747333911_0001_m_000000_0_-1224689180_1
2017-09-30 00:19:16,622 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741890_1070, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job_1506747333911_0001_1.jhist
2017-09-30 00:19:16,645 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job_1506747333911_0001_1.jhist for DFSClient_NONMAPREDUCE_288913750_1
2017-09-30 00:19:16,646 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_288913750_1
2017-09-30 00:19:16,666 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_288913750_1
2017-09-30 00:19:16,698 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0001/job_1506747333911_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_288913750_1
2017-09-30 00:19:16,720 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741891_1071, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0001.summary_tmp
2017-09-30 00:19:16,738 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_288913750_1
2017-09-30 00:19:16,777 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741892_1072, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0001-1506748736450-root-INSERT+OVERWRITE+LOCAL+DIRECTO...twitterkeys%28Sta-1506748756680-1-0-SUCCEEDED-default-1506748746384.jhist_tmp
2017-09-30 00:19:16,786 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0001-1506748736450-root-INSERT+OVERWRITE+LOCAL+DIRECTO...twitterkeys%28Sta-1506748756680-1-0-SUCCEEDED-default-1506748746384.jhist_tmp is closed by DFSClient_NONMAPREDUCE_288913750_1
2017-09-30 00:19:16,828 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741893_1073, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0001_conf.xml_tmp
2017-09-30 00:19:16,838 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_288913750_1
2017-09-30 00:20:30,122 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 112 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 27 Number of syncs: 85 SyncTimes(ms): 101 
2017-09-30 00:30:17,531 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 114 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 27 Number of syncs: 87 SyncTimes(ms): 105 
2017-09-30 00:32:52,524 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 130 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 29 Number of syncs: 101 SyncTimes(ms): 129 
2017-09-30 00:32:52,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741894_1074, replicas=127.0.0.1:50010 for /tmp/hive/root/88c8cc19-eb7d-4876-b8ae-eeba4a0d997c/hive_2017-09-30_00-32-52_459_895553208968385729-1/-mr-10003/e065aad7-1fcb-4fa6-aa54-726a9db80796/map.xml
2017-09-30 00:32:52,759 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/88c8cc19-eb7d-4876-b8ae-eeba4a0d997c/hive_2017-09-30_00-32-52_459_895553208968385729-1/-mr-10003/e065aad7-1fcb-4fa6-aa54-726a9db80796/map.xml is closed by DFSClient_NONMAPREDUCE_1335889370_1
2017-09-30 00:32:52,767 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/88c8cc19-eb7d-4876-b8ae-eeba4a0d997c/hive_2017-09-30_00-32-52_459_895553208968385729-1/-mr-10003/e065aad7-1fcb-4fa6-aa54-726a9db80796/map.xml
2017-09-30 00:32:53,112 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call Call#97 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:59944: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/88c8cc19-eb7d-4876-b8ae-eeba4a0d997c/hive_2017-09-30_00-32-52_459_895553208968385729-1/-mr-10003/e065aad7-1fcb-4fa6-aa54-726a9db80796/reduce.xml
2017-09-30 00:32:53,228 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741895_1075, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/libjars/hive-json-serde-0.3.jar
2017-09-30 00:32:53,318 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741895_1075 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/libjars/hive-json-serde-0.3.jar
2017-09-30 00:32:53,722 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/libjars/hive-json-serde-0.3.jar is closed by DFSClient_NONMAPREDUCE_1335889370_1
2017-09-30 00:32:53,732 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/libjars/hive-json-serde-0.3.jar
2017-09-30 00:32:53,767 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741896_1076, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job.jar
2017-09-30 00:32:53,994 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job.jar is closed by DFSClient_NONMAPREDUCE_1335889370_1
2017-09-30 00:32:53,998 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job.jar
2017-09-30 00:32:54,052 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job.split
2017-09-30 00:32:54,056 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741897_1077, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job.split
2017-09-30 00:32:54,066 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741897_1077 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job.split
2017-09-30 00:32:54,469 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job.split is closed by DFSClient_NONMAPREDUCE_1335889370_1
2017-09-30 00:32:54,501 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741898_1078, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job.splitmetainfo
2017-09-30 00:32:54,526 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741898_1078 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job.splitmetainfo
2017-09-30 00:32:54,931 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1335889370_1
2017-09-30 00:32:55,034 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741899_1079, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job.xml
2017-09-30 00:32:55,080 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741899_1079 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job.xml
2017-09-30 00:32:55,483 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job.xml is closed by DFSClient_NONMAPREDUCE_1335889370_1
2017-09-30 00:33:01,055 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741900_1080, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job_1506747333911_0002_1_conf.xml
2017-09-30 00:33:01,136 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741900_1080 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job_1506747333911_0002_1_conf.xml
2017-09-30 00:33:01,544 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job_1506747333911_0002_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1730412632_1
2017-09-30 00:33:06,665 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741901_1081, replicas=127.0.0.1:50010 for /tmp/hive/root/88c8cc19-eb7d-4876-b8ae-eeba4a0d997c/hive_2017-09-30_00-32-52_459_895553208968385729-1/_task_tmp.-mr-10000/_tmp.000000_0
2017-09-30 00:33:08,927 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/88c8cc19-eb7d-4876-b8ae-eeba4a0d997c/hive_2017-09-30_00-32-52_459_895553208968385729-1/_task_tmp.-mr-10000/_tmp.000000_0 is closed by DFSClient_attempt_1506747333911_0002_m_000000_0_-1227702749_1
2017-09-30 00:33:09,048 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741902_1082, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job_1506747333911_0002_1.jhist
2017-09-30 00:33:09,051 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1730412632_1
2017-09-30 00:33:09,069 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job_1506747333911_0002_1.jhist for DFSClient_NONMAPREDUCE_-1730412632_1
2017-09-30 00:33:09,070 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1730412632_1
2017-09-30 00:33:09,133 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0002/job_1506747333911_0002_1.jhist is closed by DFSClient_NONMAPREDUCE_-1730412632_1
2017-09-30 00:33:09,140 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741903_1083, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0002.summary_tmp
2017-09-30 00:33:09,151 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0002.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1730412632_1
2017-09-30 00:33:09,191 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741904_1084, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0002-1506749575748-root-INSERT+OVERWRITE+LOCAL+DIRECTO...twitterkeys%28Sta-1506749589118-1-0-SUCCEEDED-default-1506749580851.jhist_tmp
2017-09-30 00:33:09,215 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0002-1506749575748-root-INSERT+OVERWRITE+LOCAL+DIRECTO...twitterkeys%28Sta-1506749589118-1-0-SUCCEEDED-default-1506749580851.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1730412632_1
2017-09-30 00:33:09,423 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741905_1085, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0002_conf.xml_tmp
2017-09-30 00:33:09,441 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741905_1085 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0002_conf.xml_tmp
2017-09-30 00:33:09,846 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0002_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1730412632_1
2017-09-30 00:34:46,288 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1038ms
No GCs detected
2017-09-30 00:35:12,296 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 230 Total time for transactions(ms): 28 Number of transactions batched in Syncs: 56 Number of syncs: 174 SyncTimes(ms): 236 
2017-09-30 00:35:12,330 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741906_1086, replicas=127.0.0.1:50010 for /test/twitterkeys.txt._COPYING_
2017-09-30 00:35:12,390 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/twitterkeys.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_1268408279_1
2017-09-30 00:40:31,741 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 236 Total time for transactions(ms): 28 Number of transactions batched in Syncs: 58 Number of syncs: 178 SyncTimes(ms): 240 
2017-09-30 00:40:31,796 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741907_1087, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/job.jar
2017-09-30 00:40:31,848 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/job.jar is closed by DFSClient_NONMAPREDUCE_-141275214_1
2017-09-30 00:40:31,852 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/job.jar
2017-09-30 00:40:31,884 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/job.split
2017-09-30 00:40:31,891 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741908_1088, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/job.split
2017-09-30 00:40:31,898 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/job.split is closed by DFSClient_NONMAPREDUCE_-141275214_1
2017-09-30 00:40:31,908 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741909_1089, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/job.splitmetainfo
2017-09-30 00:40:31,920 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-141275214_1
2017-09-30 00:40:32,017 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741910_1090, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/job.xml
2017-09-30 00:40:32,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741910_1090 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/job.xml
2017-09-30 00:40:32,435 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/job.xml is closed by DFSClient_NONMAPREDUCE_-141275214_1
2017-09-30 00:40:38,057 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741911_1091, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/job_1506747333911_0003_1_conf.xml
2017-09-30 00:40:38,090 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/job_1506747333911_0003_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-208974243_1
2017-09-30 00:40:42,613 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741912_1092, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/job_1506747333911_0003_1.jhist
2017-09-30 00:40:42,619 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/job_1506747333911_0003_1.jhist for DFSClient_NONMAPREDUCE_-208974243_1
2017-09-30 00:40:47,403 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741913_1093, replicas=127.0.0.1:50010 for /test/out/_temporary/1/_temporary/attempt_1506747333911_0003_r_000000_0/part-r-00000
2017-09-30 00:40:47,472 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/out/_temporary/1/_temporary/attempt_1506747333911_0003_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1506747333911_0003_r_000000_0_889539046_1
2017-09-30 00:40:47,558 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-208974243_1
2017-09-30 00:40:47,603 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/out/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-208974243_1
2017-09-30 00:40:47,607 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-208974243_1
2017-09-30 00:40:47,621 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0003/job_1506747333911_0003_1.jhist is closed by DFSClient_NONMAPREDUCE_-208974243_1
2017-09-30 00:40:47,628 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741914_1094, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0003.summary_tmp
2017-09-30 00:40:47,640 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0003.summary_tmp is closed by DFSClient_NONMAPREDUCE_-208974243_1
2017-09-30 00:40:47,679 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741915_1095, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0003-1506750032697-root-word+count-1506750047608-1-1-SUCCEEDED-default-1506750037919.jhist_tmp
2017-09-30 00:40:47,686 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741915_1095 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0003-1506750032697-root-word+count-1506750047608-1-1-SUCCEEDED-default-1506750037919.jhist_tmp
2017-09-30 00:40:48,090 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0003-1506750032697-root-word+count-1506750047608-1-1-SUCCEEDED-default-1506750037919.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-208974243_1
2017-09-30 00:40:48,146 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741916_1096, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0003_conf.xml_tmp
2017-09-30 00:40:48,177 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741916_1096 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0003_conf.xml_tmp
2017-09-30 00:40:48,582 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0003_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-208974243_1
2017-09-30 00:44:15,110 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1215ms
No GCs detected
2017-09-30 00:44:36,188 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 316 Total time for transactions(ms): 33 Number of transactions batched in Syncs: 82 Number of syncs: 234 SyncTimes(ms): 298 
2017-09-30 00:47:48,978 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 318 Total time for transactions(ms): 34 Number of transactions batched in Syncs: 82 Number of syncs: 236 SyncTimes(ms): 301 
2017-09-30 00:49:03,953 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 320 Total time for transactions(ms): 34 Number of transactions batched in Syncs: 82 Number of syncs: 238 SyncTimes(ms): 302 
2017-09-30 00:50:13,242 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 327 Total time for transactions(ms): 36 Number of transactions batched in Syncs: 82 Number of syncs: 245 SyncTimes(ms): 313 
2017-09-30 00:51:11,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741917_1097, replicas=127.0.0.1:50010 for /tmp/hive/root/94d65fc7-196d-44a1-aba9-e18c389190c2/hive_2017-09-30_00-51-11_420_7859826590997985509-1/-mr-10003/615b293f-d64e-4417-8742-0288e5feecb7/map.xml
2017-09-30 00:51:11,718 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/94d65fc7-196d-44a1-aba9-e18c389190c2/hive_2017-09-30_00-51-11_420_7859826590997985509-1/-mr-10003/615b293f-d64e-4417-8742-0288e5feecb7/map.xml is closed by DFSClient_NONMAPREDUCE_1936817680_1
2017-09-30 00:51:11,725 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/94d65fc7-196d-44a1-aba9-e18c389190c2/hive_2017-09-30_00-51-11_420_7859826590997985509-1/-mr-10003/615b293f-d64e-4417-8742-0288e5feecb7/map.xml
2017-09-30 00:51:12,124 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000, call Call#63 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:60136: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/94d65fc7-196d-44a1-aba9-e18c389190c2/hive_2017-09-30_00-51-11_420_7859826590997985509-1/-mr-10003/615b293f-d64e-4417-8742-0288e5feecb7/reduce.xml
2017-09-30 00:51:12,220 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741918_1098, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/libjars/hive-json-serde-0.3.jar
2017-09-30 00:51:12,299 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741918_1098 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/libjars/hive-json-serde-0.3.jar
2017-09-30 00:51:12,704 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/libjars/hive-json-serde-0.3.jar is closed by DFSClient_NONMAPREDUCE_1936817680_1
2017-09-30 00:51:12,714 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/libjars/hive-json-serde-0.3.jar
2017-09-30 00:51:12,739 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741919_1099, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/job.jar
2017-09-30 00:51:12,964 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/job.jar is closed by DFSClient_NONMAPREDUCE_1936817680_1
2017-09-30 00:51:12,969 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/job.jar
2017-09-30 00:51:13,026 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/job.split
2017-09-30 00:51:13,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741920_1100, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/job.split
2017-09-30 00:51:13,041 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741920_1100 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/job.split
2017-09-30 00:51:13,443 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/job.split is closed by DFSClient_NONMAPREDUCE_1936817680_1
2017-09-30 00:51:13,443 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 375 Total time for transactions(ms): 39 Number of transactions batched in Syncs: 94 Number of syncs: 281 SyncTimes(ms): 377 
2017-09-30 00:51:13,460 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741921_1101, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/job.splitmetainfo
2017-09-30 00:51:13,480 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1936817680_1
2017-09-30 00:51:13,523 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741922_1102, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/job.xml
2017-09-30 00:51:13,544 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741922_1102 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/job.xml
2017-09-30 00:51:13,950 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/job.xml is closed by DFSClient_NONMAPREDUCE_1936817680_1
2017-09-30 00:51:19,687 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741923_1103, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/job_1506747333911_0004_1_conf.xml
2017-09-30 00:51:19,744 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/job_1506747333911_0004_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1026772542_1
2017-09-30 00:51:27,148 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741924_1104, replicas=127.0.0.1:50010 for /tmp/hive/root/94d65fc7-196d-44a1-aba9-e18c389190c2/hive_2017-09-30_00-51-11_420_7859826590997985509-1/_task_tmp.-mr-10000/_tmp.000000_0
2017-09-30 00:51:28,275 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/94d65fc7-196d-44a1-aba9-e18c389190c2/hive_2017-09-30_00-51-11_420_7859826590997985509-1/_task_tmp.-mr-10000/_tmp.000000_0 is closed by DFSClient_attempt_1506747333911_0004_m_000000_0_-1109707597_1
2017-09-30 00:51:28,398 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741925_1105, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/job_1506747333911_0004_1.jhist
2017-09-30 00:51:28,423 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/job_1506747333911_0004_1.jhist for DFSClient_NONMAPREDUCE_-1026772542_1
2017-09-30 00:51:28,424 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1026772542_1
2017-09-30 00:51:28,455 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1026772542_1
2017-09-30 00:51:28,482 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0004/job_1506747333911_0004_1.jhist is closed by DFSClient_NONMAPREDUCE_-1026772542_1
2017-09-30 00:51:28,500 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741926_1106, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0004.summary_tmp
2017-09-30 00:51:28,511 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0004.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1026772542_1
2017-09-30 00:51:28,674 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741927_1107, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0004-1506750674265-root-INSERT+OVERWRITE+LOCAL+DIRECTO...twitterkeys%28Sta-1506750688457-1-0-SUCCEEDED-default-1506750679478.jhist_tmp
2017-09-30 00:51:28,697 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0004-1506750674265-root-INSERT+OVERWRITE+LOCAL+DIRECTO...twitterkeys%28Sta-1506750688457-1-0-SUCCEEDED-default-1506750679478.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1026772542_1
2017-09-30 00:51:28,713 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741928_1108, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0004_conf.xml_tmp
2017-09-30 00:51:28,723 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0004_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1026772542_1
2017-09-30 00:51:39,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741929_1109, replicas=127.0.0.1:50010 for /tmp/hive/root/94d65fc7-196d-44a1-aba9-e18c389190c2/hive_2017-09-30_00-51-39_158_1764046535225112371-1/-mr-10003/2ebac62d-0f32-4fcb-9205-9bfa043b6a3e/map.xml
2017-09-30 00:51:39,285 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/94d65fc7-196d-44a1-aba9-e18c389190c2/hive_2017-09-30_00-51-39_158_1764046535225112371-1/-mr-10003/2ebac62d-0f32-4fcb-9205-9bfa043b6a3e/map.xml is closed by DFSClient_NONMAPREDUCE_1936817680_1
2017-09-30 00:51:39,286 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/94d65fc7-196d-44a1-aba9-e18c389190c2/hive_2017-09-30_00-51-39_158_1764046535225112371-1/-mr-10003/2ebac62d-0f32-4fcb-9205-9bfa043b6a3e/map.xml
2017-09-30 00:51:39,373 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9000, call Call#241 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:60192: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/94d65fc7-196d-44a1-aba9-e18c389190c2/hive_2017-09-30_00-51-39_158_1764046535225112371-1/-mr-10003/2ebac62d-0f32-4fcb-9205-9bfa043b6a3e/reduce.xml
2017-09-30 00:51:39,412 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741930_1110, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/libjars/hive-json-serde-0.3.jar
2017-09-30 00:51:39,445 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/libjars/hive-json-serde-0.3.jar is closed by DFSClient_NONMAPREDUCE_1936817680_1
2017-09-30 00:51:39,447 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/libjars/hive-json-serde-0.3.jar
2017-09-30 00:51:39,453 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741931_1111, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/job.jar
2017-09-30 00:51:39,568 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/job.jar is closed by DFSClient_NONMAPREDUCE_1936817680_1
2017-09-30 00:51:39,569 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/job.jar
2017-09-30 00:51:39,586 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/job.split
2017-09-30 00:51:39,587 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741932_1112, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/job.split
2017-09-30 00:51:39,593 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/job.split is closed by DFSClient_NONMAPREDUCE_1936817680_1
2017-09-30 00:51:39,598 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741933_1113, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/job.splitmetainfo
2017-09-30 00:51:39,604 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1936817680_1
2017-09-30 00:51:39,617 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741934_1114, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/job.xml
2017-09-30 00:51:39,637 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741934_1114 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/job.xml
2017-09-30 00:51:40,043 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/job.xml is closed by DFSClient_NONMAPREDUCE_1936817680_1
2017-09-30 00:51:45,171 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741935_1115, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/job_1506747333911_0005_1_conf.xml
2017-09-30 00:51:45,207 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/job_1506747333911_0005_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1681743192_1
2017-09-30 00:51:51,074 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741936_1116, replicas=127.0.0.1:50010 for /tmp/hive/root/94d65fc7-196d-44a1-aba9-e18c389190c2/hive_2017-09-30_00-51-39_158_1764046535225112371-1/_task_tmp.-mr-10000/_tmp.000000_0
2017-09-30 00:51:52,992 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/94d65fc7-196d-44a1-aba9-e18c389190c2/hive_2017-09-30_00-51-39_158_1764046535225112371-1/_task_tmp.-mr-10000/_tmp.000000_0 is closed by DFSClient_attempt_1506747333911_0005_m_000000_0_-1790927246_1
2017-09-30 00:51:53,097 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741937_1117, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/job_1506747333911_0005_1.jhist
2017-09-30 00:51:53,128 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/job_1506747333911_0005_1.jhist for DFSClient_NONMAPREDUCE_1681743192_1
2017-09-30 00:51:53,128 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1681743192_1
2017-09-30 00:51:53,133 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1681743192_1
2017-09-30 00:51:53,181 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0005/job_1506747333911_0005_1.jhist is closed by DFSClient_NONMAPREDUCE_1681743192_1
2017-09-30 00:51:53,189 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741938_1118, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0005.summary_tmp
2017-09-30 00:51:53,200 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741938_1118 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0005.summary_tmp
2017-09-30 00:51:53,605 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0005.summary_tmp is closed by DFSClient_NONMAPREDUCE_1681743192_1
2017-09-30 00:51:53,697 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741939_1119, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0005-1506750700132-root-INSERT+OVERWRITE+LOCAL+DIRECTO...twitterkeys%28Sta-1506750713149-1-0-SUCCEEDED-default-1506750705022.jhist_tmp
2017-09-30 00:51:53,735 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0005-1506750700132-root-INSERT+OVERWRITE+LOCAL+DIRECTO...twitterkeys%28Sta-1506750713149-1-0-SUCCEEDED-default-1506750705022.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1681743192_1
2017-09-30 00:51:53,759 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741940_1120, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0005_conf.xml_tmp
2017-09-30 00:51:53,768 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0005_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1681743192_1
2017-09-30 00:55:40,614 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 536 Total time for transactions(ms): 47 Number of transactions batched in Syncs: 138 Number of syncs: 398 SyncTimes(ms): 477 
2017-09-30 00:57:21,039 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 537 Total time for transactions(ms): 47 Number of transactions batched in Syncs: 138 Number of syncs: 399 SyncTimes(ms): 480 
2017-09-30 00:57:21,074 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741941_1121, replicas=127.0.0.1:50010 for /test/urls.csv._COPYING_
2017-09-30 00:57:21,130 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/urls.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1517142673_1
2017-09-30 00:57:46,469 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741942_1122, replicas=127.0.0.1:50010 for /test/hashtags.csv._COPYING_
2017-09-30 00:57:46,519 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/hashtags.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1687850523_1
2017-09-30 00:59:46,318 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 549 Total time for transactions(ms): 48 Number of transactions batched in Syncs: 142 Number of syncs: 407 SyncTimes(ms): 487 
2017-09-30 00:59:46,377 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741943_1123, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0006/job.jar
2017-09-30 00:59:46,430 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0006/job.jar is closed by DFSClient_NONMAPREDUCE_-1759041472_1
2017-09-30 00:59:46,434 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0006/job.jar
2017-09-30 01:00:08,745 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741944_1124, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/job.jar
2017-09-30 01:00:08,794 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/job.jar is closed by DFSClient_NONMAPREDUCE_-354182389_1
2017-09-30 01:00:08,798 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/job.jar
2017-09-30 01:00:08,834 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/job.split
2017-09-30 01:00:08,844 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741945_1125, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/job.split
2017-09-30 01:00:08,855 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741945_1125 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/job.split
2017-09-30 01:00:09,260 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/job.split is closed by DFSClient_NONMAPREDUCE_-354182389_1
2017-09-30 01:00:09,297 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741946_1126, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/job.splitmetainfo
2017-09-30 01:00:09,326 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-354182389_1
2017-09-30 01:00:09,523 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741947_1127, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/job.xml
2017-09-30 01:00:09,543 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/job.xml is closed by DFSClient_NONMAPREDUCE_-354182389_1
2017-09-30 01:00:14,616 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741948_1128, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/job_1506747333911_0007_1_conf.xml
2017-09-30 01:00:14,657 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/job_1506747333911_0007_1_conf.xml is closed by DFSClient_NONMAPREDUCE_2084737675_1
2017-09-30 01:00:19,414 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741949_1129, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/job_1506747333911_0007_1.jhist
2017-09-30 01:00:19,422 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/job_1506747333911_0007_1.jhist for DFSClient_NONMAPREDUCE_2084737675_1
2017-09-30 01:00:23,896 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741950_1130, replicas=127.0.0.1:50010 for /test/hashtags/_temporary/1/_temporary/attempt_1506747333911_0007_r_000000_0/part-r-00000
2017-09-30 01:00:23,952 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/hashtags/_temporary/1/_temporary/attempt_1506747333911_0007_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1506747333911_0007_r_000000_0_-798729292_1
2017-09-30 01:00:24,045 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_2084737675_1
2017-09-30 01:00:24,067 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/hashtags/_SUCCESS is closed by DFSClient_NONMAPREDUCE_2084737675_1
2017-09-30 01:00:24,070 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_2084737675_1
2017-09-30 01:00:24,086 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0007/job_1506747333911_0007_1.jhist is closed by DFSClient_NONMAPREDUCE_2084737675_1
2017-09-30 01:00:24,094 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741951_1131, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0007.summary_tmp
2017-09-30 01:00:24,102 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0007.summary_tmp is closed by DFSClient_NONMAPREDUCE_2084737675_1
2017-09-30 01:00:24,135 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741952_1132, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0007-1506751209714-root-word+count-1506751224072-1-1-SUCCEEDED-default-1506751214429.jhist_tmp
2017-09-30 01:00:24,144 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0007-1506751209714-root-word+count-1506751224072-1-1-SUCCEEDED-default-1506751214429.jhist_tmp is closed by DFSClient_NONMAPREDUCE_2084737675_1
2017-09-30 01:00:24,160 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741953_1133, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0007_conf.xml_tmp
2017-09-30 01:00:24,170 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741953_1133 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0007_conf.xml_tmp
2017-09-30 01:00:24,573 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0007_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_2084737675_1
2017-09-30 01:05:27,238 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 639 Total time for transactions(ms): 51 Number of transactions batched in Syncs: 168 Number of syncs: 471 SyncTimes(ms): 546 
2017-09-30 01:05:27,300 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741954_1134, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0008/job.jar
2017-09-30 01:05:27,354 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0008/job.jar is closed by DFSClient_NONMAPREDUCE_1664382931_1
2017-09-30 01:05:27,359 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0008/job.jar
2017-09-30 01:05:54,426 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741955_1135, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/job.jar
2017-09-30 01:05:54,478 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/job.jar is closed by DFSClient_NONMAPREDUCE_1914528042_1
2017-09-30 01:05:54,483 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/job.jar
2017-09-30 01:05:54,513 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/job.split
2017-09-30 01:05:54,521 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741956_1136, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/job.split
2017-09-30 01:05:54,529 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/job.split is closed by DFSClient_NONMAPREDUCE_1914528042_1
2017-09-30 01:05:54,542 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741957_1137, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/job.splitmetainfo
2017-09-30 01:05:54,550 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741957_1137 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/job.splitmetainfo
2017-09-30 01:05:54,953 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1914528042_1
2017-09-30 01:05:55,141 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741958_1138, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/job.xml
2017-09-30 01:05:55,154 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741958_1138 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/job.xml
2017-09-30 01:05:55,558 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/job.xml is closed by DFSClient_NONMAPREDUCE_1914528042_1
2017-09-30 01:06:00,887 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741959_1139, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/job_1506747333911_0009_1_conf.xml
2017-09-30 01:06:00,956 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/job_1506747333911_0009_1_conf.xml is closed by DFSClient_NONMAPREDUCE_745291199_1
2017-09-30 01:06:05,431 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741960_1140, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/job_1506747333911_0009_1.jhist
2017-09-30 01:06:05,439 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/job_1506747333911_0009_1.jhist for DFSClient_NONMAPREDUCE_745291199_1
2017-09-30 01:06:10,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741961_1141, replicas=127.0.0.1:50010 for /test/urls/_temporary/1/_temporary/attempt_1506747333911_0009_r_000000_0/part-r-00000
2017-09-30 01:06:10,270 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/urls/_temporary/1/_temporary/attempt_1506747333911_0009_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1506747333911_0009_r_000000_0_-130849127_1
2017-09-30 01:06:10,364 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_745291199_1
2017-09-30 01:06:10,390 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/urls/_SUCCESS is closed by DFSClient_NONMAPREDUCE_745291199_1
2017-09-30 01:06:10,394 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_745291199_1
2017-09-30 01:06:10,413 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506747333911_0009/job_1506747333911_0009_1.jhist is closed by DFSClient_NONMAPREDUCE_745291199_1
2017-09-30 01:06:10,421 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741962_1142, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0009.summary_tmp
2017-09-30 01:06:10,428 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0009.summary_tmp is closed by DFSClient_NONMAPREDUCE_745291199_1
2017-09-30 01:06:10,455 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741963_1143, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0009-1506751555860-root-word+count-1506751570395-1-1-SUCCEEDED-default-1506751560726.jhist_tmp
2017-09-30 01:06:10,479 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741963_1143 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0009-1506751555860-root-word+count-1506751570395-1-1-SUCCEEDED-default-1506751560726.jhist_tmp
2017-09-30 01:06:10,887 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0009-1506751555860-root-word+count-1506751570395-1-1-SUCCEEDED-default-1506751560726.jhist_tmp is closed by DFSClient_NONMAPREDUCE_745291199_1
2017-09-30 01:06:10,952 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741964_1144, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0009_conf.xml_tmp
2017-09-30 01:06:10,978 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506747333911_0009_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_745291199_1
2017-09-30 01:08:33,274 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1021ms
No GCs detected
2017-09-30 01:12:42,746 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1071ms
No GCs detected
2017-09-30 01:15:05,138 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-30 01:15:05,138 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-30 01:15:05,139 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 862, 1589
2017-09-30 01:15:05,139 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=1590 lastSyncedTxid=1589 mostRecentTxid=1590
2017-09-30 01:15:05,139 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 729 Total time for transactions(ms): 60 Number of transactions batched in Syncs: 194 Number of syncs: 535 SyncTimes(ms): 612 
2017-09-30 01:15:05,143 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=1590 lastSyncedTxid=1590 mostRecentTxid=1590
2017-09-30 01:15:05,143 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 729 Total time for transactions(ms): 60 Number of transactions batched in Syncs: 194 Number of syncs: 536 SyncTimes(ms): 616 
2017-09-30 01:15:05,145 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000000862 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000000862-0000000000000001590
2017-09-30 01:15:05,146 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1591
2017-09-30 01:15:05,372 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 3000.00 KB/s
2017-09-30 01:15:05,372 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001590 size 9246 bytes.
2017-09-30 01:15:05,377 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 861
2017-09-30 01:15:05,377 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000797, cpktTxId=0000000000000000797)
2017-09-30 01:17:46,259 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-30 01:17:46,262 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1
************************************************************/
2017-09-30 15:37:30,504 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-30 15:37:30,512 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-30 15:37:30,525 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-30 15:37:30,947 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-30 15:37:31,112 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-30 15:37:31,112 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-30 15:37:31,130 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-30 15:37:31,133 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-30 15:37:31,228 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-30 15:37:31,396 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-30 15:37:31,417 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-30 15:37:31,475 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-30 15:37:31,484 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-30 15:37:31,492 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-30 15:37:31,497 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-30 15:37:31,500 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-30 15:37:31,500 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-30 15:37:31,500 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-30 15:37:31,602 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-30 15:37:31,604 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-30 15:37:31,621 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-30 15:37:31,621 INFO org.mortbay.log: jetty-6.1.26
2017-09-30 15:37:31,863 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-30 15:37:31,929 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-30 15:37:31,929 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-30 15:37:31,964 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-30 15:37:31,969 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-30 15:37:31,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-30 15:37:31,971 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-30 15:37:31,998 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-30 15:37:31,998 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-30 15:37:31,999 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-30 15:37:32,000 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 30 15:37:32
2017-09-30 15:37:32,001 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-30 15:37:32,001 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-30 15:37:32,002 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-30 15:37:32,002 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-30 15:37:32,017 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-30 15:37:32,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-30 15:37:32,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-30 15:37:32,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-30 15:37:32,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-30 15:37:32,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-30 15:37:32,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-30 15:37:32,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-30 15:37:32,026 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-30 15:37:32,026 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-30 15:37:32,026 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-30 15:37:32,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-30 15:37:32,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-30 15:37:32,099 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-30 15:37:32,099 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-30 15:37:32,099 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-30 15:37:32,099 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-30 15:37:32,100 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-30 15:37:32,100 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-30 15:37:32,100 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-30 15:37:32,110 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-30 15:37:32,111 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-30 15:37:32,111 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-30 15:37:32,111 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-30 15:37:32,112 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-30 15:37:32,113 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-30 15:37:32,113 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-30 15:37:32,116 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-30 15:37:32,116 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-30 15:37:32,116 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-30 15:37:32,120 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-30 15:37:32,120 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-30 15:37:32,123 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-30 15:37:32,123 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-30 15:37:32,123 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-30 15:37:32,123 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-30 15:37:32,262 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 3397@localhost
2017-09-30 15:37:32,283 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-30 15:37:32,314 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000001591 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000001591-0000000000000001591
2017-09-30 15:37:32,318 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000001590, cpktTxId=0000000000000001590)
2017-09-30 15:37:32,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 113 INodes.
2017-09-30 15:37:32,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-30 15:37:32,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1590 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000001590
2017-09-30 15:37:32,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@20f12539 expecting start txid #1591
2017-09-30 15:37:32,394 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000001591-0000000000000001591
2017-09-30 15:37:32,395 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000001591-0000000000000001591' to transaction ID 1591
2017-09-30 15:37:32,402 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000001591-0000000000000001591 of size 1048576 edits # 1 loaded in 0 seconds
2017-09-30 15:37:32,402 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2017-09-30 15:37:32,402 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2017-09-30 15:37:32,407 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /home/raji/hadoop_store/hdfs/namenode/current/fsimage.ckpt_0000000000000001591 using no compression
2017-09-30 15:37:32,442 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /home/raji/hadoop_store/hdfs/namenode/current/fsimage.ckpt_0000000000000001591 of size 9246 bytes saved in 0 seconds.
2017-09-30 15:37:32,451 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1590
2017-09-30 15:37:32,451 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000000861, cpktTxId=0000000000000000861)
2017-09-30 15:37:32,466 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1592
2017-09-30 15:37:32,549 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-30 15:37:32,549 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 423 msecs
2017-09-30 15:37:32,708 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-30 15:37:32,712 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-30 15:37:32,722 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-30 15:37:32,779 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-30 15:37:32,787 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-30 15:37:32,787 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 42 blocks to reach the threshold 0.9990 of total blocks 43.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 15:37:32,821 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-30 15:37:32,822 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-30 15:37:32,827 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-30 15:37:32,831 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-30 15:37:32,831 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-30 15:37:32,838 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 7 milliseconds
name space=113
storage space=25706848
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-30 15:37:32,862 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-30 15:37:37,284 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-30 15:37:37,286 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-30 15:37:37,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-30 15:37:37,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-30 15:37:37,427 INFO BlockStateChange: BLOCK* processReport 0x37af85b53d10e728: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-30 15:37:37,431 INFO BlockStateChange: BLOCK* processReport 0x37af85b53d10e728: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 41, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2017-09-30 15:44:36,555 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1033ms
No GCs detected
2017-09-30 15:45:10,306 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 127.0.0.1:48752: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/test/test.csv._COPYING_. Name node is in safe mode.
The reported blocks 41 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 43.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 15:45:58,116 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2017-09-30 15:45:58,117 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 506 secs
2017-09-30 15:45:58,117 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2017-09-30 15:45:58,117 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2017-09-30 15:45:58,117 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-30 15:45:58,130 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 43
2017-09-30 15:45:58,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-30 15:45:58,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 2
2017-09-30 15:45:58,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-30 15:45:58,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-09-30 15:45:58,131 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2017-09-30 15:46:02,773 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 1591 Number of syncs: 2 SyncTimes(ms): 8 
2017-09-30 15:46:02,805 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741965_1145, replicas=127.0.0.1:50010 for /test/test.csv._COPYING_
2017-09-30 15:46:02,963 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741965_1145 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /test/test.csv._COPYING_
2017-09-30 15:46:02,963 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2017-09-30 15:46:03,371 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/test.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_263420806_1
2017-09-30 15:46:59,834 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741966_1146, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job.jar
2017-09-30 15:46:59,893 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job.jar is closed by DFSClient_NONMAPREDUCE_-905297802_1
2017-09-30 15:46:59,900 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job.jar
2017-09-30 15:47:00,004 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job.split
2017-09-30 15:47:00,012 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741967_1147, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job.split
2017-09-30 15:47:00,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741967_1147 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job.split
2017-09-30 15:47:00,435 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job.split is closed by DFSClient_NONMAPREDUCE_-905297802_1
2017-09-30 15:47:00,473 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741968_1148, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job.splitmetainfo
2017-09-30 15:47:00,495 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741968_1148 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job.splitmetainfo
2017-09-30 15:47:00,900 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-905297802_1
2017-09-30 15:47:01,060 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741969_1149, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job.xml
2017-09-30 15:47:01,107 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741969_1149 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job.xml
2017-09-30 15:47:01,513 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job.xml is closed by DFSClient_NONMAPREDUCE_-905297802_1
2017-09-30 15:47:09,216 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 36 Total time for transactions(ms): 16 Number of transactions batched in Syncs: 1600 Number of syncs: 27 SyncTimes(ms): 43 
2017-09-30 15:47:09,383 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741970_1150, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job_1506804069277_0001_1_conf.xml
2017-09-30 15:47:09,432 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741970_1150 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job_1506804069277_0001_1_conf.xml
2017-09-30 15:47:09,838 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job_1506804069277_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-784136766_1
2017-09-30 15:47:14,472 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741971_1151, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job_1506804069277_0001_1.jhist
2017-09-30 15:47:14,497 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job_1506804069277_0001_1.jhist for DFSClient_NONMAPREDUCE_-784136766_1
2017-09-30 15:47:19,440 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741972_1152, replicas=127.0.0.1:50010 for /test/testwc/_temporary/1/_temporary/attempt_1506804069277_0001_r_000000_0/part-r-00000
2017-09-30 15:47:19,501 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/testwc/_temporary/1/_temporary/attempt_1506804069277_0001_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1506804069277_0001_r_000000_0_-369152535_1
2017-09-30 15:47:19,582 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-784136766_1
2017-09-30 15:47:19,619 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/testwc/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-784136766_1
2017-09-30 15:47:19,623 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-784136766_1
2017-09-30 15:47:19,651 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0001/job_1506804069277_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_-784136766_1
2017-09-30 15:47:19,661 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741973_1153, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506804069277_0001.summary_tmp
2017-09-30 15:47:19,669 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741973_1153 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506804069277_0001.summary_tmp
2017-09-30 15:47:20,072 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506804069277_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_-784136766_1
2017-09-30 15:47:20,159 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741974_1154, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506804069277_0001-1506804421890-root-word+count-1506804439625-1-1-SUCCEEDED-default-1506804429208.jhist_tmp
2017-09-30 15:47:20,171 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741974_1154 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506804069277_0001-1506804421890-root-word+count-1506804439625-1-1-SUCCEEDED-default-1506804429208.jhist_tmp
2017-09-30 15:47:20,575 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506804069277_0001-1506804421890-root-word+count-1506804439625-1-1-SUCCEEDED-default-1506804429208.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-784136766_1
2017-09-30 15:47:20,617 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741975_1155, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506804069277_0001_conf.xml_tmp
2017-09-30 15:47:20,633 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506804069277_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-784136766_1
2017-09-30 16:01:50,745 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 89 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 1616 Number of syncs: 63 SyncTimes(ms): 93 
2017-09-30 16:12:10,991 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1012ms
No GCs detected
2017-09-30 16:13:34,351 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 92 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 1617 Number of syncs: 66 SyncTimes(ms): 99 
2017-09-30 16:16:54,286 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 94 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 1617 Number of syncs: 68 SyncTimes(ms): 103 
2017-09-30 16:20:43,208 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-30 16:20:43,209 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-30 16:20:43,209 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1592, 1693
2017-09-30 16:20:43,209 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=1694 lastSyncedTxid=1693 mostRecentTxid=1694
2017-09-30 16:20:43,209 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 103 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 1619 Number of syncs: 75 SyncTimes(ms): 111 
2017-09-30 16:20:43,215 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=1694 lastSyncedTxid=1694 mostRecentTxid=1694
2017-09-30 16:20:43,216 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 103 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 1619 Number of syncs: 76 SyncTimes(ms): 116 
2017-09-30 16:20:43,220 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000001592 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000001592-0000000000000001694
2017-09-30 16:20:43,220 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1695
2017-09-30 16:20:44,004 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 4500.00 KB/s
2017-09-30 16:20:44,004 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001694 size 9855 bytes.
2017-09-30 16:20:44,006 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1591
2017-09-30 16:20:44,006 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000001590, cpktTxId=0000000000000001590)
2017-09-30 16:24:23,804 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2017-09-30 16:25:30,672 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 12 
2017-09-30 16:30:24,341 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 27 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 3 Number of syncs: 24 SyncTimes(ms): 39 
2017-09-30 16:34:35,369 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 41 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 5 Number of syncs: 36 SyncTimes(ms): 57 
2017-09-30 16:41:18,591 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 48 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 6 Number of syncs: 42 SyncTimes(ms): 69 
2017-09-30 16:42:22,334 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 57 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 7 Number of syncs: 50 SyncTimes(ms): 84 
2017-09-30 16:43:23,618 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 71 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 9 Number of syncs: 62 SyncTimes(ms): 100 
2017-09-30 16:43:23,818 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741976_1156, replicas=127.0.0.1:50010 for /tmp/hive/root/d1b67fdb-5dee-4199-8bba-2aa0c75ee7de/hive_2017-09-30_16-43-23_579_5035983053069503711-1/-mr-10003/2b8951a5-82e8-4847-8982-dfa16466ad6f/map.xml
2017-09-30 16:43:23,842 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741976_1156 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/d1b67fdb-5dee-4199-8bba-2aa0c75ee7de/hive_2017-09-30_16-43-23_579_5035983053069503711-1/-mr-10003/2b8951a5-82e8-4847-8982-dfa16466ad6f/map.xml
2017-09-30 16:43:24,250 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/d1b67fdb-5dee-4199-8bba-2aa0c75ee7de/hive_2017-09-30_16-43-23_579_5035983053069503711-1/-mr-10003/2b8951a5-82e8-4847-8982-dfa16466ad6f/map.xml is closed by DFSClient_NONMAPREDUCE_271162150_1
2017-09-30 16:43:24,278 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/d1b67fdb-5dee-4199-8bba-2aa0c75ee7de/hive_2017-09-30_16-43-23_579_5035983053069503711-1/-mr-10003/2b8951a5-82e8-4847-8982-dfa16466ad6f/map.xml
2017-09-30 16:43:24,622 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call Call#311 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:49008: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/d1b67fdb-5dee-4199-8bba-2aa0c75ee7de/hive_2017-09-30_16-43-23_579_5035983053069503711-1/-mr-10003/2b8951a5-82e8-4847-8982-dfa16466ad6f/reduce.xml
2017-09-30 16:43:24,703 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741977_1157, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/libjars/hive-json-serde-0.3.jar
2017-09-30 16:43:24,769 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/libjars/hive-json-serde-0.3.jar is closed by DFSClient_NONMAPREDUCE_271162150_1
2017-09-30 16:43:24,772 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/libjars/hive-json-serde-0.3.jar
2017-09-30 16:43:24,777 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741978_1158, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job.jar
2017-09-30 16:43:25,101 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741978_1158 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job.jar
2017-09-30 16:43:25,504 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job.jar is closed by DFSClient_NONMAPREDUCE_271162150_1
2017-09-30 16:43:25,511 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job.jar
2017-09-30 16:43:25,641 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job.split
2017-09-30 16:43:25,646 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741979_1159, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job.split
2017-09-30 16:43:25,665 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741979_1159 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job.split
2017-09-30 16:43:26,066 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job.split is closed by DFSClient_NONMAPREDUCE_271162150_1
2017-09-30 16:43:26,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741980_1160, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job.splitmetainfo
2017-09-30 16:43:26,086 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_271162150_1
2017-09-30 16:43:26,124 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741981_1161, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job.xml
2017-09-30 16:43:26,139 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741981_1161 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job.xml
2017-09-30 16:43:26,544 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job.xml is closed by DFSClient_NONMAPREDUCE_271162150_1
2017-09-30 16:43:33,968 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741982_1162, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job_1506804069277_0002_1_conf.xml
2017-09-30 16:43:34,056 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job_1506804069277_0002_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-486333599_1
2017-09-30 16:43:42,989 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741983_1163, replicas=127.0.0.1:50010 for /tmp/hive/root/d1b67fdb-5dee-4199-8bba-2aa0c75ee7de/hive_2017-09-30_16-43-23_579_5035983053069503711-1/_task_tmp.-mr-10000/_tmp.000000_0
2017-09-30 16:43:43,013 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/d1b67fdb-5dee-4199-8bba-2aa0c75ee7de/hive_2017-09-30_16-43-23_579_5035983053069503711-1/_task_tmp.-mr-10000/_tmp.000000_0 is closed by DFSClient_attempt_1506804069277_0002_m_000000_0_1964946897_1
2017-09-30 16:43:43,137 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741984_1164, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job_1506804069277_0002_1.jhist
2017-09-30 16:43:43,170 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job_1506804069277_0002_1.jhist for DFSClient_NONMAPREDUCE_-486333599_1
2017-09-30 16:43:43,177 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-486333599_1
2017-09-30 16:43:43,182 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-486333599_1
2017-09-30 16:43:43,229 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506804069277_0002/job_1506804069277_0002_1.jhist is closed by DFSClient_NONMAPREDUCE_-486333599_1
2017-09-30 16:43:43,238 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741985_1165, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506804069277_0002.summary_tmp
2017-09-30 16:43:43,255 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506804069277_0002.summary_tmp is closed by DFSClient_NONMAPREDUCE_-486333599_1
2017-09-30 16:43:43,301 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741986_1166, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506804069277_0002-1506807806774-root-INSERT+OVERWRITE+LOCAL+DIRECTORY++%27%2Ftest...2-1506807823195-1-0-SUCCEEDED-default-1506807813744.jhist_tmp
2017-09-30 16:43:43,312 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506804069277_0002-1506807806774-root-INSERT+OVERWRITE+LOCAL+DIRECTORY++%27%2Ftest...2-1506807823195-1-0-SUCCEEDED-default-1506807813744.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-486333599_1
2017-09-30 16:43:43,335 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741987_1167, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506804069277_0002_conf.xml_tmp
2017-09-30 16:43:43,348 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741987_1167 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506804069277_0002_conf.xml_tmp
2017-09-30 16:43:43,749 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506804069277_0002_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-486333599_1
2017-09-30 16:57:44,681 INFO BlockStateChange: BLOCK* processReport 0x37af85b53d10e729: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 49, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2017-09-30 16:59:25,446 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 172 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 36 Number of syncs: 136 SyncTimes(ms): 174 
2017-09-30 17:00:53,247 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 176 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 36 Number of syncs: 140 SyncTimes(ms): 175 
2017-09-30 17:02:19,373 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 178 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 36 Number of syncs: 142 SyncTimes(ms): 179 
2017-09-30 17:03:24,602 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 181 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 36 Number of syncs: 145 SyncTimes(ms): 187 
2017-09-30 17:04:30,110 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 183 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 36 Number of syncs: 147 SyncTimes(ms): 191 
2017-09-30 17:07:54,542 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 185 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 36 Number of syncs: 149 SyncTimes(ms): 197 
2017-09-30 17:09:18,130 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 187 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 36 Number of syncs: 151 SyncTimes(ms): 200 
2017-09-30 17:12:56,925 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 201 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 38 Number of syncs: 163 SyncTimes(ms): 221 
2017-09-30 17:17:05,767 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 215 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 40 Number of syncs: 175 SyncTimes(ms): 235 
2017-09-30 17:18:36,192 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 223 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 42 Number of syncs: 181 SyncTimes(ms): 243 
2017-09-30 17:20:45,352 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-30 17:20:45,352 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-30 17:20:45,352 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1695, 1919
2017-09-30 17:20:45,352 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=1920 lastSyncedTxid=1919 mostRecentTxid=1920
2017-09-30 17:20:45,352 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 226 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 42 Number of syncs: 184 SyncTimes(ms): 247 
2017-09-30 17:20:45,357 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=1920 lastSyncedTxid=1920 mostRecentTxid=1920
2017-09-30 17:20:45,357 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 226 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 42 Number of syncs: 185 SyncTimes(ms): 252 
2017-09-30 17:20:45,358 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000001695 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000001695-0000000000000001920
2017-09-30 17:20:45,358 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1921
2017-09-30 17:20:45,434 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 10000.00 KB/s
2017-09-30 17:20:45,434 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001920 size 10413 bytes.
2017-09-30 17:20:45,436 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1694
2017-09-30 17:20:45,436 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000001591, cpktTxId=0000000000000001591)
2017-09-30 17:24:48,092 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 5 
2017-09-30 17:24:48,677 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741988_1168, replicas=127.0.0.1:50010 for /tmp/hive/root/35179700-b477-4466-8556-e6d622b8c3df/hive_2017-09-30_17-24-47_420_6729177996708114303-1/dummy_path/dummy_file
2017-09-30 17:24:48,750 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/35179700-b477-4466-8556-e6d622b8c3df/hive_2017-09-30_17-24-47_420_6729177996708114303-1/dummy_path/dummy_file is closed by DFSClient_NONMAPREDUCE_2059604149_1
2017-09-30 17:25:49,146 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 17 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 4 Number of syncs: 13 SyncTimes(ms): 25 
2017-09-30 17:25:49,169 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741989_1169, replicas=127.0.0.1:50010 for /tmp/hive/root/35179700-b477-4466-8556-e6d622b8c3df/hive_2017-09-30_17-25-49_141_8821748471311184189-1/dummy_path/dummy_file
2017-09-30 17:25:49,182 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/35179700-b477-4466-8556-e6d622b8c3df/hive_2017-09-30_17-25-49_141_8821748471311184189-1/dummy_path/dummy_file is closed by DFSClient_NONMAPREDUCE_2059604149_1
2017-09-30 17:26:58,681 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 33 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 8 Number of syncs: 25 SyncTimes(ms): 39 
2017-09-30 17:32:27,031 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 42 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 9 Number of syncs: 33 SyncTimes(ms): 55 
2017-09-30 17:33:51,182 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 44 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 9 Number of syncs: 35 SyncTimes(ms): 59 
2017-09-30 17:37:09,661 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 45 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 9 Number of syncs: 36 SyncTimes(ms): 62 
2017-09-30 17:39:48,610 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 54 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 10 Number of syncs: 44 SyncTimes(ms): 75 
2017-09-30 17:41:24,269 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 55 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 10 Number of syncs: 45 SyncTimes(ms): 78 
2017-09-30 17:41:24,294 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741990_1170, replicas=127.0.0.1:50010 for /data/jsontest.json._COPYING_
2017-09-30 17:41:24,344 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741990_1170 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /data/jsontest.json._COPYING_
2017-09-30 17:41:24,749 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /data/jsontest.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_2123618776_1
2017-09-30 17:42:26,283 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 61 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 12 Number of syncs: 49 SyncTimes(ms): 88 
2017-09-30 17:47:29,614 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 63 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 12 Number of syncs: 51 SyncTimes(ms): 91 
2017-09-30 17:47:29,636 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741991_1171, replicas=127.0.0.1:50010 for /user/hive/warehouse/json_table/jsontest.json
2017-09-30 17:47:29,711 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741991_1171 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/hive/warehouse/json_table/jsontest.json
2017-09-30 17:47:30,117 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/json_table/jsontest.json is closed by DFSClient_NONMAPREDUCE_-43555095_1
2017-09-30 17:49:36,113 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 76 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 15 Number of syncs: 61 SyncTimes(ms): 98 
2017-09-30 17:52:19,859 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 83 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 16 Number of syncs: 67 SyncTimes(ms): 104 
2017-09-30 17:52:22,921 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1086ms
No GCs detected
2017-09-30 17:54:07,504 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 93 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 17 Number of syncs: 76 SyncTimes(ms): 119 
2017-09-30 17:56:40,657 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-30 17:56:40,674 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1
************************************************************/
2017-09-30 18:13:29,320 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /home/raji/hadoop/hadoop-2.8.1/etc/hadoop:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/home/raji/hadoop/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/home/raji/hadoop/hadoop-2.8.1/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-30 18:13:29,327 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-30 18:13:29,332 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-30 18:13:29,613 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-30 18:13:29,690 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-30 18:13:29,690 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-30 18:13:29,709 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-30 18:13:29,712 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-30 18:13:29,799 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-30 18:13:29,959 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-30 18:13:30,040 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-30 18:13:30,196 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-30 18:13:30,210 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-30 18:13:30,217 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-30 18:13:30,224 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-30 18:13:30,227 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-30 18:13:30,227 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-30 18:13:30,227 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-30 18:13:30,339 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-30 18:13:30,342 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-30 18:13:30,364 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-30 18:13:30,364 INFO org.mortbay.log: jetty-6.1.26
2017-09-30 18:13:30,632 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-30 18:13:30,770 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-30 18:13:30,770 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-30 18:13:30,808 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2017-09-30 18:13:30,814 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2017-09-30 18:13:30,815 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2017-09-30 18:13:30,817 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2017-09-30 18:13:30,850 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-30 18:13:30,850 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-30 18:13:30,851 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-30 18:13:30,851 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 Sep 30 18:13:30
2017-09-30 18:13:30,853 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-30 18:13:30,853 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-30 18:13:30,854 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-30 18:13:30,854 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-30 18:13:30,873 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-30 18:13:30,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-30 18:13:30,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-30 18:13:30,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-30 18:13:30,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-30 18:13:30,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-30 18:13:30,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-30 18:13:30,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-30 18:13:30,881 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-09-30 18:13:30,881 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-30 18:13:30,881 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-30 18:13:30,881 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-30 18:13:30,882 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-30 18:13:30,943 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-30 18:13:30,943 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-30 18:13:30,943 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-30 18:13:30,943 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-30 18:13:30,944 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2017-09-30 18:13:30,944 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2017-09-30 18:13:30,944 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2017-09-30 18:13:30,952 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-30 18:13:30,952 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-30 18:13:30,953 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-30 18:13:30,953 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-30 18:13:30,954 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-30 18:13:30,954 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-30 18:13:30,954 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-30 18:13:30,959 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-09-30 18:13:30,960 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2017-09-30 18:13:30,960 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-09-30 18:13:30,963 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-30 18:13:30,964 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-30 18:13:30,966 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-30 18:13:30,966 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-30 18:13:30,966 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-30 18:13:30,966 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-30 18:13:31,092 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/raji/hadoop_store/hdfs/namenode/in_use.lock acquired by nodename 3276@localhost
2017-09-30 18:13:31,108 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/raji/hadoop_store/hdfs/namenode/current
2017-09-30 18:13:31,133 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000001921 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000001921-0000000000000002020
2017-09-30 18:13:31,137 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000001920, cpktTxId=0000000000000001920)
2017-09-30 18:13:31,163 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 125 INodes.
2017-09-30 18:13:31,201 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-30 18:13:31,201 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1920 from /home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000001920
2017-09-30 18:13:31,202 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@20f12539 expecting start txid #1921
2017-09-30 18:13:31,202 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000001921-0000000000000002020
2017-09-30 18:13:31,203 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000001921-0000000000000002020' to transaction ID 1921
2017-09-30 18:13:31,267 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000001921-0000000000000002020 of size 1048576 edits # 100 loaded in 0 seconds
2017-09-30 18:13:31,267 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-09-30 18:13:31,268 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2021
2017-09-30 18:13:31,368 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-30 18:13:31,368 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 399 msecs
2017-09-30 18:13:31,523 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-30 18:13:31,527 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-30 18:13:31,537 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-30 18:13:31,594 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-30 18:13:31,601 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-30 18:13:31,602 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 52 blocks to reach the threshold 0.9990 of total blocks 53.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 18:13:31,632 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-30 18:13:31,633 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-30 18:13:31,641 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-30 18:13:31,644 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-30 18:13:31,644 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2017-09-30 18:13:31,667 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 22 milliseconds
name space=126
storage space=26171136
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2017-09-30 18:13:31,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-30 18:13:36,158 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841) storage 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-30 18:13:36,159 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-30 18:13:36,159 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 07adc5c3-30ba-458c-9c90-1941f8b7d2e1 (127.0.0.1:50010).
2017-09-30 18:13:36,221 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7582333b-07d5-4900-80c5-0d83adec8e8e for DN 127.0.0.1:50010
2017-09-30 18:13:36,275 INFO BlockStateChange: BLOCK* processReport 0x11d3e33dd482f6b7: Processing first storage report for DS-7582333b-07d5-4900-80c5-0d83adec8e8e from datanode 07adc5c3-30ba-458c-9c90-1941f8b7d2e1
2017-09-30 18:13:36,278 INFO BlockStateChange: BLOCK* processReport 0x11d3e33dd482f6b7: from storage DS-7582333b-07d5-4900-80c5-0d83adec8e8e node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=07adc5c3-30ba-458c-9c90-1941f8b7d2e1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-6d7f04a9-1980-46d0-807b-12e5c1aa7c30;nsid=1959194256;c=1505591284841), blocks: 51, hasStaleStorage: false, processing time: 9 msecs, invalidatedBlocks: 0
2017-09-30 18:14:17,612 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000, call Call#4 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:57210: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /tmp/hive/root/d2f8a46d-ba8e-438c-9ae7-fd585bee75c2. Name node is in safe mode.
The reported blocks 51 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 53.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 18:14:46,136 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9000, call Call#4 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:57214: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /tmp/hive/root/4c698835-9bf0-460a-8a9d-e3ea7491c1ce. Name node is in safe mode.
The reported blocks 51 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 53.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 18:15:21,698 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1045ms
No GCs detected
2017-09-30 18:15:32,725 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000, call Call#4 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:57220: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /tmp/hive/root/1e1adba3-3df7-43ba-86ab-e794d8d8a848. Name node is in safe mode.
The reported blocks 51 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 53.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-09-30 18:16:34,639 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2017-09-30 18:16:34,640 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 183 secs
2017-09-30 18:16:34,640 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2017-09-30 18:16:34,640 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2017-09-30 18:16:34,640 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-30 18:16:34,652 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 53
2017-09-30 18:16:34,652 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-30 18:16:34,652 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 2
2017-09-30 18:16:34,652 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-30 18:16:34,652 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-09-30 18:16:34,653 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
2017-09-30 18:17:18,079 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 2020 Number of syncs: 2 SyncTimes(ms): 9 
2017-09-30 18:19:33,182 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 6 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 2020 Number of syncs: 6 SyncTimes(ms): 17 
2017-09-30 18:19:33,256 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741992_1172, replicas=127.0.0.1:50010 for /user/hive/warehouse/twitter_table/tweets.json
2017-09-30 18:19:34,710 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741993_1173, replicas=127.0.0.1:50010 for /user/hive/warehouse/twitter_table/tweets.json
2017-09-30 18:19:36,016 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741994_1174, replicas=127.0.0.1:50010 for /user/hive/warehouse/twitter_table/tweets.json
2017-09-30 18:19:36,979 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741995_1175, replicas=127.0.0.1:50010 for /user/hive/warehouse/twitter_table/tweets.json
2017-09-30 18:19:37,994 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741996_1176, replicas=127.0.0.1:50010 for /user/hive/warehouse/twitter_table/tweets.json
2017-09-30 18:19:38,218 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741996_1176 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/hive/warehouse/twitter_table/tweets.json
2017-09-30 18:19:38,627 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/twitter_table/tweets.json is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:21:17,541 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 24 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 2030 Number of syncs: 14 SyncTimes(ms): 33 
2017-09-30 18:22:03,795 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2017-09-30 18:22:56,212 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 38 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 2031 Number of syncs: 27 SyncTimes(ms): 51 
2017-09-30 18:24:25,388 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 45 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 2032 Number of syncs: 33 SyncTimes(ms): 62 
2017-09-30 18:28:58,120 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 47 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 2032 Number of syncs: 35 SyncTimes(ms): 66 
2017-09-30 18:30:46,766 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 61 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 2034 Number of syncs: 47 SyncTimes(ms): 88 
2017-09-30 18:32:29,866 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 68 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 2035 Number of syncs: 53 SyncTimes(ms): 95 
2017-09-30 18:36:52,998 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 75 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 2036 Number of syncs: 59 SyncTimes(ms): 104 
2017-09-30 18:39:59,618 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 82 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 2037 Number of syncs: 65 SyncTimes(ms): 114 
2017-09-30 18:41:50,244 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 89 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 2038 Number of syncs: 71 SyncTimes(ms): 123 
2017-09-30 18:46:26,440 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 96 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 2039 Number of syncs: 77 SyncTimes(ms): 131 
2017-09-30 18:49:54,698 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 103 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 2040 Number of syncs: 83 SyncTimes(ms): 136 
2017-09-30 18:49:55,060 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741997_1177, replicas=127.0.0.1:50010 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10006/93951d2d-4766-43e5-9854-068842c4eb3d/map.xml
2017-09-30 18:49:55,074 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741997_1177 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10006/93951d2d-4766-43e5-9854-068842c4eb3d/map.xml
2017-09-30 18:49:55,479 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10006/93951d2d-4766-43e5-9854-068842c4eb3d/map.xml is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:49:55,516 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10006/93951d2d-4766-43e5-9854-068842c4eb3d/map.xml
2017-09-30 18:49:55,583 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741998_1178, replicas=127.0.0.1:50010 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10006/93951d2d-4766-43e5-9854-068842c4eb3d/reduce.xml
2017-09-30 18:49:55,611 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741998_1178 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10006/93951d2d-4766-43e5-9854-068842c4eb3d/reduce.xml
2017-09-30 18:49:56,016 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10006/93951d2d-4766-43e5-9854-068842c4eb3d/reduce.xml is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:49:56,027 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10006/93951d2d-4766-43e5-9854-068842c4eb3d/reduce.xml
2017-09-30 18:49:56,546 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741999_1179, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job.jar
2017-09-30 18:49:56,787 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741999_1179 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job.jar
2017-09-30 18:49:57,188 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job.jar is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:49:57,191 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job.jar
2017-09-30 18:49:57,274 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job.split
2017-09-30 18:49:57,284 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742000_1180, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job.split
2017-09-30 18:49:57,297 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742000_1180 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job.split
2017-09-30 18:49:57,700 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job.split is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:49:57,710 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742001_1181, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job.splitmetainfo
2017-09-30 18:49:57,718 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742001_1181 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job.splitmetainfo
2017-09-30 18:49:58,122 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:49:58,228 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742002_1182, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job.xml
2017-09-30 18:49:58,260 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742002_1182 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job.xml
2017-09-30 18:49:58,664 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job.xml is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:50:06,673 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742003_1183, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job_1506813242048_0001_1_conf.xml
2017-09-30 18:50:06,775 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job_1506813242048_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1296671953_1
2017-09-30 18:50:21,543 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742004_1184, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job_1506813242048_0001_1.jhist
2017-09-30 18:50:21,651 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job_1506813242048_0001_1.jhist for DFSClient_NONMAPREDUCE_-1296671953_1
2017-09-30 18:50:34,099 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742005_1185, replicas=127.0.0.1:50010 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/_task_tmp.-mr-10004/_tmp.000000_0
2017-09-30 18:50:34,448 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742006_1186, replicas=127.0.0.1:50010 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/_task_tmp.-mr-10004/_tmp.000001_0
2017-09-30 18:50:34,778 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/_task_tmp.-mr-10004/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0001_r_000000_0_-1693746535_1
2017-09-30 18:50:34,960 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742006_1186 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/_task_tmp.-mr-10004/_tmp.000001_0
2017-09-30 18:50:35,137 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742007_1187, replicas=127.0.0.1:50010 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/_task_tmp.-mr-10004/_tmp.000002_0
2017-09-30 18:50:35,348 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/_task_tmp.-mr-10004/_tmp.000002_0 is closed by DFSClient_attempt_1506813242048_0001_r_000002_0_-1803827339_1
2017-09-30 18:50:35,382 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/_task_tmp.-mr-10004/_tmp.000001_0 is closed by DFSClient_attempt_1506813242048_0001_r_000001_0_-1715252026_1
2017-09-30 18:50:35,637 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1296671953_1
2017-09-30 18:50:35,644 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1296671953_1
2017-09-30 18:50:35,682 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742004_1184 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job_1506813242048_0001_1.jhist
2017-09-30 18:50:36,087 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0001/job_1506813242048_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_-1296671953_1
2017-09-30 18:50:36,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742008_1188, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0001.summary_tmp
2017-09-30 18:50:36,143 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1296671953_1
2017-09-30 18:50:36,209 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742009_1189, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0001-1506815398939-root-select+get_json_object%28twitter_table....null%28S-1506815435650-3-3-SUCCEEDED-default-1506815406371.jhist_tmp
2017-09-30 18:50:36,229 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742009_1189 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0001-1506815398939-root-select+get_json_object%28twitter_table....null%28S-1506815435650-3-3-SUCCEEDED-default-1506815406371.jhist_tmp
2017-09-30 18:50:36,633 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0001-1506815398939-root-select+get_json_object%28twitter_table....null%28S-1506815435650-3-3-SUCCEEDED-default-1506815406371.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1296671953_1
2017-09-30 18:50:36,667 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742010_1190, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0001_conf.xml_tmp
2017-09-30 18:50:36,683 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1296671953_1
2017-09-30 18:50:39,011 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742011_1191, replicas=127.0.0.1:50010 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10008/1c4b4a69-fa7c-48e2-95ca-a75459ac62e8/map.xml
2017-09-30 18:50:39,021 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742011_1191 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10008/1c4b4a69-fa7c-48e2-95ca-a75459ac62e8/map.xml
2017-09-30 18:50:39,427 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10008/1c4b4a69-fa7c-48e2-95ca-a75459ac62e8/map.xml is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:50:39,435 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10008/1c4b4a69-fa7c-48e2-95ca-a75459ac62e8/map.xml
2017-09-30 18:50:39,455 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742012_1192, replicas=127.0.0.1:50010 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10008/1c4b4a69-fa7c-48e2-95ca-a75459ac62e8/reduce.xml
2017-09-30 18:50:39,475 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742012_1192 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10008/1c4b4a69-fa7c-48e2-95ca-a75459ac62e8/reduce.xml
2017-09-30 18:50:39,880 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10008/1c4b4a69-fa7c-48e2-95ca-a75459ac62e8/reduce.xml is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:50:39,890 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10008/1c4b4a69-fa7c-48e2-95ca-a75459ac62e8/reduce.xml
2017-09-30 18:50:40,091 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742013_1193, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job.jar
2017-09-30 18:50:40,223 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742013_1193 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job.jar
2017-09-30 18:50:40,626 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job.jar is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:50:40,634 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job.jar
2017-09-30 18:50:40,752 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job.split
2017-09-30 18:50:40,754 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742014_1194, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job.split
2017-09-30 18:50:40,770 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job.split is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:50:40,781 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742015_1195, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job.splitmetainfo
2017-09-30 18:50:40,793 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:50:40,821 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742016_1196, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job.xml
2017-09-30 18:50:40,848 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job.xml is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:50:48,706 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742017_1197, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job_1506813242048_0002_1_conf.xml
2017-09-30 18:50:48,738 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742017_1197 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job_1506813242048_0002_1_conf.xml
2017-09-30 18:50:49,144 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job_1506813242048_0002_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1395886937_1
2017-09-30 18:51:04,896 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742018_1198, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job_1506813242048_0002_1.jhist
2017-09-30 18:51:04,896 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 264 Total time for transactions(ms): 29 Number of transactions batched in Syncs: 2086 Number of syncs: 196 SyncTimes(ms): 367 
2017-09-30 18:51:05,029 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job_1506813242048_0002_1.jhist for DFSClient_NONMAPREDUCE_-1395886937_1
2017-09-30 18:51:16,177 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742019_1199, replicas=127.0.0.1:50010 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10001/.hive-staging_hive_2017-09-30_18-49-54_632_2344480476569988476-1/_task_tmp.-ext-10002/_tmp.000000_0
2017-09-30 18:51:16,911 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10001/.hive-staging_hive_2017-09-30_18-49-54_632_2344480476569988476-1/_task_tmp.-ext-10002/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0002_r_000000_0_107210082_1
2017-09-30 18:51:17,359 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742020_1200, replicas=127.0.0.1:50010 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10001/.hive-staging_hive_2017-09-30_18-49-54_632_2344480476569988476-1/_task_tmp.-ext-10002/_tmp.000001_0
2017-09-30 18:51:17,788 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742020_1200 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10001/.hive-staging_hive_2017-09-30_18-49-54_632_2344480476569988476-1/_task_tmp.-ext-10002/_tmp.000001_0
2017-09-30 18:51:18,216 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10001/.hive-staging_hive_2017-09-30_18-49-54_632_2344480476569988476-1/_task_tmp.-ext-10002/_tmp.000001_0 is closed by DFSClient_attempt_1506813242048_0002_r_000001_0_-1049422890_1
2017-09-30 18:51:18,360 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742021_1201, replicas=127.0.0.1:50010 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10001/.hive-staging_hive_2017-09-30_18-49-54_632_2344480476569988476-1/_task_tmp.-ext-10002/_tmp.000002_0
2017-09-30 18:51:18,761 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-49-54_632_2344480476569988476-1/-mr-10001/.hive-staging_hive_2017-09-30_18-49-54_632_2344480476569988476-1/_task_tmp.-ext-10002/_tmp.000002_0 is closed by DFSClient_attempt_1506813242048_0002_r_000002_0_395611131_1
2017-09-30 18:51:18,873 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1395886937_1
2017-09-30 18:51:18,879 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1395886937_1
2017-09-30 18:51:18,917 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742018_1198 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job_1506813242048_0002_1.jhist
2017-09-30 18:51:19,320 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0002/job_1506813242048_0002_1.jhist is closed by DFSClient_NONMAPREDUCE_-1395886937_1
2017-09-30 18:51:19,341 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742022_1202, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0002.summary_tmp
2017-09-30 18:51:19,377 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0002.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1395886937_1
2017-09-30 18:51:19,422 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742023_1203, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0002-1506815440868-root-select+get_json_object%28twitter_table....null%28S-1506815478882-4-3-SUCCEEDED-default-1506815448535.jhist_tmp
2017-09-30 18:51:19,441 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0002-1506815440868-root-select+get_json_object%28twitter_table....null%28S-1506815478882-4-3-SUCCEEDED-default-1506815448535.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1395886937_1
2017-09-30 18:51:19,466 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742024_1204, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0002_conf.xml_tmp
2017-09-30 18:51:19,477 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0002_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1395886937_1
2017-09-30 18:53:35,583 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 318 Total time for transactions(ms): 37 Number of transactions batched in Syncs: 2101 Number of syncs: 237 SyncTimes(ms): 486 
2017-09-30 18:53:35,626 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742025_1205, replicas=127.0.0.1:50010 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-53-35_527_5402267920702221257-1/-mr-10003/3aa64ac4-6697-4e39-ac7e-136b3afce0e5/map.xml
2017-09-30 18:53:35,634 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742025_1205 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-53-35_527_5402267920702221257-1/-mr-10003/3aa64ac4-6697-4e39-ac7e-136b3afce0e5/map.xml
2017-09-30 18:53:36,037 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-53-35_527_5402267920702221257-1/-mr-10003/3aa64ac4-6697-4e39-ac7e-136b3afce0e5/map.xml is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:53:36,045 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-53-35_527_5402267920702221257-1/-mr-10003/3aa64ac4-6697-4e39-ac7e-136b3afce0e5/map.xml
2017-09-30 18:53:36,175 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000, call Call#954 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:57758: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-53-35_527_5402267920702221257-1/-mr-10003/3aa64ac4-6697-4e39-ac7e-136b3afce0e5/reduce.xml
2017-09-30 18:53:36,205 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742026_1206, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/job.jar
2017-09-30 18:53:36,359 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/job.jar is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:53:36,364 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/job.jar
2017-09-30 18:53:36,384 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/job.split
2017-09-30 18:53:36,385 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742027_1207, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/job.split
2017-09-30 18:53:36,391 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742027_1207 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/job.split
2017-09-30 18:53:36,794 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/job.split is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:53:36,819 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742028_1208, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/job.splitmetainfo
2017-09-30 18:53:36,851 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:53:36,894 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742029_1209, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/job.xml
2017-09-30 18:53:36,913 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/job.xml is closed by DFSClient_NONMAPREDUCE_404563124_1
2017-09-30 18:53:42,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742030_1210, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/job_1506813242048_0003_1_conf.xml
2017-09-30 18:53:42,170 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/job_1506813242048_0003_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-364861183_1
2017-09-30 18:53:54,279 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742031_1211, replicas=127.0.0.1:50010 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-53-35_527_5402267920702221257-1/_task_tmp.-mr-10000/_tmp.000002_0
2017-09-30 18:53:54,504 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-53-35_527_5402267920702221257-1/_task_tmp.-mr-10000/_tmp.000002_0 is closed by DFSClient_attempt_1506813242048_0003_m_000002_0_893089570_1
2017-09-30 18:53:54,867 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742032_1212, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/job_1506813242048_0003_1.jhist
2017-09-30 18:53:54,991 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/job_1506813242048_0003_1.jhist for DFSClient_NONMAPREDUCE_-364861183_1
2017-09-30 18:53:55,467 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742033_1213, replicas=127.0.0.1:50010 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-53-35_527_5402267920702221257-1/_task_tmp.-mr-10000/_tmp.000001_0
2017-09-30 18:53:55,950 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742034_1214, replicas=127.0.0.1:50010 for /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-53-35_527_5402267920702221257-1/_task_tmp.-mr-10000/_tmp.000000_0
2017-09-30 18:54:00,134 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-53-35_527_5402267920702221257-1/_task_tmp.-mr-10000/_tmp.000001_0 is closed by DFSClient_attempt_1506813242048_0003_m_000001_0_1165906178_1
2017-09-30 18:54:00,248 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/7eb17eaa-4e14-448e-a204-a14286777fa7/hive_2017-09-30_18-53-35_527_5402267920702221257-1/_task_tmp.-mr-10000/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0003_m_000000_0_-1318204091_1
2017-09-30 18:54:00,332 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-364861183_1
2017-09-30 18:54:00,340 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-364861183_1
2017-09-30 18:54:00,368 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0003/job_1506813242048_0003_1.jhist is closed by DFSClient_NONMAPREDUCE_-364861183_1
2017-09-30 18:54:00,376 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742035_1215, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0003.summary_tmp
2017-09-30 18:54:00,386 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0003.summary_tmp is closed by DFSClient_NONMAPREDUCE_-364861183_1
2017-09-30 18:54:00,409 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742036_1216, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0003-1506815616936-root-INSERT+OVERWRITE+LOCAL+DIRECTORY++%27%2Ft...null-1506815640341-3-0-SUCCEEDED-default-1506815621914.jhist_tmp
2017-09-30 18:54:00,420 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0003-1506815616936-root-INSERT+OVERWRITE+LOCAL+DIRECTORY++%27%2Ft...null-1506815640341-3-0-SUCCEEDED-default-1506815621914.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-364861183_1
2017-09-30 18:54:00,439 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742037_1217, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0003_conf.xml_tmp
2017-09-30 18:54:00,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742037_1217 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0003_conf.xml_tmp
2017-09-30 18:54:00,853 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0003_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-364861183_1
2017-09-30 18:54:54,154 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 423 Total time for transactions(ms): 42 Number of transactions batched in Syncs: 2130 Number of syncs: 313 SyncTimes(ms): 644 
2017-09-30 18:55:12,319 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1184ms
No GCs detected
2017-09-30 19:06:42,440 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-30 19:06:42,440 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-30 19:06:42,440 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 2021, 2443
2017-09-30 19:06:42,440 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=2444 lastSyncedTxid=2443 mostRecentTxid=2444
2017-09-30 19:06:42,440 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 424 Total time for transactions(ms): 43 Number of transactions batched in Syncs: 2130 Number of syncs: 314 SyncTimes(ms): 647 
2017-09-30 19:06:42,446 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=2444 lastSyncedTxid=2444 mostRecentTxid=2444
2017-09-30 19:06:42,446 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 424 Total time for transactions(ms): 43 Number of transactions batched in Syncs: 2130 Number of syncs: 315 SyncTimes(ms): 652 
2017-09-30 19:06:42,450 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000002021 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000002021-0000000000000002444
2017-09-30 19:06:42,450 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2445
2017-09-30 19:06:43,619 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 5500.00 KB/s
2017-09-30 19:06:43,619 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000002444 size 11847 bytes.
2017-09-30 19:06:43,625 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1920
2017-09-30 19:06:43,625 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000001694, cpktTxId=0000000000000001694)
2017-09-30 19:08:42,765 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2017-09-30 19:09:11,817 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742038_1218, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10007/40f19ada-0c5f-4720-ba31-1d3fe4144b9e/map.xml
2017-09-30 19:09:11,896 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10007/40f19ada-0c5f-4720-ba31-1d3fe4144b9e/map.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:09:11,907 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10007/40f19ada-0c5f-4720-ba31-1d3fe4144b9e/map.xml
2017-09-30 19:09:11,920 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742039_1219, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10007/40f19ada-0c5f-4720-ba31-1d3fe4144b9e/reduce.xml
2017-09-30 19:09:11,929 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10007/40f19ada-0c5f-4720-ba31-1d3fe4144b9e/reduce.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:09:11,931 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10007/40f19ada-0c5f-4720-ba31-1d3fe4144b9e/reduce.xml
2017-09-30 19:09:12,344 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742040_1220, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job.jar
2017-09-30 19:09:12,563 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job.jar is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:09:12,568 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job.jar
2017-09-30 19:09:12,627 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job.split
2017-09-30 19:09:12,634 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742041_1221, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job.split
2017-09-30 19:09:12,645 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742041_1221 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job.split
2017-09-30 19:09:13,047 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job.split is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:09:13,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742042_1222, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job.splitmetainfo
2017-09-30 19:09:13,067 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742042_1222 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job.splitmetainfo
2017-09-30 19:09:13,471 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:09:13,582 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742043_1223, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job.xml
2017-09-30 19:09:13,608 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742043_1223 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job.xml
2017-09-30 19:09:14,011 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:09:18,702 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742044_1224, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job_1506813242048_0004_1_conf.xml
2017-09-30 19:09:18,738 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job_1506813242048_0004_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1133059647_1
2017-09-30 19:09:31,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742045_1225, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job_1506813242048_0004_1.jhist
2017-09-30 19:09:31,792 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job_1506813242048_0004_1.jhist for DFSClient_NONMAPREDUCE_1133059647_1
2017-09-30 19:09:45,099 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 64 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 18 Number of syncs: 45 SyncTimes(ms): 101 
2017-09-30 19:09:45,508 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742046_1226, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-mr-10004/_tmp.000001_0
2017-09-30 19:09:45,957 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742047_1227, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-mr-10004/_tmp.000002_0
2017-09-30 19:09:46,180 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742048_1228, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-mr-10004/_tmp.000000_0
2017-09-30 19:09:46,188 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742046_1226 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-mr-10004/_tmp.000001_0
2017-09-30 19:09:46,396 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-mr-10004/_tmp.000002_0 is closed by DFSClient_attempt_1506813242048_0004_r_000002_0_848059116_1
2017-09-30 19:09:46,536 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742048_1228 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-mr-10004/_tmp.000000_0
2017-09-30 19:09:46,596 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-mr-10004/_tmp.000001_0 is closed by DFSClient_attempt_1506813242048_0004_r_000001_0_447826971_1
2017-09-30 19:09:46,946 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-mr-10004/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0004_r_000000_0_-1469585970_1
2017-09-30 19:09:47,116 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1133059647_1
2017-09-30 19:09:47,120 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1133059647_1
2017-09-30 19:09:47,148 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0004/job_1506813242048_0004_1.jhist is closed by DFSClient_NONMAPREDUCE_1133059647_1
2017-09-30 19:09:47,167 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742049_1229, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0004.summary_tmp
2017-09-30 19:09:47,313 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0004.summary_tmp is closed by DFSClient_NONMAPREDUCE_1133059647_1
2017-09-30 19:09:47,377 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742050_1230, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0004-1506816554339-root-select+explode%28split%28substr%28get_json_...null-1506816587121-3-3-SUCCEEDED-default-1506816558528.jhist_tmp
2017-09-30 19:09:47,395 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742050_1230 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0004-1506816554339-root-select+explode%28split%28substr%28get_json_...null-1506816587121-3-3-SUCCEEDED-default-1506816558528.jhist_tmp
2017-09-30 19:09:47,799 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0004-1506816554339-root-select+explode%28split%28substr%28get_json_...null-1506816587121-3-3-SUCCEEDED-default-1506816558528.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1133059647_1
2017-09-30 19:09:47,886 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742051_1231, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0004_conf.xml_tmp
2017-09-30 19:09:47,920 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742051_1231 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0004_conf.xml_tmp
2017-09-30 19:09:48,324 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0004_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1133059647_1
2017-09-30 19:09:49,742 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742052_1232, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10009/0c9b03f5-04c2-4674-bde1-78bb6e157e50/map.xml
2017-09-30 19:09:49,750 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10009/0c9b03f5-04c2-4674-bde1-78bb6e157e50/map.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:09:49,752 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10009/0c9b03f5-04c2-4674-bde1-78bb6e157e50/map.xml
2017-09-30 19:09:49,761 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742053_1233, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10009/0c9b03f5-04c2-4674-bde1-78bb6e157e50/reduce.xml
2017-09-30 19:09:49,771 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10009/0c9b03f5-04c2-4674-bde1-78bb6e157e50/reduce.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:09:49,775 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10009/0c9b03f5-04c2-4674-bde1-78bb6e157e50/reduce.xml
2017-09-30 19:09:49,874 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742054_1234, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/job.jar
2017-09-30 19:09:50,019 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/job.jar is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:09:50,023 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/job.jar
2017-09-30 19:09:50,065 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/job.split
2017-09-30 19:09:50,067 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742055_1235, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/job.split
2017-09-30 19:09:50,082 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742055_1235 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/job.split
2017-09-30 19:09:50,486 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/job.split is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:09:50,521 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742056_1236, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/job.splitmetainfo
2017-09-30 19:09:50,554 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:09:50,612 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742057_1237, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/job.xml
2017-09-30 19:09:50,632 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/job.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:10:01,738 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742058_1238, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/job_1506813242048_0005_1_conf.xml
2017-09-30 19:10:01,788 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/job_1506813242048_0005_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-617257796_1
2017-09-30 19:10:17,478 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742059_1239, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/job_1506813242048_0005_1.jhist
2017-09-30 19:10:17,600 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/job_1506813242048_0005_1.jhist for DFSClient_NONMAPREDUCE_-617257796_1
2017-09-30 19:10:32,107 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742060_1240, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-mr-10005/_tmp.000000_0
2017-09-30 19:10:32,633 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742061_1241, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-mr-10005/_tmp.000001_0
2017-09-30 19:10:32,866 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-mr-10005/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0005_r_000000_0_-468886981_1
2017-09-30 19:10:33,310 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742061_1241 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-mr-10005/_tmp.000001_0
2017-09-30 19:10:33,322 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742062_1242, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-mr-10005/_tmp.000002_0
2017-09-30 19:10:33,747 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-mr-10005/_tmp.000001_0 is closed by DFSClient_attempt_1506813242048_0005_r_000001_0_-171939101_1
2017-09-30 19:10:33,940 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742062_1242 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-mr-10005/_tmp.000002_0
2017-09-30 19:10:34,345 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-mr-10005/_tmp.000002_0 is closed by DFSClient_attempt_1506813242048_0005_r_000002_0_795339688_1
2017-09-30 19:10:34,426 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-617257796_1
2017-09-30 19:10:34,430 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-617257796_1
2017-09-30 19:10:34,446 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0005/job_1506813242048_0005_1.jhist is closed by DFSClient_NONMAPREDUCE_-617257796_1
2017-09-30 19:10:34,452 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742063_1243, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0005.summary_tmp
2017-09-30 19:10:34,462 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0005.summary_tmp is closed by DFSClient_NONMAPREDUCE_-617257796_1
2017-09-30 19:10:34,485 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742064_1244, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0005-1506816590659-root-select+explode%28split%28substr%28get_json_...null-1506816634431-4-3-SUCCEEDED-default-1506816601549.jhist_tmp
2017-09-30 19:10:34,494 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0005-1506816590659-root-select+explode%28split%28substr%28get_json_...null-1506816634431-4-3-SUCCEEDED-default-1506816601549.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-617257796_1
2017-09-30 19:10:34,508 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742065_1245, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0005_conf.xml_tmp
2017-09-30 19:10:34,522 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742065_1245 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0005_conf.xml_tmp
2017-09-30 19:10:34,925 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0005_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-617257796_1
2017-09-30 19:10:36,235 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742066_1246, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10011/1a3d5f42-c558-40f4-83bc-bbef7723ea26/map.xml
2017-09-30 19:10:36,244 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742066_1246 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10011/1a3d5f42-c558-40f4-83bc-bbef7723ea26/map.xml
2017-09-30 19:10:36,645 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10011/1a3d5f42-c558-40f4-83bc-bbef7723ea26/map.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:10:36,649 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10011/1a3d5f42-c558-40f4-83bc-bbef7723ea26/map.xml
2017-09-30 19:10:36,659 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742067_1247, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10011/1a3d5f42-c558-40f4-83bc-bbef7723ea26/reduce.xml
2017-09-30 19:10:36,668 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10011/1a3d5f42-c558-40f4-83bc-bbef7723ea26/reduce.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:10:36,670 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10011/1a3d5f42-c558-40f4-83bc-bbef7723ea26/reduce.xml
2017-09-30 19:10:36,774 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742068_1248, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/job.jar
2017-09-30 19:10:36,922 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/job.jar is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:10:36,925 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/job.jar
2017-09-30 19:10:36,955 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/job.split
2017-09-30 19:10:36,958 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742069_1249, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/job.split
2017-09-30 19:10:36,967 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/job.split is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:10:36,974 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742070_1250, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/job.splitmetainfo
2017-09-30 19:10:36,979 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:10:36,993 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742071_1251, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/job.xml
2017-09-30 19:10:37,004 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/job.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:10:47,167 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 261 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 74 Number of syncs: 187 SyncTimes(ms): 391 
2017-09-30 19:10:47,412 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742072_1252, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/job_1506813242048_0006_1_conf.xml
2017-09-30 19:10:47,466 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/job_1506813242048_0006_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-391121516_1
2017-09-30 19:11:02,360 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742073_1253, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/job_1506813242048_0006_1.jhist
2017-09-30 19:11:02,462 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/job_1506813242048_0006_1.jhist for DFSClient_NONMAPREDUCE_-391121516_1
2017-09-30 19:11:15,629 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742074_1254, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10001/.hive-staging_hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-ext-10002/_tmp.000002_0
2017-09-30 19:11:16,393 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742075_1255, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10001/.hive-staging_hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-ext-10002/_tmp.000000_0
2017-09-30 19:11:16,748 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742076_1256, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10001/.hive-staging_hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-ext-10002/_tmp.000001_0
2017-09-30 19:11:16,955 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10001/.hive-staging_hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-ext-10002/_tmp.000002_0 is closed by DFSClient_attempt_1506813242048_0006_r_000002_0_-902614683_1
2017-09-30 19:11:17,614 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10001/.hive-staging_hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-ext-10002/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0006_r_000000_0_-737006776_1
2017-09-30 19:11:17,774 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-09-08_597_2421012345313409004-1/-mr-10001/.hive-staging_hive_2017-09-30_19-09-08_597_2421012345313409004-1/_task_tmp.-ext-10002/_tmp.000001_0 is closed by DFSClient_attempt_1506813242048_0006_r_000001_0_-2068960311_1
2017-09-30 19:11:17,956 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-391121516_1
2017-09-30 19:11:17,961 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-391121516_1
2017-09-30 19:11:17,978 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742073_1253 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/job_1506813242048_0006_1.jhist
2017-09-30 19:11:18,381 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0006/job_1506813242048_0006_1.jhist is closed by DFSClient_NONMAPREDUCE_-391121516_1
2017-09-30 19:11:18,400 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742077_1257, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0006.summary_tmp
2017-09-30 19:11:18,427 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0006.summary_tmp is closed by DFSClient_NONMAPREDUCE_-391121516_1
2017-09-30 19:11:18,489 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742078_1258, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0006-1506816637018-root-select+explode%28split%28substr%28get_json_...null-1506816677962-4-3-SUCCEEDED-default-1506816647141.jhist_tmp
2017-09-30 19:11:18,506 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0006-1506816637018-root-select+explode%28split%28substr%28get_json_...null-1506816677962-4-3-SUCCEEDED-default-1506816647141.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-391121516_1
2017-09-30 19:11:18,526 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742079_1259, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0006_conf.xml_tmp
2017-09-30 19:11:18,539 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742079_1259 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0006_conf.xml_tmp
2017-09-30 19:11:18,943 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0006_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-391121516_1
2017-09-30 19:12:03,890 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 324 Total time for transactions(ms): 18 Number of transactions batched in Syncs: 91 Number of syncs: 232 SyncTimes(ms): 563 
2017-09-30 19:12:03,944 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742080_1260, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10005/bca5cb7e-105c-4537-b881-ffe9c9df8362/map.xml
2017-09-30 19:12:03,956 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742080_1260 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10005/bca5cb7e-105c-4537-b881-ffe9c9df8362/map.xml
2017-09-30 19:12:04,358 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10005/bca5cb7e-105c-4537-b881-ffe9c9df8362/map.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:12:04,363 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10005/bca5cb7e-105c-4537-b881-ffe9c9df8362/map.xml
2017-09-30 19:12:04,373 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742081_1261, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10005/bca5cb7e-105c-4537-b881-ffe9c9df8362/reduce.xml
2017-09-30 19:12:04,384 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742081_1261 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10005/bca5cb7e-105c-4537-b881-ffe9c9df8362/reduce.xml
2017-09-30 19:12:04,788 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10005/bca5cb7e-105c-4537-b881-ffe9c9df8362/reduce.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:12:04,797 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10005/bca5cb7e-105c-4537-b881-ffe9c9df8362/reduce.xml
2017-09-30 19:12:05,005 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742082_1262, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/job.jar
2017-09-30 19:12:05,126 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/job.jar is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:12:05,130 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/job.jar
2017-09-30 19:12:05,145 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/job.split
2017-09-30 19:12:05,146 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742083_1263, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/job.split
2017-09-30 19:12:05,153 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/job.split is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:12:05,158 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742084_1264, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/job.splitmetainfo
2017-09-30 19:12:05,163 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:12:05,175 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742085_1265, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/job.xml
2017-09-30 19:12:05,193 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742085_1265 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/job.xml
2017-09-30 19:12:05,596 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/job.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:12:10,344 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742086_1266, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/job_1506813242048_0007_1_conf.xml
2017-09-30 19:12:10,383 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/job_1506813242048_0007_1_conf.xml is closed by DFSClient_NONMAPREDUCE_583229140_1
2017-09-30 19:12:24,430 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742087_1267, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/job_1506813242048_0007_1.jhist
2017-09-30 19:12:24,540 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/job_1506813242048_0007_1.jhist for DFSClient_NONMAPREDUCE_583229140_1
2017-09-30 19:12:36,901 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742088_1268, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-mr-10002/_tmp.000001_0
2017-09-30 19:12:37,205 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-mr-10002/_tmp.000001_0 is closed by DFSClient_attempt_1506813242048_0007_r_000001_0_1350047491_1
2017-09-30 19:12:37,302 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742089_1269, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-mr-10002/_tmp.000000_0
2017-09-30 19:12:37,586 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-mr-10002/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0007_r_000000_0_602197540_1
2017-09-30 19:12:37,985 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742090_1270, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-mr-10002/_tmp.000002_0
2017-09-30 19:12:38,125 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742090_1270 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-mr-10002/_tmp.000002_0
2017-09-30 19:12:38,537 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-mr-10002/_tmp.000002_0 is closed by DFSClient_attempt_1506813242048_0007_r_000002_0_-1208040106_1
2017-09-30 19:12:38,712 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_583229140_1
2017-09-30 19:12:38,717 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_583229140_1
2017-09-30 19:12:38,732 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0007/job_1506813242048_0007_1.jhist is closed by DFSClient_NONMAPREDUCE_583229140_1
2017-09-30 19:12:38,738 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742091_1271, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0007.summary_tmp
2017-09-30 19:12:38,745 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0007.summary_tmp is closed by DFSClient_NONMAPREDUCE_583229140_1
2017-09-30 19:12:38,766 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742092_1272, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0007-1506816725650-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506816758720-3-3-SUCCEEDED-default-1506816730184.jhist_tmp
2017-09-30 19:12:38,773 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0007-1506816725650-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506816758720-3-3-SUCCEEDED-default-1506816730184.jhist_tmp is closed by DFSClient_NONMAPREDUCE_583229140_1
2017-09-30 19:12:38,786 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742093_1273, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0007_conf.xml_tmp
2017-09-30 19:12:38,801 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0007_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_583229140_1
2017-09-30 19:12:40,065 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742094_1274, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10007/be69a5cb-a239-400a-a271-dc0df55dbd22/map.xml
2017-09-30 19:12:40,072 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742094_1274 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10007/be69a5cb-a239-400a-a271-dc0df55dbd22/map.xml
2017-09-30 19:12:40,474 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10007/be69a5cb-a239-400a-a271-dc0df55dbd22/map.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:12:40,483 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10007/be69a5cb-a239-400a-a271-dc0df55dbd22/map.xml
2017-09-30 19:12:40,506 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742095_1275, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10007/be69a5cb-a239-400a-a271-dc0df55dbd22/reduce.xml
2017-09-30 19:12:40,530 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742095_1275 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10007/be69a5cb-a239-400a-a271-dc0df55dbd22/reduce.xml
2017-09-30 19:12:40,935 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10007/be69a5cb-a239-400a-a271-dc0df55dbd22/reduce.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:12:40,944 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10007/be69a5cb-a239-400a-a271-dc0df55dbd22/reduce.xml
2017-09-30 19:12:41,104 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742096_1276, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job.jar
2017-09-30 19:12:41,273 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742096_1276 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job.jar
2017-09-30 19:12:41,675 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job.jar is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:12:41,685 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job.jar
2017-09-30 19:12:41,761 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job.split
2017-09-30 19:12:41,764 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742097_1277, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job.split
2017-09-30 19:12:41,773 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job.split is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:12:41,779 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742098_1278, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job.splitmetainfo
2017-09-30 19:12:41,790 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:12:41,809 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742099_1279, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job.xml
2017-09-30 19:12:41,819 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:12:51,459 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742100_1280, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job_1506813242048_0008_1_conf.xml
2017-09-30 19:12:51,489 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742100_1280 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job_1506813242048_0008_1_conf.xml
2017-09-30 19:12:51,895 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job_1506813242048_0008_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1686017474_1
2017-09-30 19:13:08,152 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742101_1281, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job_1506813242048_0008_1.jhist
2017-09-30 19:13:08,152 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 482 Total time for transactions(ms): 28 Number of transactions batched in Syncs: 137 Number of syncs: 343 SyncTimes(ms): 783 
2017-09-30 19:13:08,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job_1506813242048_0008_1.jhist for DFSClient_NONMAPREDUCE_1686017474_1
2017-09-30 19:13:20,684 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742102_1282, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-mr-10003/_tmp.000002_0
2017-09-30 19:13:20,835 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742103_1283, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-mr-10003/_tmp.000000_0
2017-09-30 19:13:20,960 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742104_1284, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-mr-10003/_tmp.000001_0
2017-09-30 19:13:21,412 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742102_1282 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-mr-10003/_tmp.000002_0
2017-09-30 19:13:21,455 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-mr-10003/_tmp.000001_0 is closed by DFSClient_attempt_1506813242048_0008_r_000001_0_287227621_1
2017-09-30 19:13:21,518 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-mr-10003/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0008_r_000000_0_953419743_1
2017-09-30 19:13:21,838 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-mr-10003/_tmp.000002_0 is closed by DFSClient_attempt_1506813242048_0008_r_000002_0_1664082459_1
2017-09-30 19:13:22,076 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1686017474_1
2017-09-30 19:13:22,082 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1686017474_1
2017-09-30 19:13:22,116 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742101_1281 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job_1506813242048_0008_1.jhist
2017-09-30 19:13:22,519 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0008/job_1506813242048_0008_1.jhist is closed by DFSClient_NONMAPREDUCE_1686017474_1
2017-09-30 19:13:22,533 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742105_1285, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0008.summary_tmp
2017-09-30 19:13:22,553 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0008.summary_tmp is closed by DFSClient_NONMAPREDUCE_1686017474_1
2017-09-30 19:13:22,590 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742106_1286, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0008-1506816761834-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506816802083-4-3-SUCCEEDED-default-1506816771312.jhist_tmp
2017-09-30 19:13:22,615 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0008-1506816761834-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506816802083-4-3-SUCCEEDED-default-1506816771312.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1686017474_1
2017-09-30 19:13:22,646 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742107_1287, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0008_conf.xml_tmp
2017-09-30 19:13:22,658 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0008_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1686017474_1
2017-09-30 19:13:24,886 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742108_1288, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10009/b5b4fd37-fc16-4428-87d2-64c21bd77249/map.xml
2017-09-30 19:13:24,903 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10009/b5b4fd37-fc16-4428-87d2-64c21bd77249/map.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:13:24,906 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10009/b5b4fd37-fc16-4428-87d2-64c21bd77249/map.xml
2017-09-30 19:13:24,921 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742109_1289, replicas=127.0.0.1:50010 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10009/b5b4fd37-fc16-4428-87d2-64c21bd77249/reduce.xml
2017-09-30 19:13:24,933 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10009/b5b4fd37-fc16-4428-87d2-64c21bd77249/reduce.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:13:24,937 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/80c19218-881a-48db-ae30-b41977bf65e4/hive_2017-09-30_19-12-03_714_6342658737141026056-1/-mr-10009/b5b4fd37-fc16-4428-87d2-64c21bd77249/reduce.xml
2017-09-30 19:13:25,097 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742110_1290, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/job.jar
2017-09-30 19:13:25,283 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/job.jar is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:13:25,286 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/job.jar
2017-09-30 19:13:25,317 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/job.split
2017-09-30 19:13:25,318 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742111_1291, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/job.split
2017-09-30 19:13:25,323 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/job.split is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:13:25,329 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742112_1292, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/job.splitmetainfo
2017-09-30 19:13:25,334 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:13:25,346 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742113_1293, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/job.xml
2017-09-30 19:13:25,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742113_1293 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/job.xml
2017-09-30 19:13:25,759 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/job.xml is closed by DFSClient_NONMAPREDUCE_1610145433_1
2017-09-30 19:13:34,952 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742114_1294, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/job_1506813242048_0009_1_conf.xml
2017-09-30 19:13:35,007 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/job_1506813242048_0009_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1751229865_1
2017-09-30 19:13:51,989 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742115_1295, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/job_1506813242048_0009_1.jhist
2017-09-30 19:13:52,118 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/job_1506813242048_0009_1.jhist for DFSClient_NONMAPREDUCE_1751229865_1
2017-09-30 19:14:03,707 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742116_1296, replicas=127.0.0.1:50010 for /test/proj1_output/.hive-staging_hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-ext-10000/_tmp.000000_0
2017-09-30 19:14:03,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742117_1297, replicas=127.0.0.1:50010 for /test/proj1_output/.hive-staging_hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-ext-10000/_tmp.000001_0
2017-09-30 19:14:04,421 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742118_1298, replicas=127.0.0.1:50010 for /test/proj1_output/.hive-staging_hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-ext-10000/_tmp.000002_0
2017-09-30 19:14:04,493 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742116_1296 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /test/proj1_output/.hive-staging_hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-ext-10000/_tmp.000000_0
2017-09-30 19:14:04,512 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742117_1297 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /test/proj1_output/.hive-staging_hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-ext-10000/_tmp.000001_0
2017-09-30 19:14:04,862 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_output/.hive-staging_hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-ext-10000/_tmp.000002_0 is closed by DFSClient_attempt_1506813242048_0009_r_000002_0_205217306_1
2017-09-30 19:14:04,908 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_output/.hive-staging_hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-ext-10000/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0009_r_000000_0_-214331491_1
2017-09-30 19:14:04,939 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_output/.hive-staging_hive_2017-09-30_19-12-03_714_6342658737141026056-1/_task_tmp.-ext-10000/_tmp.000001_0 is closed by DFSClient_attempt_1506813242048_0009_r_000001_0_-1666602259_1
2017-09-30 19:14:05,104 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1751229865_1
2017-09-30 19:14:05,113 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1751229865_1
2017-09-30 19:14:05,132 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0009/job_1506813242048_0009_1.jhist is closed by DFSClient_NONMAPREDUCE_1751229865_1
2017-09-30 19:14:05,138 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742119_1299, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0009.summary_tmp
2017-09-30 19:14:05,154 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0009.summary_tmp is closed by DFSClient_NONMAPREDUCE_1751229865_1
2017-09-30 19:14:05,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742120_1300, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0009-1506816805810-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506816845116-4-3-SUCCEEDED-default-1506816814799.jhist_tmp
2017-09-30 19:14:05,188 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0009-1506816805810-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506816845116-4-3-SUCCEEDED-default-1506816814799.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1751229865_1
2017-09-30 19:14:05,218 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742121_1301, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0009_conf.xml_tmp
2017-09-30 19:14:05,228 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0009_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1751229865_1
2017-09-30 19:15:16,792 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 646 Total time for transactions(ms): 33 Number of transactions batched in Syncs: 183 Number of syncs: 463 SyncTimes(ms): 1065 
2017-09-30 19:22:08,622 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 647 Total time for transactions(ms): 33 Number of transactions batched in Syncs: 183 Number of syncs: 464 SyncTimes(ms): 1067 
2017-09-30 19:22:08,681 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742122_1302, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0010/job.jar
2017-09-30 19:22:08,728 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0010/job.jar is closed by DFSClient_NONMAPREDUCE_-1559222002_1
2017-09-30 19:22:08,733 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0010/job.jar
2017-09-30 19:23:57,256 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 657 Total time for transactions(ms): 33 Number of transactions batched in Syncs: 185 Number of syncs: 472 SyncTimes(ms): 1071 
2017-09-30 19:23:57,315 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742123_1303, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/job.jar
2017-09-30 19:23:57,370 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/job.jar is closed by DFSClient_NONMAPREDUCE_-1923237504_1
2017-09-30 19:23:57,375 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/job.jar
2017-09-30 19:23:57,417 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/job.split
2017-09-30 19:23:57,425 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742124_1304, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/job.split
2017-09-30 19:23:57,431 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/job.split is closed by DFSClient_NONMAPREDUCE_-1923237504_1
2017-09-30 19:23:57,441 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742125_1305, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/job.splitmetainfo
2017-09-30 19:23:57,451 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-1923237504_1
2017-09-30 19:23:57,551 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742126_1306, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/job.xml
2017-09-30 19:23:57,563 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742126_1306 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/job.xml
2017-09-30 19:23:57,966 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/job.xml is closed by DFSClient_NONMAPREDUCE_-1923237504_1
2017-09-30 19:24:03,544 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742127_1307, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/job_1506813242048_0011_1_conf.xml
2017-09-30 19:24:03,573 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/job_1506813242048_0011_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1688102962_1
2017-09-30 19:24:11,355 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742128_1308, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/job_1506813242048_0011_1.jhist
2017-09-30 19:24:11,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/job_1506813242048_0011_1.jhist for DFSClient_NONMAPREDUCE_1688102962_1
2017-09-30 19:24:16,071 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742129_1309, replicas=127.0.0.1:50010 for /test/projwc/_temporary/1/_temporary/attempt_1506813242048_0011_r_000000_0/part-r-00000
2017-09-30 19:24:16,371 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/projwc/_temporary/1/_temporary/attempt_1506813242048_0011_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1506813242048_0011_r_000000_0_2048150266_1
2017-09-30 19:24:16,509 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1688102962_1
2017-09-30 19:24:16,537 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/projwc/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1688102962_1
2017-09-30 19:24:16,543 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1688102962_1
2017-09-30 19:24:16,560 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742128_1308 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/job_1506813242048_0011_1.jhist
2017-09-30 19:24:16,965 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0011/job_1506813242048_0011_1.jhist is closed by DFSClient_NONMAPREDUCE_1688102962_1
2017-09-30 19:24:16,986 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742130_1310, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0011.summary_tmp
2017-09-30 19:24:17,014 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0011.summary_tmp is closed by DFSClient_NONMAPREDUCE_1688102962_1
2017-09-30 19:24:17,085 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742131_1311, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0011-1506817438354-root-word+count-1506817456544-3-1-SUCCEEDED-default-1506817443357.jhist_tmp
2017-09-30 19:24:17,116 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742131_1311 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0011-1506817438354-root-word+count-1506817456544-3-1-SUCCEEDED-default-1506817443357.jhist_tmp
2017-09-30 19:24:17,523 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0011-1506817438354-root-word+count-1506817456544-3-1-SUCCEEDED-default-1506817443357.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1688102962_1
2017-09-30 19:24:17,565 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742132_1312, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0011_conf.xml_tmp
2017-09-30 19:24:17,596 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0011_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1688102962_1
2017-09-30 19:38:11,989 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 737 Total time for transactions(ms): 37 Number of transactions batched in Syncs: 209 Number of syncs: 528 SyncTimes(ms): 1166 
2017-09-30 19:38:20,557 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742133_1313, replicas=127.0.0.1:50010 for /tmp/hive/root/f5c96744-fe1c-4466-a12a-bf0220210936/hive_2017-09-30_19-38-19_257_1929673169893754220-1/dummy_path/dummy_file
2017-09-30 19:38:20,629 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742133_1313 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/f5c96744-fe1c-4466-a12a-bf0220210936/hive_2017-09-30_19-38-19_257_1929673169893754220-1/dummy_path/dummy_file
2017-09-30 19:38:21,036 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/f5c96744-fe1c-4466-a12a-bf0220210936/hive_2017-09-30_19-38-19_257_1929673169893754220-1/dummy_path/dummy_file is closed by DFSClient_NONMAPREDUCE_764100346_1
2017-09-30 19:39:15,733 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 747 Total time for transactions(ms): 37 Number of transactions batched in Syncs: 212 Number of syncs: 535 SyncTimes(ms): 1183 
2017-09-30 19:44:26,020 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 756 Total time for transactions(ms): 37 Number of transactions batched in Syncs: 214 Number of syncs: 542 SyncTimes(ms): 1200 
2017-09-30 19:48:36,728 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 759 Total time for transactions(ms): 37 Number of transactions batched in Syncs: 214 Number of syncs: 545 SyncTimes(ms): 1209 
2017-09-30 19:48:47,355 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742134_1314, replicas=127.0.0.1:50010 for /tmp/hive/root/c5253cf6-6a2f-4630-9722-9268f89020f3/hive_2017-09-30_19-48-44_852_8227314682665269919-1/-mr-10004/c96f5bbf-1b45-45c2-95ea-7d71bfc31e16/map.xml
2017-09-30 19:48:47,438 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/c5253cf6-6a2f-4630-9722-9268f89020f3/hive_2017-09-30_19-48-44_852_8227314682665269919-1/-mr-10004/c96f5bbf-1b45-45c2-95ea-7d71bfc31e16/map.xml is closed by DFSClient_NONMAPREDUCE_863843429_1
2017-09-30 19:48:47,449 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/c5253cf6-6a2f-4630-9722-9268f89020f3/hive_2017-09-30_19-48-44_852_8227314682665269919-1/-mr-10004/c96f5bbf-1b45-45c2-95ea-7d71bfc31e16/map.xml
2017-09-30 19:48:47,911 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000, call Call#33 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:59042: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/c5253cf6-6a2f-4630-9722-9268f89020f3/hive_2017-09-30_19-48-44_852_8227314682665269919-1/-mr-10004/c96f5bbf-1b45-45c2-95ea-7d71bfc31e16/reduce.xml
2017-09-30 19:48:48,101 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742135_1315, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/job.jar
2017-09-30 19:48:48,334 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/job.jar is closed by DFSClient_NONMAPREDUCE_863843429_1
2017-09-30 19:48:48,339 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/job.jar
2017-09-30 19:48:48,451 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/job.split
2017-09-30 19:48:48,457 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742136_1316, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/job.split
2017-09-30 19:48:48,465 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742136_1316 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/job.split
2017-09-30 19:48:48,867 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/job.split is closed by DFSClient_NONMAPREDUCE_863843429_1
2017-09-30 19:48:48,875 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742137_1317, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/job.splitmetainfo
2017-09-30 19:48:48,886 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_863843429_1
2017-09-30 19:48:48,928 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742138_1318, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/job.xml
2017-09-30 19:48:48,950 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/job.xml is closed by DFSClient_NONMAPREDUCE_863843429_1
2017-09-30 19:48:53,438 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742139_1319, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/job_1506813242048_0012_1_conf.xml
2017-09-30 19:48:53,503 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/job_1506813242048_0012_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-2059587664_1
2017-09-30 19:49:06,597 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742140_1320, replicas=127.0.0.1:50010 for /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-48-44_852_8227314682665269919-1/_task_tmp.-ext-10002/_tmp.000002_0
2017-09-30 19:49:06,652 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742141_1321, replicas=127.0.0.1:50010 for /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-48-44_852_8227314682665269919-1/_task_tmp.-ext-10002/_tmp.000001_0
2017-09-30 19:49:06,697 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742140_1320 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-48-44_852_8227314682665269919-1/_task_tmp.-ext-10002/_tmp.000002_0
2017-09-30 19:49:07,141 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-48-44_852_8227314682665269919-1/_task_tmp.-ext-10002/_tmp.000002_0 is closed by DFSClient_attempt_1506813242048_0012_m_000002_0_-751019290_1
2017-09-30 19:49:07,171 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742142_1322, replicas=127.0.0.1:50010 for /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-48-44_852_8227314682665269919-1/_task_tmp.-ext-10002/_tmp.000000_0
2017-09-30 19:49:07,487 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742143_1323, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/job_1506813242048_0012_1.jhist
2017-09-30 19:49:07,575 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/job_1506813242048_0012_1.jhist for DFSClient_NONMAPREDUCE_-2059587664_1
2017-09-30 19:49:11,564 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-48-44_852_8227314682665269919-1/_task_tmp.-ext-10002/_tmp.000001_0 is closed by DFSClient_attempt_1506813242048_0012_m_000001_0_454266871_1
2017-09-30 19:49:11,613 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-48-44_852_8227314682665269919-1/_task_tmp.-ext-10002/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0012_m_000000_0_1266134210_1
2017-09-30 19:49:11,734 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-2059587664_1
2017-09-30 19:49:11,738 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-2059587664_1
2017-09-30 19:49:11,758 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0012/job_1506813242048_0012_1.jhist is closed by DFSClient_NONMAPREDUCE_-2059587664_1
2017-09-30 19:49:11,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742144_1324, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0012.summary_tmp
2017-09-30 19:49:11,771 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0012.summary_tmp is closed by DFSClient_NONMAPREDUCE_-2059587664_1
2017-09-30 19:49:11,794 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742145_1325, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0012-1506818929176-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506818951739-3-0-SUCCEEDED-default-1506818933236.jhist_tmp
2017-09-30 19:49:11,807 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0012-1506818929176-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506818951739-3-0-SUCCEEDED-default-1506818933236.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-2059587664_1
2017-09-30 19:49:11,829 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742146_1326, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0012_conf.xml_tmp
2017-09-30 19:49:11,853 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742146_1326 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0012_conf.xml_tmp
2017-09-30 19:49:12,256 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0012_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-2059587664_1
2017-09-30 19:49:14,196 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742147_1327, replicas=127.0.0.1:50010 for /tmp/hive/root/c5253cf6-6a2f-4630-9722-9268f89020f3/hive_2017-09-30_19-48-44_852_8227314682665269919-1/-mr-10006/40b807ef-104a-42a0-83f9-3caf527df5be/map.xml
2017-09-30 19:49:14,202 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/c5253cf6-6a2f-4630-9722-9268f89020f3/hive_2017-09-30_19-48-44_852_8227314682665269919-1/-mr-10006/40b807ef-104a-42a0-83f9-3caf527df5be/map.xml is closed by DFSClient_NONMAPREDUCE_863843429_1
2017-09-30 19:49:14,204 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/c5253cf6-6a2f-4630-9722-9268f89020f3/hive_2017-09-30_19-48-44_852_8227314682665269919-1/-mr-10006/40b807ef-104a-42a0-83f9-3caf527df5be/map.xml
2017-09-30 19:49:14,282 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call Call#211 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:59126: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/c5253cf6-6a2f-4630-9722-9268f89020f3/hive_2017-09-30_19-48-44_852_8227314682665269919-1/-mr-10006/40b807ef-104a-42a0-83f9-3caf527df5be/reduce.xml
2017-09-30 19:49:14,303 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742148_1328, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/job.jar
2017-09-30 19:49:14,444 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/job.jar is closed by DFSClient_NONMAPREDUCE_863843429_1
2017-09-30 19:49:14,448 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/job.jar
2017-09-30 19:49:14,469 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/job.split
2017-09-30 19:49:14,470 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742149_1329, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/job.split
2017-09-30 19:49:14,477 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742149_1329 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/job.split
2017-09-30 19:49:14,881 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/job.split is closed by DFSClient_NONMAPREDUCE_863843429_1
2017-09-30 19:49:14,903 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742150_1330, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/job.splitmetainfo
2017-09-30 19:49:14,925 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_863843429_1
2017-09-30 19:49:14,989 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742151_1331, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/job.xml
2017-09-30 19:49:15,001 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742151_1331 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/job.xml
2017-09-30 19:49:15,405 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/job.xml is closed by DFSClient_NONMAPREDUCE_863843429_1
2017-09-30 19:49:24,066 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742152_1332, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/job_1506813242048_0013_1_conf.xml
2017-09-30 19:49:24,099 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/job_1506813242048_0013_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-2046715244_1
2017-09-30 19:49:28,743 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742153_1333, replicas=127.0.0.1:50010 for /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-48-44_852_8227314682665269919-1/_task_tmp.-ext-10000/_tmp.000000_0
2017-09-30 19:49:28,895 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-48-44_852_8227314682665269919-1/_task_tmp.-ext-10000/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0013_m_000000_0_-128666925_1
2017-09-30 19:49:29,020 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742154_1334, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/job_1506813242048_0013_1.jhist
2017-09-30 19:49:29,024 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-2046715244_1
2017-09-30 19:49:29,030 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/job_1506813242048_0013_1.jhist for DFSClient_NONMAPREDUCE_-2046715244_1
2017-09-30 19:49:29,032 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-2046715244_1
2017-09-30 19:49:29,056 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0013/job_1506813242048_0013_1.jhist is closed by DFSClient_NONMAPREDUCE_-2046715244_1
2017-09-30 19:49:29,062 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742155_1335, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0013.summary_tmp
2017-09-30 19:49:29,070 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0013.summary_tmp is closed by DFSClient_NONMAPREDUCE_-2046715244_1
2017-09-30 19:49:29,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742156_1336, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0013-1506818955473-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506818969036-1-0-SUCCEEDED-default-1506818963913.jhist_tmp
2017-09-30 19:49:29,127 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0013-1506818955473-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506818969036-1-0-SUCCEEDED-default-1506818963913.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-2046715244_1
2017-09-30 19:49:29,156 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742157_1337, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0013_conf.xml_tmp
2017-09-30 19:49:29,168 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0013_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-2046715244_1
2017-09-30 19:52:14,461 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 951 Total time for transactions(ms): 46 Number of transactions batched in Syncs: 267 Number of syncs: 684 SyncTimes(ms): 1442 
2017-09-30 19:53:06,107 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742158_1338, replicas=127.0.0.1:50010 for /tmp/hive/root/2d31caf4-b06a-48d8-b6d2-a8e6394c8167/hive_2017-09-30_19-53-04_309_3108680497922228949-1/-mr-10004/4b1ce260-5841-42b9-aa56-d2647a6da315/map.xml
2017-09-30 19:53:06,187 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/2d31caf4-b06a-48d8-b6d2-a8e6394c8167/hive_2017-09-30_19-53-04_309_3108680497922228949-1/-mr-10004/4b1ce260-5841-42b9-aa56-d2647a6da315/map.xml is closed by DFSClient_NONMAPREDUCE_1073731461_1
2017-09-30 19:53:06,196 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/2d31caf4-b06a-48d8-b6d2-a8e6394c8167/hive_2017-09-30_19-53-04_309_3108680497922228949-1/-mr-10004/4b1ce260-5841-42b9-aa56-d2647a6da315/map.xml
2017-09-30 19:53:06,614 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9000, call Call#30 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:59206: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/2d31caf4-b06a-48d8-b6d2-a8e6394c8167/hive_2017-09-30_19-53-04_309_3108680497922228949-1/-mr-10004/4b1ce260-5841-42b9-aa56-d2647a6da315/reduce.xml
2017-09-30 19:53:06,725 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742159_1339, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job.jar
2017-09-30 19:53:06,932 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742159_1339 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job.jar
2017-09-30 19:53:07,336 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job.jar is closed by DFSClient_NONMAPREDUCE_1073731461_1
2017-09-30 19:53:07,344 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job.jar
2017-09-30 19:53:07,520 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job.split
2017-09-30 19:53:07,526 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742160_1340, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job.split
2017-09-30 19:53:07,551 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742160_1340 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job.split
2017-09-30 19:53:07,953 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job.split is closed by DFSClient_NONMAPREDUCE_1073731461_1
2017-09-30 19:53:07,961 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742161_1341, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job.splitmetainfo
2017-09-30 19:53:07,968 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1073731461_1
2017-09-30 19:53:08,015 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742162_1342, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job.xml
2017-09-30 19:53:08,054 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job.xml is closed by DFSClient_NONMAPREDUCE_1073731461_1
2017-09-30 19:53:12,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742163_1343, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job_1506813242048_0014_1_conf.xml
2017-09-30 19:53:12,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742163_1343 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job_1506813242048_0014_1_conf.xml
2017-09-30 19:53:13,375 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job_1506813242048_0014_1_conf.xml is closed by DFSClient_NONMAPREDUCE_642019226_1
2017-09-30 19:53:21,618 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1000 Total time for transactions(ms): 48 Number of transactions batched in Syncs: 280 Number of syncs: 719 SyncTimes(ms): 1489 
2017-09-30 19:53:24,791 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742164_1344, replicas=127.0.0.1:50010 for /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-53-04_309_3108680497922228949-1/_task_tmp.-ext-10002/_tmp.000001_0
2017-09-30 19:53:25,629 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742165_1345, replicas=127.0.0.1:50010 for /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-53-04_309_3108680497922228949-1/_task_tmp.-ext-10002/_tmp.000002_0
2017-09-30 19:53:26,442 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742166_1346, replicas=127.0.0.1:50010 for /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-53-04_309_3108680497922228949-1/_task_tmp.-ext-10002/_tmp.000000_0
2017-09-30 19:53:26,625 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-53-04_309_3108680497922228949-1/_task_tmp.-ext-10002/_tmp.000002_0 is closed by DFSClient_attempt_1506813242048_0014_m_000002_0_1928950584_1
2017-09-30 19:53:27,053 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742167_1347, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job_1506813242048_0014_1.jhist
2017-09-30 19:53:27,208 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job_1506813242048_0014_1.jhist for DFSClient_NONMAPREDUCE_642019226_1
2017-09-30 19:53:30,794 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-53-04_309_3108680497922228949-1/_task_tmp.-ext-10002/_tmp.000001_0 is closed by DFSClient_attempt_1506813242048_0014_m_000001_0_1186289226_1
2017-09-30 19:53:31,511 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-53-04_309_3108680497922228949-1/_task_tmp.-ext-10002/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0014_m_000000_0_1242801393_1
2017-09-30 19:53:31,601 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_642019226_1
2017-09-30 19:53:31,605 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_642019226_1
2017-09-30 19:53:31,629 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0014/job_1506813242048_0014_1.jhist is closed by DFSClient_NONMAPREDUCE_642019226_1
2017-09-30 19:53:31,634 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742168_1348, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0014.summary_tmp
2017-09-30 19:53:31,641 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0014.summary_tmp is closed by DFSClient_NONMAPREDUCE_642019226_1
2017-09-30 19:53:31,661 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742169_1349, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0014-1506819188265-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819211607-3-0-SUCCEEDED-default-1506819192749.jhist_tmp
2017-09-30 19:53:31,667 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0014-1506819188265-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819211607-3-0-SUCCEEDED-default-1506819192749.jhist_tmp is closed by DFSClient_NONMAPREDUCE_642019226_1
2017-09-30 19:53:31,679 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742170_1350, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0014_conf.xml_tmp
2017-09-30 19:53:31,692 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0014_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_642019226_1
2017-09-30 19:53:33,161 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742171_1351, replicas=127.0.0.1:50010 for /tmp/hive/root/2d31caf4-b06a-48d8-b6d2-a8e6394c8167/hive_2017-09-30_19-53-04_309_3108680497922228949-1/-mr-10006/3aa04f5b-926b-4a1f-bcb4-9f4cd78e35de/map.xml
2017-09-30 19:53:33,169 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742171_1351 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/2d31caf4-b06a-48d8-b6d2-a8e6394c8167/hive_2017-09-30_19-53-04_309_3108680497922228949-1/-mr-10006/3aa04f5b-926b-4a1f-bcb4-9f4cd78e35de/map.xml
2017-09-30 19:53:33,572 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/2d31caf4-b06a-48d8-b6d2-a8e6394c8167/hive_2017-09-30_19-53-04_309_3108680497922228949-1/-mr-10006/3aa04f5b-926b-4a1f-bcb4-9f4cd78e35de/map.xml is closed by DFSClient_NONMAPREDUCE_1073731461_1
2017-09-30 19:53:33,579 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/2d31caf4-b06a-48d8-b6d2-a8e6394c8167/hive_2017-09-30_19-53-04_309_3108680497922228949-1/-mr-10006/3aa04f5b-926b-4a1f-bcb4-9f4cd78e35de/map.xml
2017-09-30 19:53:33,806 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000, call Call#207 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:59288: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/2d31caf4-b06a-48d8-b6d2-a8e6394c8167/hive_2017-09-30_19-53-04_309_3108680497922228949-1/-mr-10006/3aa04f5b-926b-4a1f-bcb4-9f4cd78e35de/reduce.xml
2017-09-30 19:53:33,842 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742172_1352, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/job.jar
2017-09-30 19:53:34,009 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/job.jar is closed by DFSClient_NONMAPREDUCE_1073731461_1
2017-09-30 19:53:34,011 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/job.jar
2017-09-30 19:53:34,038 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/job.split
2017-09-30 19:53:34,040 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742173_1353, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/job.split
2017-09-30 19:53:34,046 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/job.split is closed by DFSClient_NONMAPREDUCE_1073731461_1
2017-09-30 19:53:34,054 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742174_1354, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/job.splitmetainfo
2017-09-30 19:53:34,061 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1073731461_1
2017-09-30 19:53:34,076 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742175_1355, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/job.xml
2017-09-30 19:53:34,102 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742175_1355 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/job.xml
2017-09-30 19:53:34,505 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/job.xml is closed by DFSClient_NONMAPREDUCE_1073731461_1
2017-09-30 19:53:44,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742176_1356, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/job_1506813242048_0015_1_conf.xml
2017-09-30 19:53:44,344 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/job_1506813242048_0015_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1690772768_1
2017-09-30 19:53:49,052 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742177_1357, replicas=127.0.0.1:50010 for /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-53-04_309_3108680497922228949-1/_task_tmp.-ext-10000/_tmp.000000_0
2017-09-30 19:53:49,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742177_1357 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-53-04_309_3108680497922228949-1/_task_tmp.-ext-10000/_tmp.000000_0
2017-09-30 19:53:49,637 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-53-04_309_3108680497922228949-1/_task_tmp.-ext-10000/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0015_m_000000_0_-456685171_1
2017-09-30 19:53:49,824 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742178_1358, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/job_1506813242048_0015_1.jhist
2017-09-30 19:53:49,834 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/job_1506813242048_0015_1.jhist for DFSClient_NONMAPREDUCE_1690772768_1
2017-09-30 19:53:49,837 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1690772768_1
2017-09-30 19:53:49,843 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1690772768_1
2017-09-30 19:53:49,862 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0015/job_1506813242048_0015_1.jhist is closed by DFSClient_NONMAPREDUCE_1690772768_1
2017-09-30 19:53:49,867 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742179_1359, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0015.summary_tmp
2017-09-30 19:53:49,875 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0015.summary_tmp is closed by DFSClient_NONMAPREDUCE_1690772768_1
2017-09-30 19:53:49,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742180_1360, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0015-1506819214562-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819229846-1-0-SUCCEEDED-default-1506819224150.jhist_tmp
2017-09-30 19:53:49,940 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0015-1506819214562-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819229846-1-0-SUCCEEDED-default-1506819224150.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1690772768_1
2017-09-30 19:53:49,959 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742181_1361, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0015_conf.xml_tmp
2017-09-30 19:53:49,973 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0015_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1690772768_1
2017-09-30 19:56:32,992 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1143 Total time for transactions(ms): 53 Number of transactions batched in Syncs: 319 Number of syncs: 824 SyncTimes(ms): 1670 
2017-09-30 19:56:44,398 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742182_1362, replicas=127.0.0.1:50010 for /tmp/hive/root/ae9b7a3e-9dc8-42d5-8ab8-80e4c536439d/hive_2017-09-30_19-56-41_935_5360326301602140694-1/-mr-10004/e12971c9-0178-4055-a49f-c4d50aa5b433/map.xml
2017-09-30 19:56:44,482 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/ae9b7a3e-9dc8-42d5-8ab8-80e4c536439d/hive_2017-09-30_19-56-41_935_5360326301602140694-1/-mr-10004/e12971c9-0178-4055-a49f-c4d50aa5b433/map.xml is closed by DFSClient_NONMAPREDUCE_-250977902_1
2017-09-30 19:56:44,493 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/ae9b7a3e-9dc8-42d5-8ab8-80e4c536439d/hive_2017-09-30_19-56-41_935_5360326301602140694-1/-mr-10004/e12971c9-0178-4055-a49f-c4d50aa5b433/map.xml
2017-09-30 19:56:44,807 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000, call Call#30 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:59366: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/ae9b7a3e-9dc8-42d5-8ab8-80e4c536439d/hive_2017-09-30_19-56-41_935_5360326301602140694-1/-mr-10004/e12971c9-0178-4055-a49f-c4d50aa5b433/reduce.xml
2017-09-30 19:56:44,909 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742183_1363, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/job.jar
2017-09-30 19:56:45,120 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742183_1363 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/job.jar
2017-09-30 19:56:45,523 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/job.jar is closed by DFSClient_NONMAPREDUCE_-250977902_1
2017-09-30 19:56:45,532 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/job.jar
2017-09-30 19:56:45,693 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/job.split
2017-09-30 19:56:45,706 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742184_1364, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/job.split
2017-09-30 19:56:45,718 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742184_1364 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/job.split
2017-09-30 19:56:46,119 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/job.split is closed by DFSClient_NONMAPREDUCE_-250977902_1
2017-09-30 19:56:46,138 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742185_1365, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/job.splitmetainfo
2017-09-30 19:56:46,154 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-250977902_1
2017-09-30 19:56:46,234 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742186_1366, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/job.xml
2017-09-30 19:56:46,265 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/job.xml is closed by DFSClient_NONMAPREDUCE_-250977902_1
2017-09-30 19:56:51,458 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742187_1367, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/job_1506813242048_0016_1_conf.xml
2017-09-30 19:56:51,492 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/job_1506813242048_0016_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1914410126_1
2017-09-30 19:57:04,903 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742188_1368, replicas=127.0.0.1:50010 for /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-56-41_935_5360326301602140694-1/_task_tmp.-ext-10002/_tmp.000002_0
2017-09-30 19:57:05,020 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742188_1368 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-56-41_935_5360326301602140694-1/_task_tmp.-ext-10002/_tmp.000002_0
2017-09-30 19:57:05,434 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-56-41_935_5360326301602140694-1/_task_tmp.-ext-10002/_tmp.000002_0 is closed by DFSClient_attempt_1506813242048_0016_m_000002_0_-9990047_1
2017-09-30 19:57:05,581 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742189_1369, replicas=127.0.0.1:50010 for /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-56-41_935_5360326301602140694-1/_task_tmp.-ext-10002/_tmp.000001_0
2017-09-30 19:57:05,674 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742190_1370, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/job_1506813242048_0016_1.jhist
2017-09-30 19:57:05,706 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/job_1506813242048_0016_1.jhist for DFSClient_NONMAPREDUCE_-1914410126_1
2017-09-30 19:57:05,793 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742191_1371, replicas=127.0.0.1:50010 for /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-56-41_935_5360326301602140694-1/_task_tmp.-ext-10002/_tmp.000000_0
2017-09-30 19:57:10,093 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-56-41_935_5360326301602140694-1/_task_tmp.-ext-10002/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0016_m_000000_0_-992117450_1
2017-09-30 19:57:10,130 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-56-41_935_5360326301602140694-1/_task_tmp.-ext-10002/_tmp.000001_0 is closed by DFSClient_attempt_1506813242048_0016_m_000001_0_167056002_1
2017-09-30 19:57:10,273 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1914410126_1
2017-09-30 19:57:10,279 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1914410126_1
2017-09-30 19:57:10,295 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0016/job_1506813242048_0016_1.jhist is closed by DFSClient_NONMAPREDUCE_-1914410126_1
2017-09-30 19:57:10,303 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742192_1372, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0016.summary_tmp
2017-09-30 19:57:10,309 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0016.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1914410126_1
2017-09-30 19:57:10,333 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742193_1373, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0016-1506819406479-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819430280-3-0-SUCCEEDED-default-1506819411325.jhist_tmp
2017-09-30 19:57:10,339 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0016-1506819406479-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819430280-3-0-SUCCEEDED-default-1506819411325.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1914410126_1
2017-09-30 19:57:10,350 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742194_1374, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0016_conf.xml_tmp
2017-09-30 19:57:10,358 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0016_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1914410126_1
2017-09-30 19:57:12,000 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742195_1375, replicas=127.0.0.1:50010 for /tmp/hive/root/ae9b7a3e-9dc8-42d5-8ab8-80e4c536439d/hive_2017-09-30_19-56-41_935_5360326301602140694-1/-mr-10006/687e1b1a-5733-45c2-8ef7-f905f1ee5ddc/map.xml
2017-09-30 19:57:12,014 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742195_1375 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/ae9b7a3e-9dc8-42d5-8ab8-80e4c536439d/hive_2017-09-30_19-56-41_935_5360326301602140694-1/-mr-10006/687e1b1a-5733-45c2-8ef7-f905f1ee5ddc/map.xml
2017-09-30 19:57:12,418 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/ae9b7a3e-9dc8-42d5-8ab8-80e4c536439d/hive_2017-09-30_19-56-41_935_5360326301602140694-1/-mr-10006/687e1b1a-5733-45c2-8ef7-f905f1ee5ddc/map.xml is closed by DFSClient_NONMAPREDUCE_-250977902_1
2017-09-30 19:57:12,426 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/ae9b7a3e-9dc8-42d5-8ab8-80e4c536439d/hive_2017-09-30_19-56-41_935_5360326301602140694-1/-mr-10006/687e1b1a-5733-45c2-8ef7-f905f1ee5ddc/map.xml
2017-09-30 19:57:12,615 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000, call Call#212 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:59452: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/ae9b7a3e-9dc8-42d5-8ab8-80e4c536439d/hive_2017-09-30_19-56-41_935_5360326301602140694-1/-mr-10006/687e1b1a-5733-45c2-8ef7-f905f1ee5ddc/reduce.xml
2017-09-30 19:57:12,635 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742196_1376, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/job.jar
2017-09-30 19:57:12,762 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/job.jar is closed by DFSClient_NONMAPREDUCE_-250977902_1
2017-09-30 19:57:12,765 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/job.jar
2017-09-30 19:57:12,784 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/job.split
2017-09-30 19:57:12,785 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742197_1377, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/job.split
2017-09-30 19:57:12,791 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/job.split is closed by DFSClient_NONMAPREDUCE_-250977902_1
2017-09-30 19:57:12,795 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742198_1378, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/job.splitmetainfo
2017-09-30 19:57:12,806 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-250977902_1
2017-09-30 19:57:12,834 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742199_1379, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/job.xml
2017-09-30 19:57:12,842 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742199_1379 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/job.xml
2017-09-30 19:57:13,245 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/job.xml is closed by DFSClient_NONMAPREDUCE_-250977902_1
2017-09-30 19:57:22,572 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742200_1380, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/job_1506813242048_0017_1_conf.xml
2017-09-30 19:57:22,633 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742200_1380 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/job_1506813242048_0017_1_conf.xml
2017-09-30 19:57:23,046 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/job_1506813242048_0017_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-8334186_1
2017-09-30 19:57:27,382 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742201_1381, replicas=127.0.0.1:50010 for /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-56-41_935_5360326301602140694-1/_task_tmp.-ext-10000/_tmp.000000_0
2017-09-30 19:57:27,542 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_hashtags/.hive-staging_hive_2017-09-30_19-56-41_935_5360326301602140694-1/_task_tmp.-ext-10000/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0017_m_000000_0_-139438139_1
2017-09-30 19:57:27,669 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-8334186_1
2017-09-30 19:57:27,681 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742202_1382, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/job_1506813242048_0017_1.jhist
2017-09-30 19:57:27,691 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-8334186_1
2017-09-30 19:57:27,693 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/job_1506813242048_0017_1.jhist for DFSClient_NONMAPREDUCE_-8334186_1
2017-09-30 19:57:27,719 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0017/job_1506813242048_0017_1.jhist is closed by DFSClient_NONMAPREDUCE_-8334186_1
2017-09-30 19:57:27,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742203_1383, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0017.summary_tmp
2017-09-30 19:57:27,733 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0017.summary_tmp is closed by DFSClient_NONMAPREDUCE_-8334186_1
2017-09-30 19:57:27,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742204_1384, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0017-1506819433304-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819447694-1-0-SUCCEEDED-default-1506819442382.jhist_tmp
2017-09-30 19:57:27,772 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0017-1506819433304-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819447694-1-0-SUCCEEDED-default-1506819442382.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-8334186_1
2017-09-30 19:57:27,785 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742205_1385, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0017_conf.xml_tmp
2017-09-30 19:57:27,799 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0017_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-8334186_1
2017-09-30 19:57:34,017 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1334 Total time for transactions(ms): 60 Number of transactions batched in Syncs: 371 Number of syncs: 963 SyncTimes(ms): 1857 
2017-09-30 19:58:35,334 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1335 Total time for transactions(ms): 60 Number of transactions batched in Syncs: 371 Number of syncs: 964 SyncTimes(ms): 1859 
2017-09-30 19:58:46,196 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742206_1386, replicas=127.0.0.1:50010 for /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_19-58-43_865_1133205610777161929-1/-mr-10004/7a595831-a53f-489e-adfc-8f6cfb7dd8ee/map.xml
2017-09-30 19:58:46,272 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_19-58-43_865_1133205610777161929-1/-mr-10004/7a595831-a53f-489e-adfc-8f6cfb7dd8ee/map.xml is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 19:58:46,287 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_19-58-43_865_1133205610777161929-1/-mr-10004/7a595831-a53f-489e-adfc-8f6cfb7dd8ee/map.xml
2017-09-30 19:58:46,706 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000, call Call#33 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:59526: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_19-58-43_865_1133205610777161929-1/-mr-10004/7a595831-a53f-489e-adfc-8f6cfb7dd8ee/reduce.xml
2017-09-30 19:58:46,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742207_1387, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/job.jar
2017-09-30 19:58:47,085 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/job.jar is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 19:58:47,089 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/job.jar
2017-09-30 19:58:47,176 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/job.split
2017-09-30 19:58:47,186 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742208_1388, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/job.split
2017-09-30 19:58:47,196 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742208_1388 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/job.split
2017-09-30 19:58:47,597 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/job.split is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 19:58:47,609 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742209_1389, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/job.splitmetainfo
2017-09-30 19:58:47,618 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 19:58:47,654 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742210_1390, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/job.xml
2017-09-30 19:58:47,678 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/job.xml is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 19:58:52,985 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742211_1391, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/job_1506813242048_0018_1_conf.xml
2017-09-30 19:58:53,021 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/job_1506813242048_0018_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-176957414_1
2017-09-30 19:59:04,747 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742212_1392, replicas=127.0.0.1:50010 for /test/proj1_url/.hive-staging_hive_2017-09-30_19-58-43_865_1133205610777161929-1/_task_tmp.-ext-10002/_tmp.000001_0
2017-09-30 19:59:04,876 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742213_1393, replicas=127.0.0.1:50010 for /test/proj1_url/.hive-staging_hive_2017-09-30_19-58-43_865_1133205610777161929-1/_task_tmp.-ext-10002/_tmp.000002_0
2017-09-30 19:59:05,950 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742214_1394, replicas=127.0.0.1:50010 for /test/proj1_url/.hive-staging_hive_2017-09-30_19-58-43_865_1133205610777161929-1/_task_tmp.-ext-10002/_tmp.000000_0
2017-09-30 19:59:06,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742213_1393 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /test/proj1_url/.hive-staging_hive_2017-09-30_19-58-43_865_1133205610777161929-1/_task_tmp.-ext-10002/_tmp.000002_0
2017-09-30 19:59:06,801 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_url/.hive-staging_hive_2017-09-30_19-58-43_865_1133205610777161929-1/_task_tmp.-ext-10002/_tmp.000002_0 is closed by DFSClient_attempt_1506813242048_0018_m_000002_0_-614852204_1
2017-09-30 19:59:07,173 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742215_1395, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/job_1506813242048_0018_1.jhist
2017-09-30 19:59:07,280 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/job_1506813242048_0018_1.jhist for DFSClient_NONMAPREDUCE_-176957414_1
2017-09-30 19:59:10,598 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_url/.hive-staging_hive_2017-09-30_19-58-43_865_1133205610777161929-1/_task_tmp.-ext-10002/_tmp.000001_0 is closed by DFSClient_attempt_1506813242048_0018_m_000001_0_2019349067_1
2017-09-30 19:59:11,055 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_url/.hive-staging_hive_2017-09-30_19-58-43_865_1133205610777161929-1/_task_tmp.-ext-10002/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0018_m_000000_0_-855650420_1
2017-09-30 19:59:11,153 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-176957414_1
2017-09-30 19:59:11,158 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-176957414_1
2017-09-30 19:59:11,178 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0018/job_1506813242048_0018_1.jhist is closed by DFSClient_NONMAPREDUCE_-176957414_1
2017-09-30 19:59:11,184 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742216_1396, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0018.summary_tmp
2017-09-30 19:59:11,193 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0018.summary_tmp is closed by DFSClient_NONMAPREDUCE_-176957414_1
2017-09-30 19:59:11,216 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742217_1397, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0018-1506819527878-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819551160-3-0-SUCCEEDED-default-1506819532835.jhist_tmp
2017-09-30 19:59:11,223 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0018-1506819527878-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819551160-3-0-SUCCEEDED-default-1506819532835.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-176957414_1
2017-09-30 19:59:11,249 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742218_1398, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0018_conf.xml_tmp
2017-09-30 19:59:11,256 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742218_1398 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0018_conf.xml_tmp
2017-09-30 19:59:11,658 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0018_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-176957414_1
2017-09-30 19:59:14,000 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742219_1399, replicas=127.0.0.1:50010 for /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_19-58-43_865_1133205610777161929-1/-mr-10006/13573a51-f951-4f11-be4f-4a502a1ea38a/map.xml
2017-09-30 19:59:14,019 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_19-58-43_865_1133205610777161929-1/-mr-10006/13573a51-f951-4f11-be4f-4a502a1ea38a/map.xml is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 19:59:14,024 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_19-58-43_865_1133205610777161929-1/-mr-10006/13573a51-f951-4f11-be4f-4a502a1ea38a/map.xml
2017-09-30 19:59:14,189 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000, call Call#213 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:59608: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_19-58-43_865_1133205610777161929-1/-mr-10006/13573a51-f951-4f11-be4f-4a502a1ea38a/reduce.xml
2017-09-30 19:59:14,212 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742220_1400, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/job.jar
2017-09-30 19:59:14,353 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742220_1400 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/job.jar
2017-09-30 19:59:14,756 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/job.jar is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 19:59:14,763 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/job.jar
2017-09-30 19:59:14,842 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/job.split
2017-09-30 19:59:14,846 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742221_1401, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/job.split
2017-09-30 19:59:14,860 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/job.split is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 19:59:14,882 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742222_1402, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/job.splitmetainfo
2017-09-30 19:59:14,925 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 19:59:14,943 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742223_1403, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/job.xml
2017-09-30 19:59:14,958 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/job.xml is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 19:59:23,916 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742224_1404, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/job_1506813242048_0019_1_conf.xml
2017-09-30 19:59:23,947 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742224_1404 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/job_1506813242048_0019_1_conf.xml
2017-09-30 19:59:24,352 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/job_1506813242048_0019_1_conf.xml is closed by DFSClient_NONMAPREDUCE_126035524_1
2017-09-30 19:59:28,654 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742225_1405, replicas=127.0.0.1:50010 for /test/proj1_url/.hive-staging_hive_2017-09-30_19-58-43_865_1133205610777161929-1/_task_tmp.-ext-10000/_tmp.000000_0
2017-09-30 19:59:28,810 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742225_1405 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /test/proj1_url/.hive-staging_hive_2017-09-30_19-58-43_865_1133205610777161929-1/_task_tmp.-ext-10000/_tmp.000000_0
2017-09-30 19:59:29,214 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_url/.hive-staging_hive_2017-09-30_19-58-43_865_1133205610777161929-1/_task_tmp.-ext-10000/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0019_m_000000_0_1662874871_1
2017-09-30 19:59:29,452 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742226_1406, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/job_1506813242048_0019_1.jhist
2017-09-30 19:59:29,455 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_126035524_1
2017-09-30 19:59:29,467 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_126035524_1
2017-09-30 19:59:29,469 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/job_1506813242048_0019_1.jhist for DFSClient_NONMAPREDUCE_126035524_1
2017-09-30 19:59:29,501 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0019/job_1506813242048_0019_1.jhist is closed by DFSClient_NONMAPREDUCE_126035524_1
2017-09-30 19:59:29,509 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742227_1407, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0019.summary_tmp
2017-09-30 19:59:29,518 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0019.summary_tmp is closed by DFSClient_NONMAPREDUCE_126035524_1
2017-09-30 19:59:29,551 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742228_1408, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0019-1506819554982-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819569470-1-0-SUCCEEDED-default-1506819563774.jhist_tmp
2017-09-30 19:59:29,560 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0019-1506819554982-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819569470-1-0-SUCCEEDED-default-1506819563774.jhist_tmp is closed by DFSClient_NONMAPREDUCE_126035524_1
2017-09-30 19:59:29,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742229_1409, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0019_conf.xml_tmp
2017-09-30 19:59:29,601 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0019_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_126035524_1
2017-09-30 20:00:01,093 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1527 Total time for transactions(ms): 64 Number of transactions batched in Syncs: 424 Number of syncs: 1102 SyncTimes(ms): 2115 
2017-09-30 20:00:01,139 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742230_1410, replicas=127.0.0.1:50010 for /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_20-00-01_009_120600547654172495-1/-mr-10004/09085bca-a04e-48eb-95ef-594ff812d399/map.xml
2017-09-30 20:00:01,148 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742230_1410 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_20-00-01_009_120600547654172495-1/-mr-10004/09085bca-a04e-48eb-95ef-594ff812d399/map.xml
2017-09-30 20:00:01,550 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_20-00-01_009_120600547654172495-1/-mr-10004/09085bca-a04e-48eb-95ef-594ff812d399/map.xml is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:00:01,555 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_20-00-01_009_120600547654172495-1/-mr-10004/09085bca-a04e-48eb-95ef-594ff812d399/map.xml
2017-09-30 20:00:01,683 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call Call#365 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:59670: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_20-00-01_009_120600547654172495-1/-mr-10004/09085bca-a04e-48eb-95ef-594ff812d399/reduce.xml
2017-09-30 20:00:01,713 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742231_1411, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/job.jar
2017-09-30 20:00:01,875 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742231_1411 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/job.jar
2017-09-30 20:00:02,280 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/job.jar is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:00:02,288 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/job.jar
2017-09-30 20:00:02,359 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/job.split
2017-09-30 20:00:02,375 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742232_1412, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/job.split
2017-09-30 20:00:02,396 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/job.split is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:00:02,409 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742233_1413, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/job.splitmetainfo
2017-09-30 20:00:02,420 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:00:02,447 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742234_1414, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/job.xml
2017-09-30 20:00:02,473 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/job.xml is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:00:08,038 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742235_1415, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/job_1506813242048_0020_1_conf.xml
2017-09-30 20:00:08,072 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742235_1415 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/job_1506813242048_0020_1_conf.xml
2017-09-30 20:00:08,481 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/job_1506813242048_0020_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-175105076_1
2017-09-30 20:00:19,133 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742236_1416, replicas=127.0.0.1:50010 for /test/proj1_expanded_url/.hive-staging_hive_2017-09-30_20-00-01_009_120600547654172495-1/_task_tmp.-ext-10002/_tmp.000001_0
2017-09-30 20:00:19,428 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742237_1417, replicas=127.0.0.1:50010 for /test/proj1_expanded_url/.hive-staging_hive_2017-09-30_20-00-01_009_120600547654172495-1/_task_tmp.-ext-10002/_tmp.000002_0
2017-09-30 20:00:20,764 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742238_1418, replicas=127.0.0.1:50010 for /test/proj1_expanded_url/.hive-staging_hive_2017-09-30_20-00-01_009_120600547654172495-1/_task_tmp.-ext-10002/_tmp.000000_0
2017-09-30 20:00:21,852 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_expanded_url/.hive-staging_hive_2017-09-30_20-00-01_009_120600547654172495-1/_task_tmp.-ext-10002/_tmp.000002_0 is closed by DFSClient_attempt_1506813242048_0020_m_000002_0_-360508930_1
2017-09-30 20:00:22,316 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742239_1419, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/job_1506813242048_0020_1.jhist
2017-09-30 20:00:22,354 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/job_1506813242048_0020_1.jhist for DFSClient_NONMAPREDUCE_-175105076_1
2017-09-30 20:00:26,363 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_expanded_url/.hive-staging_hive_2017-09-30_20-00-01_009_120600547654172495-1/_task_tmp.-ext-10002/_tmp.000001_0 is closed by DFSClient_attempt_1506813242048_0020_m_000001_0_-181854678_1
2017-09-30 20:00:27,154 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_expanded_url/.hive-staging_hive_2017-09-30_20-00-01_009_120600547654172495-1/_task_tmp.-ext-10002/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0020_m_000000_0_1449112019_1
2017-09-30 20:00:27,280 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-175105076_1
2017-09-30 20:00:27,290 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-175105076_1
2017-09-30 20:00:27,318 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0020/job_1506813242048_0020_1.jhist is closed by DFSClient_NONMAPREDUCE_-175105076_1
2017-09-30 20:00:27,325 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742240_1420, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0020.summary_tmp
2017-09-30 20:00:27,333 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0020.summary_tmp is closed by DFSClient_NONMAPREDUCE_-175105076_1
2017-09-30 20:00:27,361 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742241_1421, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0020-1506819602498-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819627293-3-0-SUCCEEDED-default-1506819607882.jhist_tmp
2017-09-30 20:00:27,370 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742241_1421 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0020-1506819602498-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819627293-3-0-SUCCEEDED-default-1506819607882.jhist_tmp
2017-09-30 20:00:27,773 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0020-1506819602498-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819627293-3-0-SUCCEEDED-default-1506819607882.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-175105076_1
2017-09-30 20:00:27,796 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742242_1422, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0020_conf.xml_tmp
2017-09-30 20:00:27,824 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742242_1422 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0020_conf.xml_tmp
2017-09-30 20:00:28,227 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0020_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-175105076_1
2017-09-30 20:00:29,928 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742243_1423, replicas=127.0.0.1:50010 for /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_20-00-01_009_120600547654172495-1/-mr-10006/0155e849-896b-46fd-83d3-5653c919220f/map.xml
2017-09-30 20:00:29,935 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_20-00-01_009_120600547654172495-1/-mr-10006/0155e849-896b-46fd-83d3-5653c919220f/map.xml is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:00:29,938 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_20-00-01_009_120600547654172495-1/-mr-10006/0155e849-896b-46fd-83d3-5653c919220f/map.xml
2017-09-30 20:00:30,025 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9000, call Call#552 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:59750: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_20-00-01_009_120600547654172495-1/-mr-10006/0155e849-896b-46fd-83d3-5653c919220f/reduce.xml
2017-09-30 20:00:30,048 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742244_1424, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/job.jar
2017-09-30 20:00:30,176 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742244_1424 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/job.jar
2017-09-30 20:00:30,579 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/job.jar is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:00:30,586 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/job.jar
2017-09-30 20:00:30,655 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/job.split
2017-09-30 20:00:30,661 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742245_1425, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/job.split
2017-09-30 20:00:30,681 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/job.split is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:00:30,700 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742246_1426, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/job.splitmetainfo
2017-09-30 20:00:30,717 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:00:30,749 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742247_1427, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/job.xml
2017-09-30 20:00:30,775 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/job.xml is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:00:39,962 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742248_1428, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/job_1506813242048_0021_1_conf.xml
2017-09-30 20:00:40,017 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742248_1428 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/job_1506813242048_0021_1_conf.xml
2017-09-30 20:00:40,423 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/job_1506813242048_0021_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-729991564_1
2017-09-30 20:00:44,643 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742249_1429, replicas=127.0.0.1:50010 for /test/proj1_expanded_url/.hive-staging_hive_2017-09-30_20-00-01_009_120600547654172495-1/_task_tmp.-ext-10000/_tmp.000000_0
2017-09-30 20:00:44,827 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_expanded_url/.hive-staging_hive_2017-09-30_20-00-01_009_120600547654172495-1/_task_tmp.-ext-10000/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0021_m_000000_0_-1589286609_1
2017-09-30 20:00:44,960 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742250_1430, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/job_1506813242048_0021_1.jhist
2017-09-30 20:00:44,970 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-729991564_1
2017-09-30 20:00:44,971 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/job_1506813242048_0021_1.jhist for DFSClient_NONMAPREDUCE_-729991564_1
2017-09-30 20:00:44,977 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-729991564_1
2017-09-30 20:00:44,998 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0021/job_1506813242048_0021_1.jhist is closed by DFSClient_NONMAPREDUCE_-729991564_1
2017-09-30 20:00:45,003 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742251_1431, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0021.summary_tmp
2017-09-30 20:00:45,010 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0021.summary_tmp is closed by DFSClient_NONMAPREDUCE_-729991564_1
2017-09-30 20:00:45,037 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742252_1432, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0021-1506819630798-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819644979-1-0-SUCCEEDED-default-1506819639775.jhist_tmp
2017-09-30 20:00:45,048 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0021-1506819630798-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819644979-1-0-SUCCEEDED-default-1506819639775.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-729991564_1
2017-09-30 20:00:45,061 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742253_1433, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0021_conf.xml_tmp
2017-09-30 20:00:45,071 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742253_1433 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0021_conf.xml_tmp
2017-09-30 20:00:45,476 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0021_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-729991564_1
2017-09-30 20:01:34,087 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1716 Total time for transactions(ms): 68 Number of transactions batched in Syncs: 477 Number of syncs: 1238 SyncTimes(ms): 2350 
2017-09-30 20:01:34,123 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742254_1434, replicas=127.0.0.1:50010 for /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_20-01-34_015_2575955567183499181-1/-mr-10004/21f5e004-bcc5-4a7a-92d0-128dc0657f1c/map.xml
2017-09-30 20:01:34,132 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_20-01-34_015_2575955567183499181-1/-mr-10004/21f5e004-bcc5-4a7a-92d0-128dc0657f1c/map.xml is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:01:34,134 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_20-01-34_015_2575955567183499181-1/-mr-10004/21f5e004-bcc5-4a7a-92d0-128dc0657f1c/map.xml
2017-09-30 20:01:34,201 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call Call#708 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:59812: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_20-01-34_015_2575955567183499181-1/-mr-10004/21f5e004-bcc5-4a7a-92d0-128dc0657f1c/reduce.xml
2017-09-30 20:01:34,216 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742255_1435, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0022/job.jar
2017-09-30 20:01:34,321 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0022/job.jar is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:01:34,325 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0022/job.jar
2017-09-30 20:01:34,338 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0022/job.split
2017-09-30 20:01:34,340 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742256_1436, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0022/job.split
2017-09-30 20:01:34,344 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0022/job.split is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:01:34,348 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742257_1437, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0022/job.splitmetainfo
2017-09-30 20:01:34,353 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0022/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:01:34,364 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742258_1438, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0022/job.xml
2017-09-30 20:01:34,371 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0022/job.xml is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:01:39,850 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742259_1439, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0022/job_1506813242048_0022_1_conf.xml
2017-09-30 20:01:39,896 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0022/job_1506813242048_0022_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-2017907816_1
2017-09-30 20:01:52,023 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742260_1440, replicas=127.0.0.1:50010 for /test/proj1_display_url/.hive-staging_hive_2017-09-30_20-01-34_015_2575955567183499181-1/_task_tmp.-ext-10002/_tmp.000001_0
2017-09-30 20:01:52,603 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742261_1441, replicas=127.0.0.1:50010 for /test/proj1_display_url/.hive-staging_hive_2017-09-30_20-01-34_015_2575955567183499181-1/_task_tmp.-ext-10002/_tmp.000002_0
2017-09-30 20:01:52,764 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742262_1442, replicas=127.0.0.1:50010 for /test/proj1_display_url/.hive-staging_hive_2017-09-30_20-01-34_015_2575955567183499181-1/_task_tmp.-ext-10002/_tmp.000000_0
2017-09-30 20:01:53,873 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_display_url/.hive-staging_hive_2017-09-30_20-01-34_015_2575955567183499181-1/_task_tmp.-ext-10002/_tmp.000002_0 is closed by DFSClient_attempt_1506813242048_0022_m_000002_0_1979377702_1
2017-09-30 20:01:54,363 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742263_1443, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0022/job_1506813242048_0022_1.jhist
2017-09-30 20:01:54,384 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0022/job_1506813242048_0022_1.jhist for DFSClient_NONMAPREDUCE_-2017907816_1
2017-09-30 20:01:58,451 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_display_url/.hive-staging_hive_2017-09-30_20-01-34_015_2575955567183499181-1/_task_tmp.-ext-10002/_tmp.000001_0 is closed by DFSClient_attempt_1506813242048_0022_m_000001_0_-246523521_1
2017-09-30 20:01:58,798 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_display_url/.hive-staging_hive_2017-09-30_20-01-34_015_2575955567183499181-1/_task_tmp.-ext-10002/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0022_m_000000_0_-1389631690_1
2017-09-30 20:01:58,868 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0022/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-2017907816_1
2017-09-30 20:01:58,875 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0022/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-2017907816_1
2017-09-30 20:01:58,893 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0022/job_1506813242048_0022_1.jhist is closed by DFSClient_NONMAPREDUCE_-2017907816_1
2017-09-30 20:01:58,904 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742264_1444, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0022.summary_tmp
2017-09-30 20:01:58,915 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0022.summary_tmp is closed by DFSClient_NONMAPREDUCE_-2017907816_1
2017-09-30 20:01:58,940 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742265_1445, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0022-1506819694382-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819718876-3-0-SUCCEEDED-default-1506819699640.jhist_tmp
2017-09-30 20:01:58,950 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0022-1506819694382-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819718876-3-0-SUCCEEDED-default-1506819699640.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-2017907816_1
2017-09-30 20:01:58,968 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742266_1446, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0022_conf.xml_tmp
2017-09-30 20:01:58,980 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742266_1446 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0022_conf.xml_tmp
2017-09-30 20:01:59,383 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0022_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-2017907816_1
2017-09-30 20:02:01,233 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742267_1447, replicas=127.0.0.1:50010 for /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_20-01-34_015_2575955567183499181-1/-mr-10006/d8f13ddd-545f-4cfa-9db3-5bc4c02e5a56/map.xml
2017-09-30 20:02:01,243 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_20-01-34_015_2575955567183499181-1/-mr-10006/d8f13ddd-545f-4cfa-9db3-5bc4c02e5a56/map.xml is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:02:01,246 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_20-01-34_015_2575955567183499181-1/-mr-10006/d8f13ddd-545f-4cfa-9db3-5bc4c02e5a56/map.xml
2017-09-30 20:02:01,302 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000, call Call#893 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:59896: java.io.FileNotFoundException: File does not exist: /tmp/hive/root/be0c06ff-b16c-4b1a-a400-0a031bdb4fa9/hive_2017-09-30_20-01-34_015_2575955567183499181-1/-mr-10006/d8f13ddd-545f-4cfa-9db3-5bc4c02e5a56/reduce.xml
2017-09-30 20:02:01,317 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742268_1448, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0023/job.jar
2017-09-30 20:02:01,435 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0023/job.jar is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:02:01,437 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0023/job.jar
2017-09-30 20:02:01,455 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0023/job.split
2017-09-30 20:02:01,456 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742269_1449, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0023/job.split
2017-09-30 20:02:01,461 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0023/job.split is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:02:01,466 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742270_1450, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0023/job.splitmetainfo
2017-09-30 20:02:01,470 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0023/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:02:01,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742271_1451, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0023/job.xml
2017-09-30 20:02:01,485 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0023/job.xml is closed by DFSClient_NONMAPREDUCE_814619903_1
2017-09-30 20:02:11,830 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742272_1452, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0023/job_1506813242048_0023_1_conf.xml
2017-09-30 20:02:11,878 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0023/job_1506813242048_0023_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1977740259_1
2017-09-30 20:02:16,509 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742273_1453, replicas=127.0.0.1:50010 for /test/proj1_display_url/.hive-staging_hive_2017-09-30_20-01-34_015_2575955567183499181-1/_task_tmp.-ext-10000/_tmp.000000_0
2017-09-30 20:02:16,670 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_display_url/.hive-staging_hive_2017-09-30_20-01-34_015_2575955567183499181-1/_task_tmp.-ext-10000/_tmp.000000_0 is closed by DFSClient_attempt_1506813242048_0023_m_000000_0_-2036266877_1
2017-09-30 20:02:16,782 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742274_1454, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0023/job_1506813242048_0023_1.jhist
2017-09-30 20:02:16,790 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0023/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1977740259_1
2017-09-30 20:02:16,794 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0023/job_1506813242048_0023_1.jhist for DFSClient_NONMAPREDUCE_-1977740259_1
2017-09-30 20:02:16,801 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0023/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1977740259_1
2017-09-30 20:02:16,818 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0023/job_1506813242048_0023_1.jhist is closed by DFSClient_NONMAPREDUCE_-1977740259_1
2017-09-30 20:02:16,826 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742275_1455, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0023.summary_tmp
2017-09-30 20:02:16,832 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0023.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1977740259_1
2017-09-30 20:02:16,858 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742276_1456, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0023-1506819721494-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819736802-1-0-SUCCEEDED-default-1506819731589.jhist_tmp
2017-09-30 20:02:16,864 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0023-1506819721494-root-INSERT+OVERWRITE++DIRECTORY++%27%2Ftest%2Fp...null-1506819736802-1-0-SUCCEEDED-default-1506819731589.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1977740259_1
2017-09-30 20:02:16,886 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742277_1457, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0023_conf.xml_tmp
2017-09-30 20:02:16,903 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0023_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1977740259_1
2017-09-30 20:06:45,148 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-30 20:06:45,148 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-30 20:06:45,148 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 2445, 4348
2017-09-30 20:06:45,148 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=4349 lastSyncedTxid=4348 mostRecentTxid=4349
2017-09-30 20:06:45,148 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1905 Total time for transactions(ms): 74 Number of transactions batched in Syncs: 530 Number of syncs: 1375 SyncTimes(ms): 2515 
2017-09-30 20:06:45,153 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=4349 lastSyncedTxid=4349 mostRecentTxid=4349
2017-09-30 20:06:45,153 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1905 Total time for transactions(ms): 74 Number of transactions batched in Syncs: 530 Number of syncs: 1376 SyncTimes(ms): 2519 
2017-09-30 20:06:45,154 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000002445 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000002445-0000000000000004349
2017-09-30 20:06:45,155 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4350
2017-09-30 20:06:45,404 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 19000.00 KB/s
2017-09-30 20:06:45,404 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004349 size 20111 bytes.
2017-09-30 20:06:45,406 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2444
2017-09-30 20:06:45,406 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000001920, cpktTxId=0000000000000001920)
2017-09-30 20:07:50,095 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2017-09-30 20:07:50,156 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742278_1458, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0024/job.jar
2017-09-30 20:07:50,211 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0024/job.jar is closed by DFSClient_NONMAPREDUCE_-374655960_1
2017-09-30 20:07:50,215 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0024/job.jar
2017-09-30 20:07:50,252 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0024/job.split
2017-09-30 20:07:50,260 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742279_1459, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0024/job.split
2017-09-30 20:07:50,266 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0024/job.split is closed by DFSClient_NONMAPREDUCE_-374655960_1
2017-09-30 20:07:50,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742280_1460, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0024/job.splitmetainfo
2017-09-30 20:07:50,282 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0024/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-374655960_1
2017-09-30 20:07:50,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742281_1461, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0024/job.xml
2017-09-30 20:07:50,388 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0024/job.xml is closed by DFSClient_NONMAPREDUCE_-374655960_1
2017-09-30 20:07:54,834 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742282_1462, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0024/job_1506813242048_0024_1_conf.xml
2017-09-30 20:07:54,868 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0024/job_1506813242048_0024_1_conf.xml is closed by DFSClient_NONMAPREDUCE_339004023_1
2017-09-30 20:07:59,529 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742283_1463, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0024/job_1506813242048_0024_1.jhist
2017-09-30 20:07:59,539 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0024/job_1506813242048_0024_1.jhist for DFSClient_NONMAPREDUCE_339004023_1
2017-09-30 20:08:04,308 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742284_1464, replicas=127.0.0.1:50010 for /test/projwc1/_temporary/1/_temporary/attempt_1506813242048_0024_r_000000_0/part-r-00000
2017-09-30 20:08:04,410 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/projwc1/_temporary/1/_temporary/attempt_1506813242048_0024_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1506813242048_0024_r_000000_0_-1782859690_1
2017-09-30 20:08:04,527 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0024/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_339004023_1
2017-09-30 20:08:04,565 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/projwc1/_SUCCESS is closed by DFSClient_NONMAPREDUCE_339004023_1
2017-09-30 20:08:04,569 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0024/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_339004023_1
2017-09-30 20:08:04,593 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0024/job_1506813242048_0024_1.jhist is closed by DFSClient_NONMAPREDUCE_339004023_1
2017-09-30 20:08:04,602 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742285_1465, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0024.summary_tmp
2017-09-30 20:08:04,614 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0024.summary_tmp is closed by DFSClient_NONMAPREDUCE_339004023_1
2017-09-30 20:08:04,641 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742286_1466, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0024-1506820070556-root-word+count-1506820084571-1-1-SUCCEEDED-default-1506820074640.jhist_tmp
2017-09-30 20:08:04,650 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0024-1506820070556-root-word+count-1506820084571-1-1-SUCCEEDED-default-1506820074640.jhist_tmp is closed by DFSClient_NONMAPREDUCE_339004023_1
2017-09-30 20:08:04,666 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742287_1467, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0024_conf.xml_tmp
2017-09-30 20:08:04,675 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0024_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_339004023_1
2017-09-30 20:20:37,536 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 82 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 24 Number of syncs: 58 SyncTimes(ms): 58 
2017-09-30 20:20:37,602 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742288_1468, replicas=127.0.0.1:50010 for /test/proj1_output/displayurl._COPYING_
2017-09-30 20:20:37,636 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_output/displayurl._COPYING_ is closed by DFSClient_NONMAPREDUCE_-119164058_1
2017-09-30 20:24:41,907 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 88 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 26 Number of syncs: 62 SyncTimes(ms): 65 
2017-09-30 20:24:41,976 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742289_1469, replicas=127.0.0.1:50010 for /test/proj1_output/expandedurl._COPYING_
2017-09-30 20:24:42,015 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_output/expandedurl._COPYING_ is closed by DFSClient_NONMAPREDUCE_993142652_1
2017-09-30 20:25:40,640 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742290_1470, replicas=127.0.0.1:50010 for /test/proj1_output/url._COPYING_
2017-09-30 20:25:40,666 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_output/url._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1312730297_1
2017-09-30 20:27:06,249 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 100 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 30 Number of syncs: 70 SyncTimes(ms): 87 
2017-09-30 20:27:06,323 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742291_1471, replicas=127.0.0.1:50010 for /test/proj1_output/hashtags._COPYING_
2017-09-30 20:27:06,345 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742291_1471 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /test/proj1_output/hashtags._COPYING_
2017-09-30 20:27:06,750 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_output/hashtags._COPYING_ is closed by DFSClient_NONMAPREDUCE_361900868_1
2017-09-30 20:46:40,553 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 106 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 32 Number of syncs: 74 SyncTimes(ms): 99 
2017-09-30 20:46:40,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742292_1472, replicas=127.0.0.1:50010 for /test/proj1_output/hashtags_urls._COPYING_
2017-09-30 20:46:40,669 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/proj1_output/hashtags_urls._COPYING_ is closed by DFSClient_NONMAPREDUCE_616804296_1
2017-09-30 20:49:23,242 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 112 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 34 Number of syncs: 78 SyncTimes(ms): 106 
2017-09-30 20:53:04,374 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 114 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 34 Number of syncs: 80 SyncTimes(ms): 109 
2017-09-30 20:53:51,978 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742293_1473, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/job.jar
2017-09-30 20:53:52,025 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/job.jar is closed by DFSClient_NONMAPREDUCE_-2119841543_1
2017-09-30 20:53:52,030 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/job.jar
2017-09-30 20:53:52,061 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/job.split
2017-09-30 20:53:52,073 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742294_1474, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/job.split
2017-09-30 20:53:52,080 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/job.split is closed by DFSClient_NONMAPREDUCE_-2119841543_1
2017-09-30 20:53:52,091 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742295_1475, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/job.splitmetainfo
2017-09-30 20:53:52,099 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742295_1475 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/job.splitmetainfo
2017-09-30 20:53:52,503 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-2119841543_1
2017-09-30 20:53:52,740 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742296_1476, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/job.xml
2017-09-30 20:53:52,750 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/job.xml is closed by DFSClient_NONMAPREDUCE_-2119841543_1
2017-09-30 20:53:57,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742297_1477, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/job_1506813242048_0025_1_conf.xml
2017-09-30 20:53:57,761 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/job_1506813242048_0025_1_conf.xml is closed by DFSClient_NONMAPREDUCE_315303941_1
2017-09-30 20:54:03,257 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742298_1478, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/job_1506813242048_0025_1.jhist
2017-09-30 20:54:03,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/job_1506813242048_0025_1.jhist for DFSClient_NONMAPREDUCE_315303941_1
2017-09-30 20:54:08,201 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 158 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 48 Number of syncs: 108 SyncTimes(ms): 147 
2017-09-30 20:54:08,288 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742299_1479, replicas=127.0.0.1:50010 for /test/projwc/_temporary/1/_temporary/attempt_1506813242048_0025_r_000000_0/part-r-00000
2017-09-30 20:54:08,542 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/projwc/_temporary/1/_temporary/attempt_1506813242048_0025_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1506813242048_0025_r_000000_0_-1315655134_1
2017-09-30 20:54:08,633 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_315303941_1
2017-09-30 20:54:08,660 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/projwc/_SUCCESS is closed by DFSClient_NONMAPREDUCE_315303941_1
2017-09-30 20:54:08,665 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_315303941_1
2017-09-30 20:54:08,689 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1506813242048_0025/job_1506813242048_0025_1.jhist is closed by DFSClient_NONMAPREDUCE_315303941_1
2017-09-30 20:54:08,696 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742300_1480, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0025.summary_tmp
2017-09-30 20:54:08,706 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0025.summary_tmp is closed by DFSClient_NONMAPREDUCE_315303941_1
2017-09-30 20:54:08,739 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742301_1481, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0025-1506822832958-root-word+count-1506822848666-1-1-SUCCEEDED-default-1506822837522.jhist_tmp
2017-09-30 20:54:08,749 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0025-1506822832958-root-word+count-1506822848666-1-1-SUCCEEDED-default-1506822837522.jhist_tmp is closed by DFSClient_NONMAPREDUCE_315303941_1
2017-09-30 20:54:08,762 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742302_1482, replicas=127.0.0.1:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0025_conf.xml_tmp
2017-09-30 20:54:08,771 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1506813242048_0025_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_315303941_1
2017-09-30 20:54:21,342 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1127ms
No GCs detected
2017-09-30 21:06:46,722 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-30 21:06:46,722 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-30 21:06:46,722 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4350, 4543
2017-09-30 21:06:46,722 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: logSyncAll toSyncToTxId=4544 lastSyncedTxid=4543 mostRecentTxid=4544
2017-09-30 21:06:46,722 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 195 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 58 Number of syncs: 137 SyncTimes(ms): 168 
2017-09-30 21:06:46,728 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Done logSyncAll lastWrittenTxId=4544 lastSyncedTxid=4544 mostRecentTxid=4544
2017-09-30 21:06:46,728 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 195 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 58 Number of syncs: 138 SyncTimes(ms): 173 
2017-09-30 21:06:46,730 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/raji/hadoop_store/hdfs/namenode/current/edits_inprogress_0000000000000004350 -> /home/raji/hadoop_store/hdfs/namenode/current/edits_0000000000000004350-0000000000000004544
2017-09-30 21:06:46,730 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4545
2017-09-30 21:06:46,858 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 10000.00 KB/s
2017-09-30 21:06:46,858 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004544 size 21367 bytes.
2017-09-30 21:06:46,861 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4349
2017-09-30 21:06:46,861 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/raji/hadoop_store/hdfs/namenode/current/fsimage_0000000000000002444, cpktTxId=0000000000000002444)
